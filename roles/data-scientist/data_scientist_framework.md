# ğŸ§  Data Scientist Interview Mindmap (Systematic)

## ğŸ“š Resources

**GitHub Repo**: https://github.com/anix-lynch/Exponent

**Source**: https://www.tryexponent.com/questions?role=data-science

---

## ğŸ“Š Question Distribution

```
Behavioral                                         100 questions
Data Analysis - Root Cause                          20 questions
Machine Learning - Model Evaluation                 11 questions
Coding                                              10 questions
Data Analysis - Business Metrics                     7 questions
SQL                                                  6 questions
Machine Learning - Supervised                        4 questions
Statistics & Experimentation - A/B Testing           4 questions
Statistics & Experimentation - Probability           4 questions
Deep Learning                                        3 questions
Machine Learning - Unsupervised                      1 questions
Statistics & Experimentation - Hypothesis Testing    1 questions
Computer Vision                                      1 questions
Recommendation Systems                               1 questions
```

**Total: 173 questions across 14 categories**

---

## ğŸ¯ How to USE this in interviews

When a question comes:

1. **Name the category silently**
2. **Apply that category's framework**
3. Speak in **structured bullets**

---

## 0ï¸âƒ£ Core Interview Meta-Structure (applies to EVERYTHING)

No matter the category, interviewers are testing:

- **Technical depth** - Do you understand the fundamentals?
- **Practical application** - Can you apply theory to real problems?
- **Communication** - Can you explain complex concepts clearly?
- **Business impact** - Do you connect models to business value?

So every answer should follow this shape:

```
Understand â†’ Plan â†’ Implement â†’ Evaluate â†’ Communicate impact
```

---

## Key Categories

### Behavioral

```
Behavioral (STAR Method)
â”œâ”€ Situation
â”‚  â”œâ”€ Context and background
â”‚  â”œâ”€ Business metrics at the time
â”‚  â”œâ”€ Team and stakeholders
â”‚  â””â”€ Why this was important
â”‚
â”œâ”€ Task
â”‚  â”œâ”€ Your specific responsibility
â”‚  â”œâ”€ Goals and objectives
â”‚  â”œâ”€ Constraints (time, resources, data)
â”‚  â””â”€ Success criteria
â”‚
â”œâ”€ Action
â”‚  â”œâ”€ Approach and methodology
â”‚  â”œâ”€ Models/techniques used
â”‚  â”œâ”€ How you collaborated
â”‚  â”œâ”€ Challenges you overcame
â”‚  â””â”€ Iterations and improvements
â”‚
â””â”€ Result
   â”œâ”€ Quantifiable outcomes
   â”œâ”€ Business impact (revenue, efficiency, etc.)
   â”œâ”€ Model performance metrics
   â”œâ”€ What you learned
   â””â”€ How you'd apply it again
```

---

### Data Analysis - Root Cause

```
Data Analysis - Root Cause
â”œâ”€ Define the problem
â”‚  â”œâ”€ What metric changed?
â”‚  â”œâ”€ When did it change?
â”‚  â”œâ”€ How much did it change?
â”‚  â””â”€ Why does it matter?
â”‚
â”œâ”€ Form hypotheses
â”‚  â”œâ”€ Internal factors (product changes, bugs)
â”‚  â”œâ”€ External factors (seasonality, competition)
â”‚  â”œâ”€ User behavior changes
â”‚  â””â”€ Data quality issues
â”‚
â”œâ”€ Segment and drill down
â”‚  â”œâ”€ By time (hourly, daily, weekly)
â”‚  â”œâ”€ By user cohort (new vs returning)
â”‚  â”œâ”€ By platform (iOS, Android, web)
â”‚  â”œâ”€ By geography
â”‚  â””â”€ By feature usage
â”‚
â”œâ”€ Test hypotheses
â”‚  â”œâ”€ Gather supporting data
â”‚  â”œâ”€ Rule out alternatives
â”‚  â”œâ”€ Look for correlations
â”‚  â””â”€ Identify root cause
â”‚
â””â”€ Recommend action
   â”œâ”€ Fix the issue
   â”œâ”€ Prevent recurrence
   â”œâ”€ Monitor going forward
   â””â”€ Expected impact
```

---

### Machine Learning - Model Evaluation

```
Machine Learning - Model Evaluation
â”œâ”€ Choose appropriate metrics
â”‚  â”œâ”€ Classification: accuracy, precision, recall, F1, AUC-ROC
â”‚  â”œâ”€ Regression: RMSE, MAE, RÂ², MAPE
â”‚  â”œâ”€ Consider business context
â”‚  â””â”€ Class imbalance considerations
â”‚
â”œâ”€ Cross-validation
â”‚  â”œâ”€ K-fold cross-validation
â”‚  â”œâ”€ Stratified for imbalanced data
â”‚  â”œâ”€ Time series: forward chaining
â”‚  â””â”€ Report mean and std of metrics
â”‚
â”œâ”€ Bias-variance tradeoff
â”‚  â”œâ”€ Underfitting (high bias)
â”‚  â”œâ”€ Overfitting (high variance)
â”‚  â”œâ”€ Learning curves
â”‚  â””â”€ Regularization strategies
â”‚
â”œâ”€ Error analysis
â”‚  â”œâ”€ Confusion matrix
â”‚  â”œâ”€ Analyze misclassifications
â”‚  â”œâ”€ Feature importance
â”‚  â””â”€ Identify systematic errors
â”‚
â””â”€ Production considerations
   â”œâ”€ Model robustness
   â”œâ”€ Inference latency
   â”œâ”€ Model size
   â””â”€ Monitoring and retraining
```

---

### Coding

```
Coding
â”œâ”€ Understand the problem
â”‚  â”œâ”€ Read carefully
â”‚  â”œâ”€ Ask clarifying questions
â”‚  â”œâ”€ Identify inputs and outputs
â”‚  â”œâ”€ Constraints and edge cases
â”‚  â””â”€ Examples
â”‚
â”œâ”€ Plan the approach
â”‚  â”œâ”€ Brute force first
â”‚  â”œâ”€ Identify patterns
â”‚  â”œâ”€ Choose data structures
â”‚  â”œâ”€ Consider time/space complexity
â”‚  â””â”€ Outline algorithm
â”‚
â”œâ”€ Implement
â”‚  â”œâ”€ Write clean, readable code
â”‚  â”œâ”€ Use meaningful variable names
â”‚  â”œâ”€ Handle edge cases
â”‚  â”œâ”€ Add comments for clarity
â”‚  â””â”€ Test as you go
â”‚
â”œâ”€ Test
â”‚  â”œâ”€ Normal cases
â”‚  â”œâ”€ Edge cases (empty, single element)
â”‚  â”œâ”€ Large inputs
â”‚  â””â”€ Invalid inputs
â”‚
â””â”€ Optimize
   â”œâ”€ Time complexity
   â”œâ”€ Space complexity
   â”œâ”€ Code readability
   â””â”€ Discuss tradeoffs
```

---

### Data Analysis - Business Metrics

```
Data Analysis - Business Metrics
â”œâ”€ Understand the business
â”‚  â”œâ”€ Business model
â”‚  â”œâ”€ Key value drivers
â”‚  â”œâ”€ User journey
â”‚  â””â”€ Competitive landscape
â”‚
â”œâ”€ Define metrics
â”‚  â”œâ”€ North Star Metric
â”‚  â”œâ”€ Leading indicators
â”‚  â”œâ”€ Lagging indicators
â”‚  â”œâ”€ Input vs output metrics
â”‚  â””â”€ Guardrail metrics
â”‚
â”œâ”€ Measure and track
â”‚  â”œâ”€ Data sources
â”‚  â”œâ”€ Calculation methodology
â”‚  â”œâ”€ Frequency of measurement
â”‚  â”œâ”€ Dashboards and reports
â”‚  â””â”€ Alerts and thresholds
â”‚
â”œâ”€ Analyze trends
â”‚  â”œâ”€ Historical patterns
â”‚  â”œâ”€ Seasonality
â”‚  â”œâ”€ Growth rates
â”‚  â”œâ”€ Cohort analysis
â”‚  â””â”€ Segment comparisons
â”‚
â””â”€ Drive action
   â”œâ”€ Insights and recommendations
   â”œâ”€ Prioritize initiatives
   â”œâ”€ Set targets and goals
   â””â”€ Measure impact
```

---

### SQL

```
SQL
â”œâ”€ Understand requirements
â”‚  â”œâ”€ What question are we answering?
â”‚  â”œâ”€ What tables are involved?
â”‚  â”œâ”€ What's the grain of the output?
â”‚  â””â”€ Performance considerations
â”‚
â”œâ”€ Write the query
â”‚  â”œâ”€ SELECT appropriate columns
â”‚  â”œâ”€ FROM and JOIN tables
â”‚  â”œâ”€ WHERE to filter rows
â”‚  â”œâ”€ GROUP BY for aggregations
â”‚  â”œâ”€ HAVING to filter groups
â”‚  â””â”€ ORDER BY and LIMIT
â”‚
â”œâ”€ Use advanced features
â”‚  â”œâ”€ Window functions (ROW_NUMBER, RANK, LAG, LEAD)
â”‚  â”œâ”€ CTEs (WITH clause) for readability
â”‚  â”œâ”€ Subqueries
â”‚  â”œâ”€ CASE statements
â”‚  â””â”€ Date functions
â”‚
â”œâ”€ Optimize
â”‚  â”œâ”€ Use indexes effectively
â”‚  â”œâ”€ Avoid SELECT *
â”‚  â”œâ”€ Filter early (WHERE before JOIN)
â”‚  â”œâ”€ Limit result set
â”‚  â””â”€ Explain plan
â”‚
â””â”€ Validate
   â”œâ”€ Check for nulls
   â”œâ”€ Verify row counts
   â”œâ”€ Spot check results
   â””â”€ Test edge cases
```

---

### Machine Learning - Supervised

```
Machine Learning - Supervised
â”œâ”€ Understand the problem
â”‚  â”œâ”€ Business objective
â”‚  â”œâ”€ Prediction task (regression/classification)
â”‚  â”œâ”€ Success metrics
â”‚  â””â”€ Constraints
â”‚
â”œâ”€ Data preparation
â”‚  â”œâ”€ Feature engineering
â”‚  â”œâ”€ Handle missing data
â”‚  â”œâ”€ Encode categorical variables
â”‚  â””â”€ Train/validation/test split
â”‚
â”œâ”€ Model selection
â”‚  â”œâ”€ Linear models (regression, logistic)
â”‚  â”œâ”€ Tree-based (RF, XGBoost, etc.)
â”‚  â”œâ”€ Neural networks
â”‚  â””â”€ Consider complexity vs interpretability
â”‚
â”œâ”€ Training and tuning
â”‚  â”œâ”€ Hyperparameter optimization
â”‚  â”œâ”€ Cross-validation
â”‚  â”œâ”€ Regularization (L1/L2)
â”‚  â””â”€ Monitor for overfitting
â”‚
â””â”€ Evaluation
   â”œâ”€ Appropriate metrics (accuracy, precision, recall, RMSE, etc.)
   â”œâ”€ Confusion matrix / ROC curve
   â”œâ”€ Feature importance
   â””â”€ Business impact
```

---

### Statistics & Experimentation - A/B Testing

```
Statistics & Experimentation - A/B Testing
â”œâ”€ Design the experiment
â”‚  â”œâ”€ Define hypothesis (null and alternative)
â”‚  â”œâ”€ Choose primary metric
â”‚  â”œâ”€ Secondary and guardrail metrics
â”‚  â”œâ”€ Determine sample size (power analysis)
â”‚  â””â”€ Randomization strategy
â”‚
â”œâ”€ Run the test
â”‚  â”œâ”€ Ensure proper randomization
â”‚  â”œâ”€ Monitor for issues (SRM, bugs)
â”‚  â”œâ”€ Avoid peeking
â”‚  â””â”€ Collect sufficient data
â”‚
â”œâ”€ Analyze results
â”‚  â”œâ”€ Calculate statistical significance (p-value)
â”‚  â”œâ”€ Calculate confidence intervals
â”‚  â”œâ”€ Check for practical significance
â”‚  â”œâ”€ Segment analysis
â”‚  â””â”€ Check guardrail metrics
â”‚
â”œâ”€ Interpret findings
â”‚  â”œâ”€ Can we reject null hypothesis?
â”‚  â”œâ”€ Effect size and business impact
â”‚  â”œâ”€ Consider external factors
â”‚  â””â”€ Long-term vs short-term effects
â”‚
â””â”€ Make decision
   â”œâ”€ Ship, iterate, or kill
   â”œâ”€ Document learnings
   â””â”€ Plan next experiments
```

---

### Statistics & Experimentation - Probability

```
Statistics & Experimentation - Probability
â”œâ”€ Understand the problem
â”‚  â”œâ”€ What are we trying to find?
â”‚  â”œâ”€ What information is given?
â”‚  â””â”€ What assumptions can we make?
â”‚
â”œâ”€ Identify distribution
â”‚  â”œâ”€ Discrete: binomial, Poisson, geometric
â”‚  â”œâ”€ Continuous: normal, exponential, uniform
â”‚  â”œâ”€ Parameters (mean, variance, etc.)
â”‚  â””â”€ Assumptions and conditions
â”‚
â”œâ”€ Apply probability rules
â”‚  â”œâ”€ Addition rule (OR)
â”‚  â”œâ”€ Multiplication rule (AND)
â”‚  â”œâ”€ Conditional probability
â”‚  â”œâ”€ Bayes' theorem
â”‚  â””â”€ Independence
â”‚
â”œâ”€ Calculate
â”‚  â”œâ”€ Expected value
â”‚  â”œâ”€ Variance and standard deviation
â”‚  â”œâ”€ Confidence intervals
â”‚  â””â”€ Percentiles
â”‚
â””â”€ Interpret
   â”œâ”€ What does the result mean?
   â”œâ”€ Practical implications
   â””â”€ Uncertainty and assumptions
```

---

### Deep Learning

```
Deep Learning
â”œâ”€ Problem formulation
â”‚  â”œâ”€ Task type (classification, regression, generation)
â”‚  â”œâ”€ Data availability
â”‚  â”œâ”€ Computational resources
â”‚  â””â”€ Interpretability needs
â”‚
â”œâ”€ Architecture design
â”‚  â”œâ”€ Input layer (shape, preprocessing)
â”‚  â”œâ”€ Hidden layers (CNN, RNN, Transformer)
â”‚  â”œâ”€ Activation functions (ReLU, tanh, sigmoid)
â”‚  â”œâ”€ Output layer (softmax, linear)
â”‚  â””â”€ Number of parameters
â”‚
â”œâ”€ Training
â”‚  â”œâ”€ Loss function
â”‚  â”œâ”€ Optimizer (Adam, SGD)
â”‚  â”œâ”€ Learning rate schedule
â”‚  â”œâ”€ Batch size
â”‚  â”œâ”€ Regularization (dropout, batch norm)
â”‚  â””â”€ Early stopping
â”‚
â”œâ”€ Evaluation
â”‚  â”œâ”€ Validation metrics
â”‚  â”œâ”€ Learning curves
â”‚  â”œâ”€ Overfitting/underfitting
â”‚  â””â”€ Generalization
â”‚
â””â”€ Optimization
   â”œâ”€ Hyperparameter tuning
   â”œâ”€ Data augmentation
   â”œâ”€ Transfer learning
   â””â”€ Model compression
```

---


## ğŸ’¡ Final Tips

### For All Data Scientist Interviews:

1. **Start with the problem** - Understand business context before jumping to solutions
2. **Show your thinking** - Walk through your approach step-by-step
3. **Quantify everything** - Use metrics to evaluate success
4. **Consider tradeoffs** - Accuracy vs speed, complexity vs interpretability
5. **Connect to business** - How does this model drive value?

### Common Mistakes to Avoid:

- âŒ Jumping to complex models without understanding the problem
- âŒ Ignoring data quality and preprocessing
- âŒ Overfitting to training data
- âŒ Not considering production constraints
- âŒ Forgetting to communicate business impact

---

**Check out the [Data_Scientist_Question_Bank.md](./Data_Scientist_Question_Bank.md) for all questions with detailed frameworks!**
