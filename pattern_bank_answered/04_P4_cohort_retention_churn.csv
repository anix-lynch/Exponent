question_id,question_text,priority,pattern_id,pattern_name,solving_formula,notes,short_answer,short_answer
82,"As a Product Manager for Clickup, analyze the scenario of low return rate of new users and propose solutions to improve metrics such as return rate, average new user sign-up, and daily average usag...",ðŸŸ¢,P4,Cohort / Retention / Churn,Define Cohorts â†’ Measure Retention â†’ Identify Churn Drivers â†’ Hypothesize â†’ Fix,Retention problem; new user churn,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 churn â†’ onboarding/activation problem. Week 1 churn â†’ value not clear. Month 1+ churn â†’ habit/competition issue. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If users churn early (Day 0-1) â†’ activation gap, onboarding friction. If one cohort worse â†’ acquisition mismatch, targeting issue. If usage drops first â†’ value erosion, core loop not engaging. If late churn (Month 1+) â†’ lack of habit, missing retention hooks.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation: simplify first experience, show value faster, reduce friction. Tighten targeting: improve acquisition quality, align messaging with product value. Reinforce core value loop: ensure users complete key action early. Add retention hooks: email, push notifications, content recommendations. Measure cohort again: track if retention curve improved for next cohort.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 churn â†’ onboarding/activation problem. Week 1 churn â†’ value not clear. Month 1+ churn â†’ habit/competition issue. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If users churn early (Day 0-1) â†’ activation gap, onboarding friction. If one cohort worse â†’ acquisition mismatch, targeting issue. If usage drops first â†’ value erosion, core loop not engaging. If late churn (Month 1+) â†’ lack of habit, missing retention hooks.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation: simplify first experience, show value faster, reduce friction. Tighten targeting: improve acquisition quality, align messaging with product value. Reinforce core value loop: ensure users complete key action early. Add retention hooks: email, push notifications, content recommendations. Measure cohort again: track if retention curve improved for next cohort."
97,"As part of the Netflix PM team, how would we investigate the issue of one million active subscribers not logging into the platform?",ðŸŸ¢,P4,Cohort / Retention / Churn,Define Cohorts â†’ Measure Retention â†’ Identify Churn Drivers â†’ Hypothesize â†’ Fix,Engagement drop; inactive users,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If paying but inactive â†’ value not delivered, product-market fit gap. If specific cohort churns â†’ acquisition quality issue. If gradual decline â†’ habit not formed, engagement loop broken.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If paying but inactive â†’ value not delivered, product-market fit gap. If specific cohort churns â†’ acquisition quality issue. If gradual decline â†’ habit not formed, engagement loop broken.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
98,"As part of the Netflix PM team, how would you investigate the issue of 1 million inactive but paying users?",ðŸŸ¢,P4,Cohort / Retention / Churn,Define Cohorts â†’ Measure Retention â†’ Identify Churn Drivers â†’ Hypothesize â†’ Fix,Retention problem; paying but not using,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If paying but inactive â†’ value not delivered, product-market fit gap. If specific cohort churns â†’ acquisition quality issue. If gradual decline â†’ habit not formed, engagement loop broken.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If paying but inactive â†’ value not delivered, product-market fit gap. If specific cohort churns â†’ acquisition quality issue. If gradual decline â†’ habit not formed, engagement loop broken.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
715,Diagnose a 35% drop in retention on Salesforce.,ðŸŸ¢,P4,Cohort / Retention / Churn,Define Cohorts â†’ Measure Retention â†’ Identify Churn Drivers â†’ Hypothesize â†’ Fix,Retention drop; churn analysis,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
717,Diagnose a 40% increase in first month churn on HelloFresh.,ðŸŸ¢,P4,Cohort / Retention / Churn,Define Cohorts â†’ Measure Retention â†’ Identify Churn Drivers â†’ Hypothesize â†’ Fix,Churn increase; retention analysis,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1212,How might you improve Spotify using social features?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product improvement; social features,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1222,How should Adobe Creative Cloud target small businesses in Singapore?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Market expansion; product strategy,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1223,How should Google launch a new teleportation product?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product launch; hypothetical product,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1225,How should WeChat further expand into America?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Market expansion; product strategy,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1226,How should Yelp expand into Asia?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Market expansion; product strategy,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1230,How would Google enter the food delivery space?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Market entry; product strategy,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1231,How would Hoop expand into South America?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Market expansion; product strategy,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1232,How would Notion expand into Europe?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Market expansion; product strategy,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1233,How would Snapchat expand into Indonesia?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Market expansion; product strategy,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1234,How would Uber expand into the bicycle market?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Market expansion; product strategy,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1243,How would you approach a rebrand for an established product?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Rebranding; product strategy,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1245,How would you approach building a 3-year strategic plan for a new business unit?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Strategic planning; product strategy,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1246,How would you approach building proactive AI?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,AI product design; product strategy,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1257,How would you build a babysitter service for Facebook?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design; new product,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1258,How would you build a Facebook product for blood donation?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design; new product,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1259,How would you build a marketplace for DocuSign apps?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design; marketplace,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1260,How would you build a monitoring device for elderly people?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design; new product,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1261,How would you build a product for disabled users on LinkedIn?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design; accessibility,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1263,How would you build a shared laundry experience?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design; new product,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1267,How would you build an ad platform for Robinhood?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design; ad platform,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1268,How would you build an audio product for Facebook?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design; new product,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1270,How would you build any product using Gen AI?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design; AI product,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1271,How would you build out a feature for Viva Engage?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Feature design; product improvement,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1277,How would you compare Disney+ to Hulu?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product comparison; competitive analysis,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1281,How would you create a business around autonomous vehicles?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Business strategy; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1301,How would you design a coffee machine for use on the International Space Station?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design; space constraints,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1302,How would you design a game for a popular Netflix reality show?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design; game design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1303,How would you design a hyperlocal feature for Facebook?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Feature design; product improvement,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1304,How would you design a password management tool for children?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design; security,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1306,How would you design a Web browser to increase the sales of your ecommerce company?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design; revenue optimization,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1310,How would you design parking features on Google Maps?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Feature design; product improvement,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1311,How would you design the product experience of an ATM machine at an international airport.,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design; UX design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1312,How would you design the YouTube landing page?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design; UX design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1325,How would you disrupt the car wash industry?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Industry disruption; product strategy,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1326,How would you disrupt the film industry using YouTube?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Industry disruption; product strategy,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1327,How would you disrupt the travel industry?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Industry disruption; product strategy,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1331,How would you enhance Facebook comments?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Feature enhancement; product improvement,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1332,How would you enhance Google Maps for individuals with disabilities?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Accessibility; product improvement,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1333,How would you enhance Instagram Stories?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Feature enhancement; product improvement,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1334,How would you enhance the email notification experience for Facebook users who are tagged in photos?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Feature enhancement; product improvement,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1335,How would you enhance the experience for Airbnb users after a negative booking?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,User experience; product improvement,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1336,How would you enhance the Facebook Birthdays feature?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Feature enhancement; product improvement,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1347,How would you expand Capital One Shopping?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product expansion; growth strategy,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1348,How would you expand Fiverr into China?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Market expansion; product strategy,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1359,How would you future-proof the organization against industry disruption?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Strategic planning; product strategy,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1377,How would you identify and address different types of needs in mobile apps?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,User needs; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1382,How would you implement birth date capture for Meta?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Feature implementation; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1383,How would you implement safety features for Roblox's private messaging between players?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Safety features; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1384,How would you improve a water bottle?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1385,How would you improve airport layovers?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Experience improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1386,How would you improve airport passengers' experience to address the pain point of time spent at the airport?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Experience improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1387,How would you improve Amazon's homepage?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1388,How would you improve Apple Music?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1389,How would you improve ChatGPT?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1390,How would you improve Day One?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1393,How would you improve Facebook Marketplace?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1394,How would you improve Facebook's timeline?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1396,How would you improve Gmail?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1397,How would you improve Google Drive?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1398,How would you improve Google Maps?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1399,How would you improve Houseparty?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1400,How would you improve Houzz?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1401,How would you improve iOS for the next 3-5 years?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1402,How would you improve LinkedIn Messaging?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1403,How would you improve Netflix's Help experience using AI?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product improvement; AI integration,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1404,How would you improve Netflix?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1405,How would you improve OpenTable?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1407,How would you improve Patreon?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1411,How would you improve Rover?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1412,How would you improve shipment tracking on Amazon?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Feature improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1413,How would you improve Shopify for new merchants who have difficulty sourcing products to sell?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1414,How would you improve someone's dining experience?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Experience improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1415,How would you improve Spotify as a podcast app?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1416,How would you improve Spotify?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1417,How would you improve SSENSE?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1418,How would you improve Stripe Payments?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1420,How would you improve TED?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1421,How would you improve the Amazon shopping experience?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Experience improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1422,How would you improve the Capital One mobile app?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1423,How would you improve the Capital One website?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1425,How would you improve the DMV?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Experience improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1426,How would you improve the Doordash post-order experience?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Experience improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1427,How would you improve the experience at a DMV?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Experience improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1428,How would you improve the experience at amusement parks?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Experience improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1429,How would you improve the Facebook feed?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1430,How would you improve the Meta Horizon World product?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1431,How would you improve the movie watching experience?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Experience improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1432,How would you improve the NBA League Pass for basketball fans?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1433,How would you improve the parking experience as a product manager for Google Maps?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Experience improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1434,How would you improve the passenger experience at a major metropolitan airport?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Experience improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1435,How would you improve the Pinterest experience?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1436,How would you improve the post-booking experience for TaskRabbit?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Experience improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1437,How would you improve the quality of Airbnb over the next six months?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1438,How would you improve the search function on Walmart.com?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Feature improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1439,How would you improve the Spotlight feature at Snapchat?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Feature improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1441,How would you improve the worst post-booking experience at an airline?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Experience improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1442,How would you improve the worst post-booking experience for OpenTable?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Experience improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1443,How would you improve Uber Eats?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1444,How would you improve Uber?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1446,How would you improve Venmo? What features would you build and why?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1447,How would you improve walmart.com?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1448,How would you improve your favorite music application?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1449,How would you improve your favorite product?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1450,How would you improve YouTube?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1452,How would you improve Zoom?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1471,How would you integrate social features into the Coinbase platform?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Feature integration; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1474,How would you launch a Copilot Plus feature in Surface?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Feature launch; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1475,How would you launch a new product in the blue-collar service industry?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product launch; product strategy,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1476,How would you launch a new product to our existing user base?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product launch; product strategy,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1477,How would you launch a product for a digital library as a Google PM?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product launch; product strategy,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1478,How would you launch a product for the proactivity space in Gemini?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product launch; product strategy,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1479,How would you launch a scheduled rides feature for Uber or Lyft?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Feature launch; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1480,How would you launch Amazon in Nigeria?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Market expansion; product strategy,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1481,How would you launch Instagram Reels?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product launch; product strategy,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1526,How would you position a new B2B SaaS product?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product positioning; product strategy,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1543,How would you re-architect WordPerfect as a PM to increase its market share?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product redesign; product strategy,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1545,How would you redesign Instagram's DM feature?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Feature redesign; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1547,How would you redesign the gas station experience?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Experience redesign; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1548,How would you redesign the worst experience on Ticketmaster to improve it?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Experience redesign; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1570,How would you solve traffic congestion in Seattle?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Problem solving; product strategy,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1586,Identify a product with untapped potential. Propose three new features for this product and outline how you would assess their effectiveness.,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product ideation; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1587,Identify any pain points you've experienced using an airline's mobile app. How would you address them?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Pain point identification; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1596,"If Facebook wants to enter the podcast space, what would you build?",ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design; new product,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1599,"If Google wants to enter the market for helping people find lost belongings, what should the product look like, and should it be built?",ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design; new product,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1602,"If Mark Zuckerberg asked you to create a product for athletes, what would you build?",ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design; new product,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1605,"If the CEO of Google asks for a product that allows meetings in person, what would you create for the next 5-10 years?",ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design; new product,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1609,"If WhatsApp becomes the default OS communication layer, how should Android respond?",ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Strategic response; product strategy,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1616,"If you had $1 billion, what would you build using generative AI?",ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product ideation; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1618,"If you had a teleportation device, how would you build a product from it?",ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product ideation; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1619,"If you had access to 20 years of geo-related data, such as street view and satellite imagery, what product would you build?",ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product ideation; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1622,"If you had unlimited resources at Google, what would you build and why?",ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product ideation; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1624,"If you have allocated budget, how would you solve the climate crisis problem?",ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Problem solving; product strategy,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1630,"If you were PM for Twitter Spaces, how would you improve it?",ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1632,"If you were the PM for the search results page, how would you design the relevance?",ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Search design; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1638,Imagine the providers of Google Glass reduced the production cost to $10; what actions would you take?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Cost change response; product strategy,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1641,Imagine you are a PM at Amazon and Walmart is entering your country. How would you respond?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Competitive response; product strategy,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1645,Imagine you're a PM for Alaska Airlines. How would you improve the in-flight experience for customers?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Experience improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1646,Imagine you're a PM for Facebook. Design a product for teens.,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design; new product,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1647,Imagine you're a PM for Meta. Design a product for hobbyists (eg. gardening),ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design; new product,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1648,Imagine you're a PM for Meta. Design a product for Volunteering. What would you build? Why?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design; new product,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1650,Imagine you're a startup founder and a VC asked you to build a company in the space of an AI career coaching. What would you build?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design; new product,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1682,Improve Discord.,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1683,Improve Facebook's Crisis Alert feature.,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Feature improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1684,Improve Google Maps for group travel.,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1685,Improve how Slack enables collaboration.,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1686,Improve Pinterest.,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1687,Improve StubHub.,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1688,Improve the Apple Watch.,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1689,Improve the Oculus Go.,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1690,Improve the Oculus Store.,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1691,Improve the post-booking experience for Turo.,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Experience improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1692,Improve the seller drop-off experience on the GOAT app.,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Experience improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1693,Improve the worst post-booking experience for Ticketmaster.,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Experience improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1694,Improve the worst post-booking experience for United Airlines.,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Experience improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1719,List four of your favorite Google products. What are some challenges one of them might face?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product analysis; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1720,List improvements for Evernote.,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1723,"List three products you're fond of and knowledgeable about. Choose one to explain why you like it, and outline your approach to tailoring this product for a new market segment.",ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product adaptation; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1727,"Lyft wants to invest in vertical take-off vehicles that can fit up to 4 people. How should we approach the market, who should be our target audience, and what features should we prioritize in our p...",ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product strategy; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1740,Meta wants to build a product for handymen like plumbers and carpenters. How would you design it?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design; new product,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1749,"Name three bad products. Then, pick one to improve.",ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1763,Pick a random object in your room. How would you redesign it?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product redesign; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1778,Product Sense - Build a product for sports.,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design; new product,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1779,Propose a new feature for Perplexity.,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Feature proposal; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1784,Redesign a DMV system.,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,System redesign; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1785,Redesign a TV remote control.,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product redesign; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1786,Redesign Google Maps to increase engagement with small businesses.,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product redesign; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1787,Redesign the airport experience.,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Experience redesign; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1788,Reinvent a backpack with 10 new features.,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product reinvention; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1789,Reinvent a pillow with 10 new features.,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product reinvention; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1790,Reinvent a trashcan with 10 new features.,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product reinvention; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1817,"Should Google enter the Metaverse space? If so, how?",ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Market entry; product strategy,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1831,"Should Uber launch an 'Uber for Kids' service? If so, how would you design it?",ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design; new product,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1852,Tell me about a bad experience you had with a low-tech product.,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product critique; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1865,Tell me about a popular product you use. How would you design a competitor and what features would you prioritize?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Competitive design; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1878,Tell me about a SaaS product you really like using.,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product analysis; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1884,Tell me about a software product that you recently had a bad experience with and why you felt that way as a user.,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product critique; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1904,Tell me about a time when you created a product or feature without the client requesting it.,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Proactive product; behavioral question,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1983,Tell me about a time when you redesigned the interface of clinical trial software for enhanced user simplicity.,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Interface redesign; behavioral question,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
1999,Tell me about a time when you used customer feedback to drive innovation.,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Customer-driven innovation; behavioral question,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2027,Tell me about a time where you ideated and launched a strategy from scratch.,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Strategy launch; behavioral question,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2030,Tell me about a time you anticipated the needs of a customer.,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Customer anticipation; behavioral question,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2100,Tell me about an idea you came up with and followed through to implementation.,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Idea implementation; behavioral question,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2117,Tell me about your design process.,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Design process; behavioral question,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2124,Tell me about your experience with product launches in international markets.,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,International launch; behavioral question,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2131,Tell me about your favorite application. How would you build or integrate it within the Facebook platform?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product integration; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2132,Tell me about your favorite product.,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product analysis; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2133,Tell me about your favorite product. How would you build its competitor?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Competitive design; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2151,Tell us about an app you don't like to use. How would you improve the app?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2153,The CEO asks you to design a new ATM specifically for their airport segment. What would you do?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design; new product,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2173,"Uber is planning to launch a shuttle service in Bangalore, India. How should Uber go about it and which key metrics should they track to measure success?",ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product launch; product strategy,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2174,Uber is planning to launch ride services for children aged 8-12 years in India. What factors would you consider given that kids of this age won't have mobile access? What modifications would you su...,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design; new product,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2194,What are 4 features you would build for Netflix?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Feature ideation; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2196,What are general applications for AI within customer support?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,AI applications; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2209,What are the company's pain points of your favorite product?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product analysis; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2217,"What are the key differences between Tiktok, Instagram, and Youtube?",ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product comparison; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2226,What are the most important industry trends right now? What strategy would you pursue if you were leading Voodoo in the next 5 years?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Industry trends; product strategy,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2231,What are the strengths and challenges of Google Play?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product analysis; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2237,What are three consumer apps you use regularly and why?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product analysis; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2249,What are your top three favorite apps? How would you improve one of them?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2253,What can we do with internet speeds in the terabytes in the future?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Future technology; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2266,What do you like about Airbnb?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product analysis; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2290,What factors would you consider when planning a strategy for a new feature for contractors and freelancers?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Feature strategy; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2293,What frameworks do you use for product positioning?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product positioning; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2306,What industry do you think could benefit the most from enterprise ChatGPT?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Industry analysis; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2311,What is a non-technical product you frequently use? How would you improve it?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2317,What is an example of a poorly designed product? How would you improve it?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product critique; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2329,What is the current strategy of 15-minute delivery apps?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Strategy analysis; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2339,What is the impact of AI search?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,AI impact; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2351,What is the product that you dislike the most and why?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product critique; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2358,What is your approach to competitive analysis?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Competitive analysis; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2362,What is your favorite Amazon product?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product analysis; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2363,What is your favorite app on your phone?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product analysis; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2364,What is your favorite Facebook product and why?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product analysis; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2365,What is your favorite Google product and how would you improve it?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2368,"What is your favorite Microsoft product, what do you dislike about it, and how would you improve it?",ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2369,What is your favorite music app and why?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product analysis; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2370,What is your favorite non-Google product and how would you improve it?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2371,What is your favorite physical product?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product analysis; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2372,What is your favorite product and why? How would you improve it? What considerations and metrics would be involved in rolling out these improvements?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2373,What is your favorite Slack feature?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Feature analysis; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2376,"What is your least favorite product among the ones you use, and how would you improve it?",ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2379,What is your process for conducting customer research?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Customer research; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2380,What is your process for crafting effective user stories? What practices have you found beneficial?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,User stories; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2382,What is your product ideation process?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product ideation; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2415,What other areas could Lemonade expand into?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Market expansion; product strategy,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2417,What parameters would you consider when designing UberPool?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design; new product,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2421,What pre-work do you need to do for Google to enter a new bicycle business targeting children?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Market entry; product strategy,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2422,What problems could an MVP app solve?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,MVP ideation; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2424,What product do you think has good UX design and why?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,UX analysis; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2425,What product should Apple announce at their next Keynote?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product ideation; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2426,What product should Google build next?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product ideation; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2436,What should America do about TikTok?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Policy/product strategy; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2438,What should LinkedIn build next?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product ideation; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2441,What strategic pillars will you use to keep Maps data fresh through user-generated content?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Data freshness; product strategy,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2454,What two new features would you add to a car garage?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Feature ideation; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2456,What type of travel product would you build for Facebook?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design; new product,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2462,What would be your strategy to improve Google Maps as a product?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2463,What would change if internet speed were 100 times faster than today?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Future technology; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2465,"What would you build and why? Run through an end-to-end ""moonshot""-style example.",ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Moonshot product; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2467,What would you do if a competitor launched a product before you?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Competitive response; product strategy,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2474,What would you do if you were the PM for Ticketmaster's post-booking experience?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design; experience improvement,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2478,What would you suggest to make the iPhone the safest cellphone in the market?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2480,"What's a collaboration product your teams use, and why do you like it?",ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product analysis; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2485,What's the biggest threat to YouTube?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Threat analysis; product strategy,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2503,What's your favorite digital or hardware product and why?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product analysis; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2504,What's your favorite e-commerce store?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product analysis; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2505,What's your favorite enterprise app?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product analysis; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2507,What's your favorite food ordering app?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product analysis; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2508,What's your favorite marketplace app?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product analysis; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2509,What's your favorite non-tech product that you use frequently?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product analysis; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2510,What's your favorite product and why?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product analysis; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2511,What's your favorite subscription-based product?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product analysis; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If paying but inactive â†’ value not delivered, product-market fit gap. If specific cohort churns â†’ acquisition quality issue. If gradual decline â†’ habit not formed, engagement loop broken.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If paying but inactive â†’ value not delivered, product-market fit gap. If specific cohort churns â†’ acquisition quality issue. If gradual decline â†’ habit not formed, engagement loop broken.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2528,Where do you see the 15-minute delivery app in the next five years?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Future vision; product strategy,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2530,Where should the company launch next?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Market expansion; product strategy,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2533,Which enterprise product do you look up to?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product analysis; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2537,Which vertical should Facebook go into next?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Market expansion; product strategy,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2538,Who are TikTok's competitors?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Competitive analysis; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2567,"Why do you like ChatGPT? Who are its users, what metrics would you use to track its success, and how would you improve it?",ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product analysis; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2615,Why does Google Maps exist? What are its opportunities and threats?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product strategy; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2616,Why has Google Maps been so successful and what would you build next on this platform?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product strategy; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2621,Why is it important for users to complete their LinkedIn profile? Discuss both user and enterprise perspectives.,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product strategy; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2624,"Why should Meta invest in noise-cancelling headphones, and what goals would you set for this product?",ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product strategy; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2635,Would you port Facebook rooms to Instagram?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product strategy; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2652,You are a Google PM in charge of the next Android keynote product announcement in 3 years. What would you build?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design; new product,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2659,"You are a PM at Netflix, design a podcast for Netflix.",ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design; new product,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2660,You are a PM at Swiggy. What would you build for health conscious users?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design; new product,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2661,You are a PM at Uber. Which market should Uber expand into next?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Market expansion; product strategy,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2664,You are a startup with the technology that translates speech/text to animal language. How do you take this to market?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Go-to-market; product strategy,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2665,"You are an editor managing a voice-dubbing project currently tracked in Excel. Design a new interface to review progress, manage feedback, and collaborate with voice actors.",ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design; new product,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2666,You are at a well-funded startup. Design a solution to solve the problem of parking.,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design; new product,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2680,You are the PM for the payments team at Booking.com. How would you introduce cryptocurrency as a new payment method?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Payment feature; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2682,You are working for a retail company that wants to improve user engagement on a telemedicine platform by leveraging their retail data. What is your approach?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Engagement improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2683,You are working for a startup to build a product for volunteering.,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design; new product,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2686,You have 3 years to make X the best in the world. What strategy would you implement?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product strategy; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2690,You have text-to-music capabilities. How would you productize it?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design; new product,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2694,"You just found a magical artifact that predicts the weather for the next 30 days. As a Google PM, what actions would you take?",ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design; new product,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2699,You received user feedback that Yelp's restaurant recommendation is not personal enough. What would you do?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Personalization; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2708,You're a financial security product PM. How would you use AI to enhance security across banking systems?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2710,You're a growth PM for Chrome Browser. Design a 3-year strategy for the browser.,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2711,You're a leader at DoorDash. What should DoorDash build next?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2713,"You're a PM at a big tech company. You have a product launch in one week, however, the legal team just flagged 100+ potential issues. What would you do?",ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2714,You're a PM at a company focused on the grocery shopping experience. How would you build a grocery shopping experience for a couple?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2716,"You're a PM at a pharma company; your product helps cows produce 20% more milk, lasting a month. What pricing strategy and price would you set for the product?",ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2718,"You're a PM at a Tech Startup focused on food delivery for companies, what would you design?",ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2721,You're a PM at Airbnb. Design furniture.,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2727,You're a PM at an elevator construction company. Design an elevator for a client.,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2730,You're a PM at Capital One. How do you measure financial gains or losses in the first year after launching a new product?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2735,You're a PM at Google. Which product would you choose to work on?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2740,You're a PM at Instagram responsible for building the Reels feature. How would you define and measure its success?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2743,You're a PM at LinkedIn. Design features to support India's growing startup ecosystem.,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2747,You're a PM at Meta. Design a product for musicians.,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2748,You're a PM at Meta. Design a product for skill sharing.,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2749,You're a PM at Meta. Design a product for users to find a handyman.,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2754,"You're a PM at Meta. How would you measure the success of the 'Report Ad' feature for Ads, considering false positives and false negatives?",ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2755,You're a PM at Meta. What product or feature would you build for small or local businesses?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2759,You're a PM at Nvidia. How would you keep Nvidia's product lineup competitive?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2761,You're a PM at Spotify considering adding a feature for artists to go live. Should you invest in this?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2765,You're a PM at Swiggy. How would you design a new segment for liquor on Instamart?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2768,You're a PM at Trader Joe's and you find that sales revenues are down. Design the experience for users based on competitors like Blue Apron.,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2771,You're a PM at Uber; design a smartwatch app.,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2773,You're a PM at WhatsApp tasked with increasing user engagement. What features will you build and how will you prioritize and evaluate them?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2775,You're a PM at Wikipedia. What product should you build next?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2780,You're a PM for a household device. What three features would you recommend and why?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2781,You're a PM for a large car manufacturer. Should the company use Generative AI or large language models in its products and workflows?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2782,"You're a PM for a new device, which is a time machine. How would you design the interface?",ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2787,You're a PM for Amazon Fulfillment. Your goal is to save warehouse space by optimizing SKUs. How would you recommend similar products to customers on Amazon Prime?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2792,You're a PM for Facebook Group Travel on mobile. What would you build?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2793,You're a PM for Facebook Sports. What would you build?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2794,You're a PM for Facebook Travel. What would you build?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2796,You're a PM for Gmail. Design a three-year product roadmap.,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2797,You're a PM for Gmail. How would you react to a competing product?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2799,You're a PM for Google Chrome on large screens. Build the three-year innovation roadmap.,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2800,You're a PM for Google News. What would be your product strategy for the upcoming year?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2801,You're a PM for Google Search. How would you grow this product?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2810,You're a PM for Maps. What product would you build in Maps specifically for farmers?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2811,"You're a PM for Max, HBO's video streaming service. Roku wants to include an HBO button on their new remote control. How much should HBO pay for this feature?",ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2812,You're a PM for Meta releasing a new Jobs feature in 2 weeks. How will you measure the success of this product in the short and long term?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2815,You're a PM for Meta. Design a product for group travel.,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2816,You're a PM for Meta. How would you build a product that helps users find handypeople?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2821,You're a PM for sponsored product ads. How would you improve the fill rate on listings pages?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2824,You're a PM for Tesla. Design the Tesla app for the Apple Watch.,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2828,You're a PM for Walmart building a new fulfillment center. What products would you stock?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2829,You're a PM in the middle of a sprint when a P1 issue arises that impacts the sprint goal due to requirements and design problems. How would you handle this?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2834,"You're a PM with two engineers, and enterprise customers won't adopt your product due to an unclear roadmap. Your engineers are already working hard on a task outlined. What would you do?",ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2836,You're a product manager at Meta. Design a product for hyperlocal experiences.,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2838,You're an Apple product manager. How would you determine the ideal length of the iPhone charging cable?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2841,You're designing an A/B test to evaluate the impact of showing content from non-friends in users' feeds. How would you test this with proper randomization?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2848,You're on the LA 2028 Olympic Games organizing committee. What product would you build?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2849,You're PM at Meta. Design a fundraising product for a cause.,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2851,"You're redesigning Capital One's Instant Push Notifications (IPN) system, moving from multiple screens to a single view. How would you improve the user experience?",ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2853,You're the CEO of an AI startup. Google offers you $1B in funding. What product would you build?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2854,You're the CEO or VP of your favorite product. How would you structure your organization and why?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2856,"You're the first product manager at a new startup that has invented teleportation, currently working between two small rooms. What would you do first?",ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2860,"You're the PM for 99 Deliveries, the logistics branch of 99 in Brazil. How would you define success for this product?",ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2869,You're the PM for Meta's Social Good team. Design a new product to encourage more volunteering.,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2870,You're the PM for one of your favorite products. What is your strategy for the next year?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2871,"You're the PM for our stock trading product. With gross profit dropping significantly over the last month, what would you do?",ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2872,You're the PM for Safeway. What product would you build to better serve people's needs?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2875,"You're the PM of a stock trading app like Fidelity or Zerodha. To increase the number of customers who complete their first trade after installing the app, what two new features would you launch?",ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2878,You're the PM of the Apple Watch; how would you design it?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2879,You're the Product Manager at Beacon. What would you do to build an in-app chat feature?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2883,"Your company excels in display technology, while a dominant market player, like Qualcomm, excels in System on Chip. How would you convince this major player to purchase your product?",ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2884,Your largest customer is advocating for a new feature not in your roadmap. What do you do?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2885,"Your recently launched feature isn't meeting customer expectations, but your engineering team and roadmap are at capacity. How would you address this?",ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2889,Youâ€™re given product adoption data across regionsâ€”how would you determine where the rollout was most successful and why?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
2890,Youâ€™re launching a new featureâ€”how would you measure its strategic impact on growth?,ðŸŸ¢,P4,Product Design,User Needs â†’ Jobs-to-be-Done â†’ Features â†’ Prioritize â†’ Test,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.","Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements."
