question_id,question_text,priority,pattern_id,pattern_name,solving_formula,notes,short_answer,design_subtype
3.3,How would you improve the LinkedIn home page?,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product improvement; homepage optimization,"NSM: Identify the single most important metric that represents success. This should be the one number that best captures user value + business value combined.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior: sessions per user, click-through rate, time on page. Content quality: relevance score, engagement depth. Monetization: conversion rate, revenue per session.

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
31,"As a Facebook PM, what would you do to design a product for hobbies?",ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; hobbies focus,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
32,"As a Google PM, how would you design a solution to enhance financial savviness for users?",ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; financial education,"NSM: Define one North Star metric that best represents user + business value. Example: Monthly Active Users with Transactions or Financial Health Score.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User financial safety, regulatory compliance, fraud prevention. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
38,"As a PM at a teleconferencing company, design a product for working from home.",ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; WFH focus,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
39,"As a PM at a vending machine company, design a new line of vending machines for hotels and motels.",ðŸŸ¢,P13,Product Design,User Context â†’ Pain Points â†’ Core Design â†’ Tradeoffs â†’ Risks,Product design; vending machines,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13A_Conceptual_Consumer
45,"As a PM at Meta, design a product for making restaurant reservations.",ðŸŸ¢,P13,Product Design,Sides â†’ Value Exchange â†’ Liquidity Risks â†’ MVP â†’ Balancing Levers,Product design; reservations,"NSM: Define one North Star metric that best represents user + business value. Example: Weekly Successful Bookings or Booking Completion Rate.

Input KPIs: Break NSM into 3-5 controllable drivers. Discovery: search relevance, listing quality, availability. Conversion: booking completion rate, payment success. Supply: inventory quality, partner reliability.

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13D_Marketplace_TwoSided
49,"As a PM at Microsoft, design a B2B customer support product for them.",ðŸŸ¢,P13,Product Design,User vs Buyer â†’ Workflow Pain â†’ MVP â†’ Adoption Risks â†’ Success Metrics,Product design; B2B support,"NSM: Define one North Star metric that best represents user + business value. Example: Issue Resolution Rate or Customer Satisfaction Score.

Input KPIs: Break NSM into 3-5 controllable drivers. Resolution: first-contact resolution, time to resolve. Quality: customer satisfaction, issue recurrence. Efficiency: tickets per agent, automation rate.

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13C_B2B_Enterprise
50,"As a PM at Netflix, design something for kids.",ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; kids focus,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
53,"As a PM at Slack, how would you redesign the product to enter the education sector?",ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Market expansion; education sector pivot,"NSM: Define one North Star metric that best represents user + business value. Example: Weekly Active Learners or Course Completion Rate.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
65,"As a PM for JPMorgan Chase's Payments Developer Portal, design a new feature to improve customer adoption.",ðŸŸ¢,P13,Product Design,User vs Buyer â†’ Workflow Pain â†’ MVP â†’ Adoption Risks â†’ Success Metrics,Feature design; adoption focus,"NSM: Define one North Star metric that best represents user + business value. Example: Issue Resolution Rate or Customer Satisfaction Score.

Input KPIs: Break NSM into 3-5 controllable drivers. Resolution: first-contact resolution, time to resolve. Quality: customer satisfaction, issue recurrence. Efficiency: tickets per agent, automation rate.

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13C_B2B_Enterprise
66,"As a PM for Mastercard, design a product for restaurants to switch to a purchase order system that reduces labor costs.",ðŸŸ¢,P13,Product Design,User vs Buyer â†’ Workflow Pain â†’ MVP â†’ Adoption Risks â†’ Success Metrics,B2B product design; cost reduction,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13C_B2B_Enterprise
70,"As a PM for the health team at Meta, design a product for tissue donation.",ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; healthcare focus,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
71,"As a PM for TikTok, design the user journey for third-party services (e.g., restaurants and shops) integrated into the app.",ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,User journey design; third-party integration,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
78,"As a product manager at OpenAI, build an enterprise product.",ðŸŸ¢,P13,Product Design,User vs Buyer â†’ Workflow Pain â†’ MVP â†’ Adoption Risks â†’ Success Metrics,Enterprise product design,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13C_B2B_Enterprise
83,"As a product manager for Meta, design a product for volunteers.",ðŸŸ¢,P13,Product Design,Sides â†’ Value Exchange â†’ Liquidity Risks â†’ MVP â†’ Balancing Levers,Product design; volunteer platform,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13D_Marketplace_TwoSided
84,"As a Product Manager for Meta, what product would you create to address climate change?",ðŸŸ¢,P13,Product Design,Vision â†’ User Segments â†’ Strategic Bets â†’ Phasing â†’ Risks,Product design; climate focus,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13E_Strategy_Vision
126,"Based on the latest AI news, what ideas do you have that are one step beyond what exists today?",ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product ideation; AI innovation,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
127,Brainstorm a product idea with the help of AI.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product ideation; AI-assisted brainstorming,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
133,"Build a product automating a three-way matching system for the Procure-to-Pay process, including exceptions handling.",ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; B2B automation,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
134,Build a product for art lovers.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product ideation; art platform,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
135,Build a sushi factory that sells wholesale sushi boxes.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; food service,"NSM: Identify the single most important metric that represents success. This should be the one number that best captures user value + business value combined.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
136,Build a table management system.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; restaurant system,"NSM: Identify the single most important metric that represents success. This should be the one number that best captures user value + business value combined.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
138,Build your own customer service AI agent for a hypothetical outdoors company.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; AI customer service,"NSM: Identify the single most important metric that represents success. This should be the one number that best captures user value + business value combined.

Input KPIs: Break NSM into 3-5 controllable drivers. Resolution: first-contact resolution, time to resolve. Quality: customer satisfaction, issue recurrence. Efficiency: tickets per agent, automation rate.

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
180,Create an app to increase reading.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product ideation; reading app,"NSM: Identify the single most important metric that represents success. This should be the one number that best captures user value + business value combined.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
186,Define a 1-year roadmap for WhatsApp in India.,ðŸŸ¢,P13,Product Design,Vision â†’ User Segments â†’ Strategic Bets â†’ Phasing â†’ Risks,Roadmap planning; market strategy,"NSM: Identify the single most important metric that represents success. This should be the one number that best captures user value + business value combined.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13E_Strategy_Vision
187,Define a 10-year roadmap for Google Maps.,ðŸŸ¢,P13,Product Design,Vision â†’ User Segments â†’ Strategic Bets â†’ Phasing â†’ Risks,Long-term roadmap; strategic planning,"NSM: Identify the single most important metric that represents success. This should be the one number that best captures user value + business value combined.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13E_Strategy_Vision
253,Design a 'maker-checker' feature in a finance platform where each manual action requires two individuals: the executor and the approver.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Feature design; finance platform,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
255,Design a banking app for kids.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; banking for kids,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
257,Design a better alarm clock.,ðŸŸ¢,P13,Product Design,User Context â†’ Pain Points â†’ Core Design â†’ Tradeoffs â†’ Risks,Product design; alarm clock,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13A_Conceptual_Consumer
258,Design a better dog bowl.,ðŸŸ¢,P13,Product Design,User Context â†’ Pain Points â†’ Core Design â†’ Tradeoffs â†’ Risks,Product design; pet product,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13A_Conceptual_Consumer
259,Design a better dog collar.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; pet product,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
260,Design a better experience for attending large events. How would you implement and test it? What would the user experience look like?,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; event experience,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
261,Design a better grocery shopping experience.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; grocery shopping,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
262,Design a betting/auction platform for auction houses.,ðŸŸ¢,P13,Product Design,Sides â†’ Value Exchange â†’ Liquidity Risks â†’ MVP â†’ Balancing Levers,Product design; auction platform,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13D_Marketplace_TwoSided
263,Design a bike program for Google's Mountain View campus.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; campus program,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
264,Design a bike-sharing system for your city.,ðŸŸ¢,P13,Product Design,Sides â†’ Value Exchange â†’ Liquidity Risks â†’ MVP â†’ Balancing Levers,Product design; bike sharing,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13D_Marketplace_TwoSided
265,Design a birthday app for Facebook.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; social app,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
266,Design a birthday app.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; birthday app,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
267,Design a bookshelf for children.,ðŸŸ¢,P13,Product Design,User Context â†’ Pain Points â†’ Core Design â†’ Tradeoffs â†’ Risks,Product design; furniture,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13A_Conceptual_Consumer
268,Design a bookshelf for elderly people.,ðŸŸ¢,P13,Product Design,User Context â†’ Pain Points â†’ Core Design â†’ Tradeoffs â†’ Risks,Product design; furniture for elderly,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13A_Conceptual_Consumer
269,Design a bookshelf.,ðŸŸ¢,P13,Product Design,User Context â†’ Pain Points â†’ Core Design â†’ Tradeoffs â†’ Risks,Product design; furniture,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13A_Conceptual_Consumer
270,Design a camera for Instagram users.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; camera,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
271,Design a camera for the elderly.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; camera for elderly,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
272,Design a car for seniors.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; automotive,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
273,Design a car stereo.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; car audio,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
274,Design a cashless candy dispensing machine.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; vending machine,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
275,Design a cereal dispenser.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; kitchen appliance,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
276,Design a chair for the disabled.,ðŸŸ¢,P13,Product Design,User Context â†’ Pain Points â†’ Core Design â†’ Tradeoffs â†’ Risks,Product design; accessibility,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13A_Conceptual_Consumer
277,Design a chess board and a Netflix recommendation engine.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; mixed question,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
278,Design a clock for children.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; clock,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
281,Design a cookbook app.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; cookbook app,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
282,Design a credit card module for kids.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; financial product for kids,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
300,Design a digital library to encourage kids to read.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; education platform,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
308,Design a Facebook app to connect users with handymen.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; marketplace platform,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
310,Design a fashion product for Facebook.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; fashion platform,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
311,Design a feature to locate items.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Feature design; location tracking,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
314,Design a file upload feature for an AI chat application.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Feature design; file upload,"NSM: Define one North Star metric that best represents user + business value. Example: Daily Active Conversations or Messages per User.

Input KPIs: Break NSM into 3-5 controllable drivers. Adoption: active conversations, message volume. Quality: response time, message relevance. Engagement: daily active users, conversation depth.

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
315,Design a financial app aimed at college students.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; financial app,"NSM: Define one North Star metric that best represents user + business value. Example: Monthly Active Users with Transactions or Financial Health Score.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User financial safety, regulatory compliance, fraud prevention. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
316,Design a financial product for kids.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; financial product for kids,"NSM: Define one North Star metric that best represents user + business value. Example: Monthly Active Users with Transactions or Financial Health Score.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User financial safety, regulatory compliance, fraud prevention. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
317,Design a fire alarm for the deaf.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; accessibility,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
318,Design a fitness app for Facebook.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; fitness app,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
319,Design a fitness app.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; fitness app,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
321,Design a food delivery app for restaurant owners and food vendors.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; food delivery,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
323,Design a food pickup app for Yelp engineers.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; food pickup,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
326,Design a fundraising product.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; fundraising,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
327,Design a garage door opener.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; IoT device,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
328,Design a gardening product for Meta.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; gardening,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
330,Design a Google Nest/Home for an elderly person.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; smart home for elderly,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
331,Design a Google Pixel Tablet for restaurants.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; tablet for restaurants,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
332,Design a Google product for individuals living in retirement homes.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; retirement homes,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
333,Design a Google product for the elderly.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; elderly users,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
334,Design a Google-branded inflight entertainment system.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; inflight entertainment,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
335,Design a grocery delivery mobile app.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; grocery delivery,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
336,Design a grocery list app.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; grocery list,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
337,Design a group chat application.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; messaging app,"NSM: Define one North Star metric that best represents user + business value. Example: Daily Active Conversations or Messages per User.

Input KPIs: Break NSM into 3-5 controllable drivers. Adoption: active conversations, message volume. Quality: response time, message relevance. Engagement: daily active users, conversation depth.

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
340,Design a hair comb for elderly (aged over 65).,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; accessibility,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
341,Design a health app within the Microsoft ecosystem.,ðŸŸ¢,P13,Product Design,User vs Buyer â†’ Workflow Pain â†’ MVP â†’ Adoption Risks â†’ Success Metrics,Product design; health app,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13C_B2B_Enterprise
342,Design a healthcare product for Meta.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; healthcare,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
343,Design a high-tech gym.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; fitness facility,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
344,Design a kayak rental service.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; rental service,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
346,Design a kitchen.,ðŸŸ¢,P13,Product Design,User Context â†’ Pain Points â†’ Core Design â†’ Tradeoffs â†’ Risks,Product design; kitchen,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13A_Conceptual_Consumer
348,Design a language learning app for Meta.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; education app,"NSM: Define one North Star metric that best represents user + business value. Example: Weekly Active Learners or Course Completion Rate.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
349,Design a lawn mower.,ðŸŸ¢,P13,Product Design,User Context â†’ Pain Points â†’ Core Design â†’ Tradeoffs â†’ Risks,Product design; lawn mower,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13A_Conceptual_Consumer
351,Design a lending library for communities.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; library service,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
352,Design a LinkedIn for blue collar workers.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; professional network,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
353,Design a listening product for Meta.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; audio product,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
358,Design a meditation app.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; meditation app,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
359,Design a messaging platform.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; messaging,"NSM: Define one North Star metric that best represents user + business value. Example: Daily Active Conversations or Messages per User.

Input KPIs: Break NSM into 3-5 controllable drivers. Adoption: active conversations, message volume. Quality: response time, message relevance. Engagement: daily active users, conversation depth.

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
360,Design a Meta product for space travel.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; space travel,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
364,Design a mobile app for Disney theme parks.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; theme park app,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
365,Design a mobile app to celebrate birthdays.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; birthday app,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
369,Design a mortgage app.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; financial app,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
371,Design a music streaming service for Facebook.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; music streaming,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
372,Design a new cane.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; accessibility,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
374,Design a new feature for WhatsApp group messages.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Feature design; messaging,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
375,Design a new feature for YouTube.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Feature design; video platform,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
376,"Design a new product that Apple could announce in 5-6 years. What features and innovations would it include, and how would it enhance the current Apple ecosystem?",ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product strategy; future product,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
377,Design a new volunteer feature in the Facebook app.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Feature design; social platform,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
378,Design a new way for tourists to communicate.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; travel communication,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
381,Design a next-generation elevator.,ðŸŸ¢,P13,Product Design,User Context â†’ Pain Points â†’ Core Design â†’ Tradeoffs â†’ Risks,Product design; elevator,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13A_Conceptual_Consumer
382,Design a parking garage for a high-tech shopping center.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; parking system,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
383,Design a parking lot.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; parking,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
384,Design a parking solution for one of your favourite navigation apps.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; parking integration,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
385,Design a payment screen mockup with virtual card numbers.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Feature design; payment UI,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
386,Design a payment system for teenage boys in Italy.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; payment system,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
390,"Design a personalized user experience for Paytm, a payments and financial services app.",ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; personalization,"NSM: Define one North Star metric that best represents user + business value. Example: Monthly Active Users with Transactions or Financial Health Score.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User financial safety, regulatory compliance, fraud prevention. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
391,Design a physical product for Airbnb.,ðŸŸ¢,P13,Product Design,User Context â†’ Pain Points â†’ Core Design â†’ Tradeoffs â†’ Risks,Product design; physical product,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13A_Conceptual_Consumer
393,Design a platform for home-chefs.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; marketplace,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
394,Design a platform for users to enjoy art.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; art platform,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
395,Design a platform that matches people wanting to learn skills with relevant mentors.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; education marketplace,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
396,Design a podcast app for Facebook.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; podcast app,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
397,Design a podcast platform.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; podcast platform,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
399,Design a product at Facebook to improve the layover experience.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; travel experience,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
400,Design a product for air travelers.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; travel,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
401,Design a product for airports.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; airport services,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
402,Design a product for board meetings.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; board meetings,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
403,Design a product for borrowing and lending.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; lending platform,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
404,Design a product for celebrity engagement.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; celebrity platform,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
405,Design a product for chefs to speed up the cooking process.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; chef tools,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
406,Design a product for child care.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; childcare,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
407,Design a product for children at your favorite museum.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; museum experience,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
408,Design a product for collaborative audio transcription and dubbing tool?,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; audio tools,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
409,Design a product for Facebook for the Olympics.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; Olympics,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
410,Design a product for Facebook to enable charity.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; charity platform,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
411,Design a product for farms.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; agriculture,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
412,Design a product for gardeners.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; gardening,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
413,Design a product for gardening enthusiasts.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; gardening,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
414,Design a product for handymen for Meta.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; marketplace,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
415,Design a product for house-switching when traveling.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; travel accommodation,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
416,Design a product for job search on Facebook.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; job search,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
417,Design a product for junior athletes to connect with their idols.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; sports networking,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
418,Design a product for learning to play musical instruments.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; education,"NSM: Define one North Star metric that best represents user + business value. Example: Weekly Active Learners or Course Completion Rate.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
419,Design a product for managing and planning budgets.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; financial planning,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
420,Design a product for managing parking (not limited to cars).,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; parking management,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
421,Design a product for museums.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; museum,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
422,Design a product for parenting.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; parenting,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
423,Design a product for parents to moderate their children's phone and screen usage.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; parental controls,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
424,"Design a product for parking, not related to Facebook.",ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; parking,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
425,Design a product for retailers with the aim of increasing advertiser ROI.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; advertising ROI,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
426,Design a product for roofers.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; contractor platform,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
427,Design a product for the blind visiting the mall.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; accessibility,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
428,Design a product for the Department of Motor Vehicles (DMV).,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; government services,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
429,Design a product for theme parks.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; theme parks,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
430,Design a product or feature for new or expecting parents on Facebook.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; parenting feature,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
432,Design a product roadmap for Flipkart's Seller Hub mobile app.,ðŸŸ¢,P13,Product Design,Vision â†’ User Segments â†’ Strategic Bets â†’ Phasing â†’ Risks,Roadmap planning; seller platform,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13E_Strategy_Vision
433,Design a product similar to Google Docs for photo editing collaboration.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; collaboration tool,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
435,"Design a product that enables apartment owners to access and manage the usage of shared amenities (e.g. gym, garden, and book club) within their complex?",ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; property management,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
436,Design a product that encourages people to read more.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; reading platform,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
437,Design a product that helps people find contractors.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; contractor marketplace,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
438,Design a product that helps people learn to play musical instruments.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; music education,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
440,Design a product to address language barriers in India.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; language translation,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
441,Design a product to connect college students.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; student networking,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
442,Design a product to gather user feedback from various other products or services.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; feedback platform,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
443,Design a product to help Facebook employees enhance their learning.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; employee learning,"NSM: Define one North Star metric that best represents user + business value. Example: Weekly Active Learners or Course Completion Rate.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
444,Design a product to help flightless birds navigate a big city.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; creative problem,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
445,Design a product to help people connect better with doctors.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; healthcare,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
446,Design a product to help people feel more rested.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; wellness,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
447,Design a product to help people start exercising again.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; fitness,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
448,Design a product to help salespeople in the automotive industry close more deals.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; sales tools,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
449,Design a product to help travelers at airports. How would you go about building it?,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; airport services,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
450,Design a product to memorialize pets who have passed away.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; pet memorial,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
458,Design a recommender system feature for Dropbox that suggests files to users when they open the app on their phone.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Feature design; recommendation,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
460,Design a refrigerator for blind people.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; accessibility,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
461,Design a refrigerator for kids.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; kids product,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
462,Design a refrigerator for Meta.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; smart appliance,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
463,Design a refrigerator for the blind.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; accessibility,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
466,Design a restaurant menu application.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; restaurant app,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
470,Design a rewarding system.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; rewards system,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
471,Design a rideshare product or feature specifically for senior citizens.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; rideshare for seniors,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
475,Design a Search Engine for Kids,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; search engine for kids,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
477,Design a self-driving car solution for kids.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; autonomous vehicles,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
480,Design a smart hat.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; wearable,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
481,Design a Smart Lock for Google.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; smart lock,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
482,Design a smart picture frame.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; smart display,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
483,Design a smart refrigerator.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; smart appliance,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
484,Design a smartphone for blind people.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; accessibility,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
485,Design a social crypto bank.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; fintech,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
486,Design a social media application for introverts.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; social media,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
487,Design a solution for attending large events and concerts.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; event experience,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
488,Design a solution for borrowing and lending goods among neighbors on Facebook.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; neighborhood platform,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
489,Design a solution for borrowing and lending on Facebook.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; lending platform,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
491,Design a solution for the world of online learning.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; education platform,"NSM: Define one North Star metric that best represents user + business value. Example: Weekly Active Learners or Course Completion Rate.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
492,Design a solution to map unmapped places in Google Maps.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; mapping,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
494,Design a streaming service like Netflix.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; streaming service,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
495,Design a studio apartment for 3 people.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; apartment design,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
516,Design a tablet for a restaurant.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; restaurant tablet,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
517,Design a task management app for personal use.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; task management,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
521,Design a teleportation device for the year 2050.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; futuristic concept,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
523,Design a Time Machine for TuSimple.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; time machine concept,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
524,Design a time machine.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; time machine concept,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
525,Design a touchscreen table for a restaurant.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; restaurant interface,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
526,Design a travel app experience for Meta.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; travel app,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
527,Design a travel product for Instagram.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; travel feature,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
532,Design a vending machine for a hotel lobby.,ðŸŸ¢,P13,Product Design,User Context â†’ Pain Points â†’ Core Design â†’ Tradeoffs â†’ Risks,Product design; vending machine,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13A_Conceptual_Consumer
534,Design a vending machine for use in airports.,ðŸŸ¢,P13,Product Design,User Context â†’ Pain Points â†’ Core Design â†’ Tradeoffs â†’ Risks,Product design; vending machine,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13A_Conceptual_Consumer
535,Design a video sharing app that verifies the authenticity of videos.,ðŸŸ¢,P13,Product Design,Sides â†’ Value Exchange â†’ Liquidity Risks â†’ MVP â†’ Balancing Levers,Product design; video verification,"NSM: Define one North Star metric that best represents user + business value. Example: Weekly Active Video Viewers or Watch Time per User.

Input KPIs: Break NSM into 3-5 controllable drivers. Content: video quality, relevance, diversity. Engagement: watch time, completion rate, shares. Platform: load time, buffering, playback quality.

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13D_Marketplace_TwoSided
536,Design a video streaming app for senior citizens.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; video streaming for seniors,"NSM: Define one North Star metric that best represents user + business value. Example: Weekly Active Video Viewers or Watch Time per User.

Input KPIs: Break NSM into 3-5 controllable drivers. Content: video quality, relevance, diversity. Engagement: watch time, completion rate, shares. Platform: load time, buffering, playback quality.

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
537,Design a video streaming product for senior citizens.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; video streaming for seniors,"NSM: Define one North Star metric that best represents user + business value. Example: Weekly Active Video Viewers or Watch Time per User.

Input KPIs: Break NSM into 3-5 controllable drivers. Content: video quality, relevance, diversity. Engagement: watch time, completion rate, shares. Platform: load time, buffering, playback quality.

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
538,Design a virtual learning experience for Meta Reality Labs that teaches hands-on skills like pottery or welding.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; VR education,"NSM: Define one North Star metric that best represents user + business value. Example: Weekly Active Learners or Course Completion Rate.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
539,Design a virtual travel product.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; virtual travel,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
541,Design a voting app.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; voting app,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
543,Design a washing machine for Gen Z.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; appliance for Gen Z,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
544,Design a washing machine for Google.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; smart appliance,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
545,Design a web app for office workers to book time off.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; HR app,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
546,Design a web app to find a cleaner.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; service marketplace,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
551,Design a wedding registry.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; wedding registry,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
552,Design a Yelp-like restaurant review app.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; review app,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
553,Design Airbnb for work.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; B2B accommodation,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
554,Design Amazon Prime video.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; streaming service,"NSM: Define one North Star metric that best represents user + business value. Example: Weekly Active Video Viewers or Watch Time per User.

Input KPIs: Break NSM into 3-5 controllable drivers. Content: video quality, relevance, diversity. Engagement: watch time, completion rate, shares. Platform: load time, buffering, playback quality.

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
561,Design an AI data product.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; AI data product,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
564,Design an alarm clock for children 100 years in the future.,ðŸŸ¢,P13,Product Design,User Context â†’ Pain Points â†’ Core Design â†’ Tradeoffs â†’ Risks,Product design; futuristic alarm clock,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13A_Conceptual_Consumer
570,Design an app for a theme park.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; theme park app,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
571,Design an app for a toy remote control car.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; toy app,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
572,Design an app for an airport that can be monetized.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; airport app with monetization,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
573,Design an app for an amusement park.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; amusement park app,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
574,Design an app for buying and selling antiques.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; marketplace,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
575,Design an app for cinema.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; cinema app,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
576,Design an app for gardening.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; gardening app,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
577,Design an app for Meta's smart glasses.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; AR glasses app,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
578,Design an app for newcomers in a city to find doctors.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; healthcare app,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
579,Design an app for renting bicycles.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; bike rental app,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
581,Design an app to allow book subscriptions with hard copies.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; book subscription,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
582,Design an app to read books online.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; e-reader app,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
583,Design an app to search for therapists.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; healthcare app,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
586,Design an application that helps users lose weight.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; health app,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
587,Design an application to help people find doctors.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; healthcare app,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
588,Design an art solution for Instagram.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; art platform,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
589,Design an art-related product for Meta.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; art product,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
590,Design an ATM for kids.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; ATM for kids,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
591,Design an ATM for London's Heathrow Airport.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; airport ATM,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
592,Design an ATM for the blind.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; accessibility,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
598,Design an e-commerce website for SLR cameras.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; e-commerce,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
599,Design an educational product for Instagram.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; education platform,"NSM: Define one North Star metric that best represents user + business value. Example: Weekly Active Learners or Course Completion Rate.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
600,Design an educational product for Meta.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; education platform,"NSM: Define one North Star metric that best represents user + business value. Example: Weekly Active Learners or Course Completion Rate.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
601,Design an educational product for YouTube.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; education platform,"NSM: Define one North Star metric that best represents user + business value. Example: Weekly Active Learners or Course Completion Rate.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
603,Design an electric car dashboard.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; automotive dashboard,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
604,Design an elevator for a skyscraper and estimate the number of elevators needed.,ðŸŸ¢,P13,Product Design,User Context â†’ Pain Points â†’ Core Design â†’ Tradeoffs â†’ Risks,Product design; elevator with estimation,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13A_Conceptual_Consumer
605,Design an elevator for blind users.,ðŸŸ¢,P13,Product Design,User Context â†’ Pain Points â†’ Core Design â†’ Tradeoffs â†’ Risks,Product design; accessibility,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13A_Conceptual_Consumer
606,Design an elevator.,ðŸŸ¢,P13,Product Design,User Context â†’ Pain Points â†’ Core Design â†’ Tradeoffs â†’ Risks,Product design; elevator,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13A_Conceptual_Consumer
607,Design an employee onboarding product for SaaS companies.,ðŸŸ¢,P13,Product Design,User vs Buyer â†’ Workflow Pain â†’ MVP â†’ Adoption Risks â†’ Success Metrics,Product design; HR onboarding,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13C_B2B_Enterprise
613,Design an events feature for a kids' messenger app.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Feature design; messaging,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
615,Design an image sharing product.,ðŸŸ¢,P13,Product Design,Sides â†’ Value Exchange â†’ Liquidity Risks â†’ MVP â†’ Balancing Levers,Product design; image sharing,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13D_Marketplace_TwoSided
616,Design an improved version of Google Photos to enhance accessibility for blind users.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; accessibility,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. Accessibility compliance, user trust, inclusive design. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
620,Design an international crypto remittance product.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; fintech,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
622,Design an iron for the blind.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; accessibility,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
628,Design an office refrigerator.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; office appliance,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
631,Design an online ticketing platform to compete with Ticketmaster.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; ticketing platform,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
640,Design ClassPass for kids.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; fitness for kids,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
642,Design E2E experience for elderly travelling through Flights.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; travel for elderly,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
647,Design Google Maps for kids.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; maps for kids,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
649,Design Instagram's Explore page.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Feature design; discovery,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
651,Design LinkedIn for students.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; professional network,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
653,Design Lyft for college students.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; rideshare for students,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
654,Design Lyft for kids.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; rideshare for kids,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
655,"Design Naukri, a job search platform.",ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; job platform,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
656,Design Netflix for dogs.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; streaming for pets,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
657,Design Netflix for kids.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; streaming for kids,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
660,Design pens for children.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; stationery,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
661,Design price alert notifications for the Coinbase app.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Feature design; price alerts,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
662,Design Robinhood.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; trading platform,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
663,Design smart furniture for Google.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; IoT furniture,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
664,Design something based on a project on your resume.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; portfolio question,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
666,Design the 'For You' page on TikTok.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Feature design; recommendation feed,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
667,Design the 'Top Picks' feature for Netflix.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Feature design; recommendation,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
673,Design the best slippers.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; footwear,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
674,Design the front page of a newspaper app.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; news app,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
675,Design the interior of a fully autonomous car that requires no human interaction.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; autonomous vehicle,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
676,Design the Netflix ads platform.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; ad platform,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
677,Design the OpenAI Playground.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; AI platform,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
682,Design TikTok for the elderly.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; social media for seniors,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
688,Design Uber for laundry.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; on-demand service,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
689,Design Weather App,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; weather app,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
691,Design YouTube advertising.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; ad platform,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
704,Develop a roadmap to drive engagement from small business owners for Apple Maps.,ðŸŸ¢,P13,Product Design,User vs Buyer â†’ Workflow Pain â†’ MVP â†’ Adoption Risks â†’ Success Metrics,Roadmap planning; engagement strategy,"NSM: Identify the single most important metric that represents success. This should be the one number that best captures user value + business value combined.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13C_B2B_Enterprise
738,Enhance any fintech app of your choice for visually impaired users.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product improvement; accessibility,"NSM: Identify the single most important metric that represents success. This should be the one number that best captures user value + business value combined.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
905,Give me three product enhancements for your favorite product.,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product improvement; feature ideas,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
970,"Given Google Search is just a simple text input and hasn't innovated further, how would you improve the user journey from the landing page?",ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product improvement; user experience,"NSM: Identify the single most important metric that represents success. This should be the one number that best captures user value + business value combined.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
979,"Given the increase in travel-related content and the trend of 'revenge travel' post-COVID, design a new product for the travel space.",ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; travel industry,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. Content quality, user safety, community guidelines compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
980,"Given the pandemic, how would you build a software product to help parents monitor their child's increasing screen time on laptops and mobiles?",ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; parental controls,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
1012,Have you tried PowerPoint and what would you improve about it?,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product improvement; PowerPoint,"NSM: Identify the single most important metric that represents success. This should be the one number that best captures user value + business value combined.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
1022,How can Facebook improve preparing for another pandemic?,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product improvement; crisis preparedness,"NSM: Identify the single most important metric that represents success. This should be the one number that best captures user value + business value combined.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
1023,How can Lyft build a product to improve transportation for patients and how will you monetize it?,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; healthcare transportation,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
1029,How could e-commerce platforms enhance the shopping experience to be more inspirational?,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product improvement; e-commerce,"NSM: Identify the single most important metric that represents success. This should be the one number that best captures user value + business value combined.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
1078,How do you design Amazon's Choice feature?,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Feature design; recommendation system,"NSM: Define one North Star metric that best represents user + business value. Choose a single metric that captures both user value and business outcomes.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
1165,How does Capital One Shopping create value for Capital One?,ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Value creation; business model,"NSM: Identify the single most important metric that represents success. This should be the one number that best captures user value + business value combined.

Input KPIs: Break NSM into 3-5 controllable drivers. User behavior drivers (engagement, activation). Supply/quality drivers (content, inventory, features). Monetization drivers (conversion, retention, LTV).

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
1212,How might you improve Spotify using social features?,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product improvement; social features,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
1261,How would you build a product for disabled users on LinkedIn?,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product design; accessibility,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
1271,How would you build out a feature for Viva Engage?,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Feature design; product improvement,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
1301,How would you design a coffee machine for use on the International Space Station?,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product design; space constraints,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
1302,How would you design a game for a popular Netflix reality show?,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product design; game design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
1303,How would you design a hyperlocal feature for Facebook?,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Feature design; product improvement,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
1304,How would you design a password management tool for children?,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product design; security,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
1306,How would you design a Web browser to increase the sales of your ecommerce company?,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product design; revenue optimization,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
1310,How would you design parking features on Google Maps?,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Feature design; product improvement,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
1311,How would you design the product experience of an ATM machine at an international airport.,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product design; UX design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
1312,How would you design the YouTube landing page?,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product design; UX design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
1336,How would you enhance the Facebook Birthdays feature?,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Feature enhancement; product improvement,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
1359,How would you future-proof the organization against industry disruption?,ðŸŸ¢,P13,Product Design,Vision â†’ User Segments â†’ Strategic Bets â†’ Phasing â†’ Risks,Strategic planning; product strategy,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
1383,How would you implement safety features for Roblox's private messaging between players?,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Safety features; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
1424,"How would you improve the customer satisfaction rating (CSAT) for Costco, a membership-only retail store?",ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,CSAT improvement; metrics,"NSM: Identify the single most important metric that represents success. This should be the one number that best captures user value + business value combined.

Input KPIs: Break NSM into 3-5 controllable drivers. Resolution: first-contact resolution, time to resolve. Quality: customer satisfaction, issue recurrence. Efficiency: tickets per agent, automation rate.

Leading Indicators: Add early signals that predict NSM movement. Short-term behaviors: first-session actions, early engagement patterns. Funnel entry signals: activation rate, feature discovery. Quality proxies: user satisfaction, retention hooks, content signals.

Guardrails: Define what must NOT break while optimizing NSM. User trust, long-term health, cost/abuse prevention, compliance. Set thresholds that trigger alerts if breached.

Dashboard: Design simple monitoring structure. NSM at top (always visible, weekly trend). Input KPIs (weekly review, track drivers). Leading indicators (daily monitoring, early signals). Guardrails (alerts only, no daily noise).",P13B_Digital_Consumer
1439,How would you improve the Spotlight feature at Snapchat?,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Feature improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
1446,How would you improve Venmo? What features would you build and why?,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
1471,How would you integrate social features into the Coinbase platform?,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Feature integration; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
1474,How would you launch a Copilot Plus feature in Surface?,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Feature launch; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
1475,How would you launch a new product in the blue-collar service industry?,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product launch; product strategy,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
1476,How would you launch a new product to our existing user base?,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product launch; product strategy,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
1479,How would you launch a scheduled rides feature for Uber or Lyft?,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Feature launch; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
1545,How would you redesign Instagram's DM feature?,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Feature redesign; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
1547,How would you redesign the gas station experience?,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Experience redesign; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
1548,How would you redesign the worst experience on Ticketmaster to improve it?,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Experience redesign; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
1586,Identify a product with untapped potential. Propose three new features for this product and outline how you would assess their effectiveness.,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product ideation; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
1602,"If Mark Zuckerberg asked you to create a product for athletes, what would you build?",ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product design; new product,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
1605,"If the CEO of Google asks for a product that allows meetings in person, what would you create for the next 5-10 years?",ðŸŸ¢,P13,Product Design,Vision â†’ User Segments â†’ Strategic Bets â†’ Phasing â†’ Risks,Product design; new product,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
1618,"If you had a teleportation device, how would you build a product from it?",ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product ideation; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
1619,"If you had access to 20 years of geo-related data, such as street view and satellite imagery, what product would you build?",ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product ideation; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
1624,"If you have allocated budget, how would you solve the climate crisis problem?",ðŸŸ¢,P13,Product Design,Vision â†’ User Segments â†’ Strategic Bets â†’ Phasing â†’ Risks,Problem solving; product strategy,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
1632,"If you were the PM for the search results page, how would you design the relevance?",ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Search design; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
1646,Imagine you're a PM for Facebook. Design a product for teens.,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product design; new product,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
1647,Imagine you're a PM for Meta. Design a product for hobbyists (eg. gardening),ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product design; new product,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
1648,Imagine you're a PM for Meta. Design a product for Volunteering. What would you build? Why?,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product design; new product,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
1683,Improve Facebook's Crisis Alert feature.,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Feature improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
1727,"Lyft wants to invest in vertical take-off vehicles that can fit up to 4 people. How should we approach the market, who should be our target audience, and what features should we prioritize in our p...",ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product strategy; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
1740,Meta wants to build a product for handymen like plumbers and carpenters. How would you design it?,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product design; new product,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
1763,Pick a random object in your room. How would you redesign it?,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product redesign; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
1778,Product Sense - Build a product for sports.,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product design; new product,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
1779,Propose a new feature for Perplexity.,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Feature proposal; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
1784,Redesign a DMV system.,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,System redesign; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
1785,Redesign a TV remote control.,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product redesign; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
1786,Redesign Google Maps to increase engagement with small businesses.,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product redesign; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
1787,Redesign the airport experience.,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Experience redesign; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
1788,Reinvent a backpack with 10 new features.,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product reinvention; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
1789,Reinvent a pillow with 10 new features.,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product reinvention; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
1790,Reinvent a trashcan with 10 new features.,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product reinvention; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
1831,"Should Uber launch an 'Uber for Kids' service? If so, how would you design it?",ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product design; new product,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
1865,Tell me about a popular product you use. How would you design a competitor and what features would you prioritize?,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Competitive design; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
1904,Tell me about a time when you created a product or feature without the client requesting it.,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Proactive product; behavioral question,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
1983,Tell me about a time when you redesigned the interface of clinical trial software for enhanced user simplicity.,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Interface redesign; behavioral question,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2027,Tell me about a time where you ideated and launched a strategy from scratch.,ðŸŸ¢,P13,Product Design,Vision â†’ User Segments â†’ Strategic Bets â†’ Phasing â†’ Risks,Strategy launch; behavioral question,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2117,Tell me about your design process.,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Design process; behavioral question,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2153,The CEO asks you to design a new ATM specifically for their airport segment. What would you do?,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product design; new product,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2194,What are 4 features you would build for Netflix?,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Feature ideation; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2226,What are the most important industry trends right now? What strategy would you pursue if you were leading Voodoo in the next 5 years?,ðŸŸ¢,P13,Product Design,Vision â†’ User Segments â†’ Strategic Bets â†’ Phasing â†’ Risks,Industry trends; product strategy,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2290,What factors would you consider when planning a strategy for a new feature for contractors and freelancers?,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Feature strategy; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2317,What is an example of a poorly designed product? How would you improve it?,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product critique; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2329,What is the current strategy of 15-minute delivery apps?,ðŸŸ¢,P13,Product Design,Vision â†’ User Segments â†’ Strategic Bets â†’ Phasing â†’ Risks,Strategy analysis; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2373,What is your favorite Slack feature?,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Feature analysis; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2417,What parameters would you consider when designing UberPool?,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product design; new product,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2422,What problems could an MVP app solve?,ðŸŸ¢,P13,Product Design,Vision â†’ User Segments â†’ Strategic Bets â†’ Phasing â†’ Risks,MVP ideation; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2424,What product do you think has good UX design and why?,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,UX analysis; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2425,What product should Apple announce at their next Keynote?,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product ideation; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2426,What product should Google build next?,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product ideation; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2454,What two new features would you add to a car garage?,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Feature ideation; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2462,What would be your strategy to improve Google Maps as a product?,ðŸŸ¢,P13,Product Design,Vision â†’ User Segments â†’ Strategic Bets â†’ Phasing â†’ Risks,Product improvement; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2659,"You are a PM at Netflix, design a podcast for Netflix.",ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product design; new product,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2665,"You are an editor managing a voice-dubbing project currently tracked in Excel. Design a new interface to review progress, manage feedback, and collaborate with voice actors.",ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product design; new product,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2666,You are at a well-funded startup. Design a solution to solve the problem of parking.,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product design; new product,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2683,You are working for a startup to build a product for volunteering.,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product design; new product,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2686,You have 3 years to make X the best in the world. What strategy would you implement?,ðŸŸ¢,P13,Product Design,Vision â†’ User Segments â†’ Strategic Bets â†’ Phasing â†’ Risks,Product strategy; product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2710,You're a growth PM for Chrome Browser. Design a 3-year strategy for the browser.,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2716,"You're a PM at a pharma company; your product helps cows produce 20% more milk, lasting a month. What pricing strategy and price would you set for the product?",ðŸŸ¢,P13,Product Design,Vision â†’ User Segments â†’ Strategic Bets â†’ Phasing â†’ Risks,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2718,"You're a PM at a Tech Startup focused on food delivery for companies, what would you design?",ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2721,You're a PM at Airbnb. Design furniture.,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2727,You're a PM at an elevator construction company. Design an elevator for a client.,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2730,You're a PM at Capital One. How do you measure financial gains or losses in the first year after launching a new product?,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2740,You're a PM at Instagram responsible for building the Reels feature. How would you define and measure its success?,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2743,You're a PM at LinkedIn. Design features to support India's growing startup ecosystem.,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2747,You're a PM at Meta. Design a product for musicians.,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2748,You're a PM at Meta. Design a product for skill sharing.,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2749,You're a PM at Meta. Design a product for users to find a handyman.,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2754,"You're a PM at Meta. How would you measure the success of the 'Report Ad' feature for Ads, considering false positives and false negatives?",ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2755,You're a PM at Meta. What product or feature would you build for small or local businesses?,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2761,You're a PM at Spotify considering adding a feature for artists to go live. Should you invest in this?,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2765,You're a PM at Swiggy. How would you design a new segment for liquor on Instamart?,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2768,You're a PM at Trader Joe's and you find that sales revenues are down. Design the experience for users based on competitors like Blue Apron.,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2771,You're a PM at Uber; design a smartwatch app.,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2773,You're a PM at WhatsApp tasked with increasing user engagement. What features will you build and how will you prioritize and evaluate them?,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2775,You're a PM at Wikipedia. What product should you build next?,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2780,You're a PM for a household device. What three features would you recommend and why?,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2782,"You're a PM for a new device, which is a time machine. How would you design the interface?",ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2796,You're a PM for Gmail. Design a three-year product roadmap.,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2799,You're a PM for Google Chrome on large screens. Build the three-year innovation roadmap.,ðŸŸ¢,P13,Product Design,Vision â†’ User Segments â†’ Strategic Bets â†’ Phasing â†’ Risks,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2800,You're a PM for Google News. What would be your product strategy for the upcoming year?,ðŸŸ¢,P13,Product Design,Vision â†’ User Segments â†’ Strategic Bets â†’ Phasing â†’ Risks,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2810,You're a PM for Maps. What product would you build in Maps specifically for farmers?,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2811,"You're a PM for Max, HBO's video streaming service. Roku wants to include an HBO button on their new remote control. How much should HBO pay for this feature?",ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2812,You're a PM for Meta releasing a new Jobs feature in 2 weeks. How will you measure the success of this product in the short and long term?,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2815,You're a PM for Meta. Design a product for group travel.,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2816,You're a PM for Meta. How would you build a product that helps users find handypeople?,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2824,You're a PM for Tesla. Design the Tesla app for the Apple Watch.,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2828,You're a PM for Walmart building a new fulfillment center. What products would you stock?,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2829,You're a PM in the middle of a sprint when a P1 issue arises that impacts the sprint goal due to requirements and design problems. How would you handle this?,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2834,"You're a PM with two engineers, and enterprise customers won't adopt your product due to an unclear roadmap. Your engineers are already working hard on a task outlined. What would you do?",ðŸŸ¢,P13,Product Design,Vision â†’ User Segments â†’ Strategic Bets â†’ Phasing â†’ Risks,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2836,You're a product manager at Meta. Design a product for hyperlocal experiences.,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2841,You're designing an A/B test to evaluate the impact of showing content from non-friends in users' feeds. How would you test this with proper randomization?,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2848,You're on the LA 2028 Olympic Games organizing committee. What product would you build?,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2849,You're PM at Meta. Design a fundraising product for a cause.,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2851,"You're redesigning Capital One's Instant Push Notifications (IPN) system, moving from multiple screens to a single view. How would you improve the user experience?",ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2853,You're the CEO of an AI startup. Google offers you $1B in funding. What product would you build?,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2854,You're the CEO or VP of your favorite product. How would you structure your organization and why?,ðŸŸ¢,P13,Product Design,Vision â†’ User Segments â†’ Strategic Bets â†’ Phasing â†’ Risks,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2869,You're the PM for Meta's Social Good team. Design a new product to encourage more volunteering.,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2870,You're the PM for one of your favorite products. What is your strategy for the next year?,ðŸŸ¢,P13,Product Design,Vision â†’ User Segments â†’ Strategic Bets â†’ Phasing â†’ Risks,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2872,You're the PM for Safeway. What product would you build to better serve people's needs?,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2875,"You're the PM of a stock trading app like Fidelity or Zerodha. To increase the number of customers who complete their first trade after installing the app, what two new features would you launch?",ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2878,You're the PM of the Apple Watch; how would you design it?,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2879,You're the Product Manager at Beacon. What would you do to build an in-app chat feature?,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2884,Your largest customer is advocating for a new feature not in your roadmap. What do you do?,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2885,"Your recently launched feature isn't meeting customer expectations, but your engineering team and roadmap are at capacity. How would you address this?",ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
2890,Youâ€™re launching a new featureâ€”how would you measure its strategic impact on growth?,ðŸŸ¢,P13,Product Design,Users â†’ Problems â†’ Solutions â†’ Tradeoffs â†’ Risks â†’ (Optional) Success Metrics,Product design,"Define Cohorts: Group users by meaningful dimensions. By signup time: week/month cohorts to track lifecycle. By acquisition source: ads vs organic vs referral to identify quality differences. By persona: power users vs casual users vs new users. By behavior: activated vs not activated, feature adopters vs non-adopters.

Measure Retention: Build retention curve and compare cohorts. Track: D1 (day 1), D7 (week 1), D30 (month 1), W4 (week 4), M3 (month 3) retention. Compare cohorts side-by-side to spot differences. Assess: absolute level (how low is retention?) and shape (early cliff vs slow decay).

Identify Churn Drivers: Understand WHEN, WHO, and WHAT. WHEN: Day 0-1 â†’ onboarding/activation gap. Week 1 â†’ value not clear. Month 1+ â†’ habit formation or competition. WHO: Which segments leave more? Specific cohorts, channels, or user types? WHAT: What changes before churn? Drop in key actions, fewer sessions, feature not used, or usage pattern shift.

Hypothesize: Generate hypotheses based on churn timing and patterns. If early drop â†’ activation problem. If one cohort worse â†’ acquisition mismatch. If usage drops first â†’ value erosion. If late churn â†’ lack of habit/reminders.

Fix: Implement targeted solutions based on hypotheses. Improve onboarding/activation for early churn. Tighten targeting if specific cohorts underperform. Reinforce core value loop if usage drops. Add retention hooks (email, push, content) for late churn. Measure cohort again to validate improvements.",
690,"Design Whatsapp for either one of 3 segments: senior citizens, families, or businesses.",ðŸŸ¢,P13,Product Design,Users â†’ Jobs â†’ Core Loop â†’ Key Features â†’ Tradeoffs â†’ Success Metrics,Product design; segmented messaging,,P13B_Digital_Consumer
