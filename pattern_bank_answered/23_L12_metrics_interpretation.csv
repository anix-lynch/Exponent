question_id,question_text,priority,pattern_id,pattern_name,solving_formula,notes,short_answer
144,"Can a university have a lower overall acceptance rate for female-identifying students, even if every department admits them at a higher rate than others?",ğŸŸ¡,L12,Metrics Interpretation,Metric Moved â†’ Proxy Validity â†’ Gaming Risk â†’ Decide,Simpson's paradox; metric interpretation,"ğŸ“Š Metric Moved: Identify what exactly changed
  ğŸ“ˆ Direction: up / down / flat, which direction did the metric move?
  ğŸ“ Magnitude: small blip vs step-change, how significant is the change?
  ğŸ¯ Scope: which segment, surface, cohort, where is the change happening?
  â° Time: one day spike vs sustained trend, is this temporary or ongoing?
  ğŸ”€ Aggregation level: overall metric vs segment-level metrics, check for Simpson's paradox
  âš ï¸ Rule: Never react to a single datapoint

ğŸ” Proxy Validity: Verify if this metric means what we think it means
  ğŸ¯ Is it a proxy or the real goal? Is this metric a stand-in for something else, or the actual outcome?
  ğŸ“ˆ How tightly correlated to value? Does this metric actually predict business value or user satisfaction?
  â­ï¸ Leading vs lagging? Is this a leading indicator (predicts future) or lagging indicator (reflects past)?
  ğŸ‘ï¸ Any known blind spots? Are there scenarios where this metric is misleading or incomplete?
  âš ï¸ Example: CTR â†‘ but satisfaction â†“ â†’ weak proxy

ğŸ® Gaming & Incentives: Assess if the metric can be manipulated
  ğŸ‘¥ By users? Spam, bots, churn masking, are users gaming the system?
  ğŸ‘” By teams? Optimize metric, hurt product, are teams optimizing for the metric at the expense of real value?
  ğŸ¨ By design? Dark patterns, forced clicks, is the product design encouraging manipulation?
  ğŸ“Š By reporting? Definition drift, are we changing how we measure this over time?
  âš ï¸ Rule: If it's tied to goals/bonuses, it WILL be gamed

ğŸ” Context Checks: Determine if this change is causal or coincidental
  ğŸ“… Seasonality? Is this a seasonal pattern we've seen before?
  ğŸš€ Launches / experiments? Did we recently launch a feature or run an experiment?
  ğŸŒ External events? Are there external factors (news, holidays, market changes) affecting this?
  ğŸ”§ Data pipeline issues? Could this be a data quality problem or reporting error?
  ğŸ”€ Aggregation bias? Is the overall metric hiding important segment-level differences (Simpson's paradox)?
  âš ï¸ Correlation vs causation: is this change actually caused by what we think, or just correlated?

âœ… Decide: Determine the appropriate action based on the analysis
  ğŸš« Ignore â†’ noise or bad proxy: if the metric is misleading or the change is insignificant, ignore it
  ğŸ‘€ Monitor â†’ unclear, need more data: if we're not sure, set up monitoring and wait for more information
  ğŸ” Investigate â†’ signal but ambiguous: if there's a potential signal, dig deeper to understand what's happening
  âš¡ Act â†’ strong signal + aligned proxy: if the metric is a good proxy and the change is significant, take action
  ğŸ’¡ Output: 'We believe X changed because Y, so we will Z.'"
1766,Post Success By Age Group.,ğŸŸ¢,L12,Metrics Interpretation,Metric Moved â†’ Proxy Validity â†’ Gaming Risk â†’ Decide,Age segmentation; metrics reporting,
1794,Revenue by Customer City,ğŸŸ¢,L12,Metrics Interpretation,Metric Moved â†’ Proxy Validity â†’ Gaming Risk â†’ Decide,Geographic segmentation; metrics reporting,
1349,How would you explain a sudden drop in revenue to leadership?,ğŸŸ¢,L12,Metrics Interpretation,Metric Moved â†’ Proxy Validity â†’ Gaming Risk â†’ Decide,Revenue explanation; metrics interpretation,
1566,How would you share experiment results internally so it's digestible by different stakeholders?,ğŸŸ¢,L12,Metrics Interpretation,Metric Moved â†’ Proxy Validity â†’ Gaming Risk â†’ Decide,Results communication; metrics interpretation,
