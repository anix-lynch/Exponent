question_id,question_text,priority,pattern_id,pattern_name,solving_formula,notes,short_answer
6,A competitor is gaining market share. How would you investigate why?,ðŸŸ¢,P1,Metric Drop Diagnosis,Clarify Metric â†’ Segment â†’ Hypothesize â†’ Data Check â†’ Action,Market share = metric; competitive analysis,"Clarify: Define the key metric(s) and success criteria. What exactly needs to change? Baseline and target?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Ensure data quality and measurement consistency.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), funnel step, acquisition channel, and user segment to find the hot spot.

Hypothesize: Top 3-5 potential causes ranked by likelihood Ã— impact. Consider product, user, market, and technical factors.

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and analyze user behavior patterns. Use session replays, surveys, or log analysis.

Action: Prioritize fixes by impact Ã— confidence. Start with data issues, then high-impact hypotheses. Run experiments, monitor results, and communicate plan."
9,A key metric is decliningâ€”what would you investigate first and how would you prioritize what to build?,ðŸŸ¢,P1,Metric Drop Diagnosis,Clarify Metric â†’ Segment â†’ Hypothesize â†’ Data Check â†’ Action,Metric declining = classic P1; includes prioritization,"Clarify: Define the key metric(s) and success criteria. What exactly needs to change? Baseline and target?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Ensure data quality and measurement consistency.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), funnel step, acquisition channel, and user segment to find the hot spot.

Hypothesize: Top 3-5 potential causes ranked by likelihood Ã— impact. Consider product, user, market, and technical factors.

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and analyze user behavior patterns. Use session replays, surveys, or log analysis.

Action: Prioritize fixes by impact Ã— confidence. Start with data issues, then high-impact hypotheses. Run experiments, monitor results, and communicate plan."
22,Amazon orders are down 25% - what do you do?,ðŸŸ¢,P1,Metric Drop Diagnosis,Clarify Metric â†’ Segment â†’ Hypothesize â†’ Data Check â†’ Action,Classic metric drop; 25% decline,"Clarify: Define the metric (numerator/denominator), baseline, and scope. Specify: orders = what exactly? Time window: when did it start? Magnitude: how significant?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Verify tracking accuracy, ETL lag, or event schema changes.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), funnel step, acquisition channel, and user segment to find the hot spot.

Hypothesize: Product changes (UI, pricing, policy), external factors (competitor, seasonality), performance issues (latency, crashes), or supply-side changes (if marketplace).

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and compare to control segments. Look for crash rates, error codes, or performance degradation.

Action: If severe + clear cause â†’ rollback/hotfix immediately. If unclear â†’ add logging, run targeted experiments, or fix segment-specific issues. Communicate findings and mitigation plan."
51,"As a PM at Open Table, how would you resolve their biggest booking experience issue?",ðŸŸ¢,P1,Metric Drop Diagnosis,Clarify Metric â†’ Segment â†’ Hypothesize â†’ Data Check â†’ Action,Problem diagnosis; booking experience,"Clarify: Define the key metric(s) and success criteria. What exactly needs to change? Baseline and target?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Ensure data quality and measurement consistency.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), listing type, and booking window to find highest-leverage opportunities.

Hypothesize: Top 3-5 potential causes ranked by likelihood Ã— impact. Consider product, user, market, and technical factors.

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and analyze user behavior patterns. Use session replays, surveys, or log analysis.

Action: Prioritize fixes by impact Ã— confidence. Start with data issues, then high-impact hypotheses. Run experiments, monitor results, and communicate plan."
81,"As a product manager for a meditation app for kids with a 3 to 5 star average rating in the Play Store, how would you improve that rating?",ðŸŸ¢,P1,Metric Drop Diagnosis,Clarify Metric â†’ Segment â†’ Hypothesize â†’ Data Check â†’ Action,Rating improvement; app store optimization,"Clarify: Define success metric and target. Current rating rate? Target growth? Scope: which segments, surfaces, or user types?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Confirm measurement is accurate and not inflated by bots or data quality issues.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), funnel step, acquisition channel, and user segment to find the hot spot.

Hypothesize: Search relevance, pricing optimization, trust signals, supply quality, feature adoption, or user experience improvements.

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and test hypotheses with A/B tests or targeted experiments. Compare conversion rates by segment.

Action: Focus on highest-impact segments. Implement fixes: improve search/ranking, optimize pricing, add trust signals, or enhance UX. Measure impact and iterate."
106,"As the head of product at a children's museum, what would you do to address the feedback that engagement is down?",ðŸŸ¢,P1,Metric Drop Diagnosis,Clarify Metric â†’ Segment â†’ Hypothesize â†’ Data Check â†’ Action,Engagement drop; museum context,"Clarify: Define the metric (numerator/denominator), baseline, and scope. Specify: engagement = what exactly? Time window: when did it start? Magnitude: how significant?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Verify tracking accuracy, ETL lag, or event schema changes.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), content type, feature usage, and time of day to find engagement drivers.

Hypothesize: Product changes (UI, pricing, policy), external factors (competitor, seasonality), performance issues (latency, crashes), or supply-side changes (if marketplace).

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and compare to control segments. Look for crash rates, error codes, or performance degradation.

Action: If severe + clear cause â†’ rollback/hotfix immediately. If unclear â†’ add logging, run targeted experiments, or fix segment-specific issues. Communicate findings and mitigation plan."
115,"As the PM for Hangouts, what would be your next steps after it launched in 2013 with a 3-star rating and polarized reviews?",ðŸŸ¢,P1,Metric Drop Diagnosis,Clarify Metric â†’ Segment â†’ Hypothesize â†’ Data Check â†’ Action,Product recovery; low rating response,"Clarify: Define the key metric(s) and success criteria. What exactly needs to change? Baseline and target?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Ensure data quality and measurement consistency.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), funnel step, acquisition channel, and user segment to find the hot spot.

Hypothesize: Top 3-5 potential causes ranked by likelihood Ã— impact. Consider product, user, market, and technical factors.

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and analyze user behavior patterns. Use session replays, surveys, or log analysis.

Action: Prioritize fixes by impact Ã— confidence. Start with data issues, then high-impact hypotheses. Run experiments, monitor results, and communicate plan."
120,"As the PM responsible for the ride experience at Lyft, what would be the most effective solution to address the major issues occurring after the driver-rider match process?",ðŸŸ¢,P1,Metric Drop Diagnosis,Clarify Metric â†’ Segment â†’ Hypothesize â†’ Data Check â†’ Action,Ride experience issues; post-match problems,"Clarify: Define the key metric(s) and success criteria. What exactly needs to change? Baseline and target?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Ensure data quality and measurement consistency.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), funnel step, acquisition channel, and user segment to find the hot spot.

Hypothesize: Top 3-5 potential causes ranked by likelihood Ã— impact. Consider product, user, market, and technical factors.

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and analyze user behavior patterns. Use session replays, surveys, or log analysis.

Action: Prioritize fixes by impact Ã— confidence. Start with data issues, then high-impact hypotheses. Run experiments, monitor results, and communicate plan."
121,"As the Product Manager for Google Docs, facing a 10% decrease in the 'Open' metrics, what steps would you take to investigate and address this decline?",ðŸŸ¢,P1,Metric Drop Diagnosis,Clarify Metric â†’ Segment â†’ Hypothesize â†’ Data Check â†’ Action,Metric drop; Open metrics decline,"Clarify: Define the metric (numerator/denominator), baseline, and scope. Time window: when did it start? Magnitude: how significant?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Verify tracking accuracy, ETL lag, or event schema changes.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), funnel step, acquisition channel, and user segment to find the hot spot.

Hypothesize: Product changes (UI, pricing, policy), external factors (competitor, seasonality), performance issues (latency, crashes), or supply-side changes (if marketplace).

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and compare to control segments. Look for crash rates, error codes, or performance degradation.

Action: If severe + clear cause â†’ rollback/hotfix immediately. If unclear â†’ add logging, run targeted experiments, or fix segment-specific issues. Communicate findings and mitigation plan."
162,Click-through rate on Netflix is down by 10%. What would you do?,ðŸŸ¢,P1,Metric Drop Diagnosis,Clarify Metric â†’ Segment â†’ Hypothesize â†’ Data Check â†’ Action,Metric drop; CTR decline,"Clarify: Define the metric (numerator/denominator), baseline, and scope. Time window: when did it start? Magnitude: how significant?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Verify tracking accuracy, ETL lag, or event schema changes.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), funnel step, acquisition channel, and user segment to find the hot spot.

Hypothesize: Product changes (UI, pricing, policy), external factors (competitor, seasonality), performance issues (latency, crashes), or supply-side changes (if marketplace).

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and compare to control segments. Look for crash rates, error codes, or performance degradation.

Action: If severe + clear cause â†’ rollback/hotfix immediately. If unclear â†’ add logging, run targeted experiments, or fix segment-specific issues. Communicate findings and mitigation plan."
168,Coinbase's net income is 10% less than it was last month. What would you do?,ðŸŸ¢,P1,Metric Drop Diagnosis,Clarify Metric â†’ Segment â†’ Hypothesize â†’ Data Check â†’ Action,Revenue drop; financial analysis,"Clarify: Define the key metric(s) and success criteria. What exactly needs to change? Baseline and target?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Ensure data quality and measurement consistency.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), funnel step, acquisition channel, and user segment to find the hot spot.

Hypothesize: Top 3-5 potential causes ranked by likelihood Ã— impact. Consider product, user, market, and technical factors.

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and analyze user behavior patterns. Use session replays, surveys, or log analysis.

Action: Prioritize fixes by impact Ã— confidence. Start with data issues, then high-impact hypotheses. Run experiments, monitor results, and communicate plan."
170,"Considering that 60% of visitors view the store's return policy page on Shopify-powered sites, how would you assist merchants to be more successful as a PM at Shopify?",ðŸŸ¢,P1,Metric Drop Diagnosis,Clarify Metric â†’ Segment â†’ Hypothesize â†’ Data Check â†’ Action,Merchant success; return policy optimization,"Clarify: Define the key metric(s) and success criteria. What exactly needs to change? Baseline and target?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Ensure data quality and measurement consistency.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), funnel step, acquisition channel, and user segment to find the hot spot.

Hypothesize: Top 3-5 potential causes ranked by likelihood Ã— impact. Consider product, user, market, and technical factors.

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and analyze user behavior patterns. Use session replays, surveys, or log analysis.

Action: Prioritize fixes by impact Ã— confidence. Start with data issues, then high-impact hypotheses. Run experiments, monitor results, and communicate plan."
235,Describe how you've used data to identify underperforming business units.,ðŸŸ¢,P1,Metric Drop Diagnosis,Clarify Metric â†’ Segment â†’ Hypothesize â†’ Data Check â†’ Action,Business unit analysis; data-driven insights,"Clarify: Define the key metric(s) and success criteria. What exactly needs to change? Baseline and target?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Ensure data quality and measurement consistency.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), funnel step, acquisition channel, and user segment to find the hot spot.

Hypothesize: Top 3-5 potential causes ranked by likelihood Ã— impact. Consider product, user, market, and technical factors.

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and analyze user behavior patterns. Use session replays, surveys, or log analysis.

Action: Prioritize fixes by impact Ã— confidence. Start with data issues, then high-impact hypotheses. Run experiments, monitor results, and communicate plan."
707,Diagnose 23andMe's 33% drop in conversion.,ðŸŸ¢,P1,Metric Drop Diagnosis,Clarify Metric â†’ Segment â†’ Hypothesize â†’ Data Check â†’ Action,Conversion drop; metric diagnosis,"Clarify: Define the metric (numerator/denominator), baseline, and scope. Specify: conversion = what exactly? Time window: when did it start? Magnitude: how significant?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Verify tracking accuracy, ETL lag, or event schema changes.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), funnel step, acquisition channel, and user segment to find the hot spot.

Hypothesize: Product changes (UI, pricing, policy), external factors (competitor, seasonality), performance issues (latency, crashes), or supply-side changes (if marketplace).

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and compare to control segments. Look for crash rates, error codes, or performance degradation.

Action: If severe + clear cause â†’ rollback/hotfix immediately. If unclear â†’ add logging, run targeted experiments, or fix segment-specific issues. Communicate findings and mitigation plan."
708,Diagnose a 15% drop in video engagement on YouTube.,ðŸŸ¢,P1,Metric Drop Diagnosis,Clarify Metric â†’ Segment â†’ Hypothesize â†’ Data Check â†’ Action,Engagement drop; metric diagnosis,"Clarify: Define the metric (numerator/denominator), baseline, and scope. Specify: engagement = what exactly? Time window: when did it start? Magnitude: how significant?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Verify tracking accuracy, ETL lag, or event schema changes.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), content type, feature usage, and time of day to find engagement drivers.

Hypothesize: Product changes (UI, pricing, policy), external factors (competitor, seasonality), performance issues (latency, crashes), or supply-side changes (if marketplace).

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and compare to control segments. Look for crash rates, error codes, or performance degradation.

Action: If severe + clear cause â†’ rollback/hotfix immediately. If unclear â†’ add logging, run targeted experiments, or fix segment-specific issues. Communicate findings and mitigation plan."
709,Diagnose a 20% drop in Facebook Groups usage.,ðŸŸ¢,P1,Metric Drop Diagnosis,Clarify Metric â†’ Segment â†’ Hypothesize â†’ Data Check â†’ Action,Usage drop; metric diagnosis,"Clarify: Define the metric (numerator/denominator), baseline, and scope. Specify: usage = what exactly? Time window: when did it start? Magnitude: how significant?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Verify tracking accuracy, ETL lag, or event schema changes.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), content type, feature usage, and time of day to find engagement drivers.

Hypothesize: Product changes (UI, pricing, policy), external factors (competitor, seasonality), performance issues (latency, crashes), or supply-side changes (if marketplace).

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and compare to control segments. Look for crash rates, error codes, or performance degradation.

Action: If severe + clear cause â†’ rollback/hotfix immediately. If unclear â†’ add logging, run targeted experiments, or fix segment-specific issues. Communicate findings and mitigation plan."
710,Diagnose a 25% decrease in conversions on Opencare.,ðŸŸ¢,P1,Metric Drop Diagnosis,Clarify Metric â†’ Segment â†’ Hypothesize â†’ Data Check â†’ Action,Conversion drop; metric diagnosis,"Clarify: Define the metric (numerator/denominator), baseline, and scope. Specify: conversion = what exactly? Time window: when did it start? Magnitude: how significant?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Verify tracking accuracy, ETL lag, or event schema changes.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), funnel step, acquisition channel, and user segment to find the hot spot.

Hypothesize: Product changes (UI, pricing, policy), external factors (competitor, seasonality), performance issues (latency, crashes), or supply-side changes (if marketplace).

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and compare to control segments. Look for crash rates, error codes, or performance degradation.

Action: If severe + clear cause â†’ rollback/hotfix immediately. If unclear â†’ add logging, run targeted experiments, or fix segment-specific issues. Communicate findings and mitigation plan."
711,Diagnose a 25% decrease in free sign ups on Notion.,ðŸŸ¢,P1,Metric Drop Diagnosis,Clarify Metric â†’ Segment â†’ Hypothesize â†’ Data Check â†’ Action,Sign-up drop; metric diagnosis,"Clarify: Define the metric (numerator/denominator), baseline, and scope. Time window: when did it start? Magnitude: how significant?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Verify tracking accuracy, ETL lag, or event schema changes.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), funnel step, acquisition channel, and user segment to find the hot spot.

Hypothesize: Product changes (UI, pricing, policy), external factors (competitor, seasonality), performance issues (latency, crashes), or supply-side changes (if marketplace).

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and compare to control segments. Look for crash rates, error codes, or performance degradation.

Action: If severe + clear cause â†’ rollback/hotfix immediately. If unclear â†’ add logging, run targeted experiments, or fix segment-specific issues. Communicate findings and mitigation plan."
712,Diagnose a 25% decrease in song listens on Spotify.,ðŸŸ¢,P1,Metric Drop Diagnosis,Clarify Metric â†’ Segment â†’ Hypothesize â†’ Data Check â†’ Action,Engagement drop; metric diagnosis,"Clarify: Define the metric (numerator/denominator), baseline, and scope. Time window: when did it start? Magnitude: how significant?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Verify tracking accuracy, ETL lag, or event schema changes.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), funnel step, acquisition channel, and user segment to find the hot spot.

Hypothesize: Product changes (UI, pricing, policy), external factors (competitor, seasonality), performance issues (latency, crashes), or supply-side changes (if marketplace).

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and compare to control segments. Look for crash rates, error codes, or performance degradation.

Action: If severe + clear cause â†’ rollback/hotfix immediately. If unclear â†’ add logging, run targeted experiments, or fix segment-specific issues. Communicate findings and mitigation plan."
713,Diagnose a 25% drop in conversion on Wealthsimple's landing page.,ðŸŸ¢,P1,Metric Drop Diagnosis,Clarify Metric â†’ Segment â†’ Hypothesize â†’ Data Check â†’ Action,Conversion drop; metric diagnosis,"Clarify: Define the metric (numerator/denominator), baseline, and scope. Specify: conversion = what exactly? Time window: when did it start? Magnitude: how significant?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Verify tracking accuracy, ETL lag, or event schema changes.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), funnel step, acquisition channel, and user segment to find the hot spot.

Hypothesize: Product changes (UI, pricing, policy), external factors (competitor, seasonality), performance issues (latency, crashes), or supply-side changes (if marketplace).

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and compare to control segments. Look for crash rates, error codes, or performance degradation.

Action: If severe + clear cause â†’ rollback/hotfix immediately. If unclear â†’ add logging, run targeted experiments, or fix segment-specific issues. Communicate findings and mitigation plan."
714,Diagnose a 35% decrease in email open rates on SendGrid.,ðŸŸ¢,P1,Metric Drop Diagnosis,Clarify Metric â†’ Segment â†’ Hypothesize â†’ Data Check â†’ Action,Email open rate drop; metric diagnosis,"Clarify: Define the metric (numerator/denominator), baseline, and scope. Time window: when did it start? Magnitude: how significant?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Verify tracking accuracy, ETL lag, or event schema changes.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), funnel step, acquisition channel, and user segment to find the hot spot.

Hypothesize: Product changes (UI, pricing, policy), external factors (competitor, seasonality), performance issues (latency, crashes), or supply-side changes (if marketplace).

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and compare to control segments. Look for crash rates, error codes, or performance degradation.

Action: If severe + clear cause â†’ rollback/hotfix immediately. If unclear â†’ add logging, run targeted experiments, or fix segment-specific issues. Communicate findings and mitigation plan."
716,Diagnose a 35% drop in usage on Invision.,ðŸŸ¢,P1,Metric Drop Diagnosis,Clarify Metric â†’ Segment â†’ Hypothesize â†’ Data Check â†’ Action,Usage drop; metric diagnosis,"Clarify: Define the metric (numerator/denominator), baseline, and scope. Specify: usage = what exactly? Time window: when did it start? Magnitude: how significant?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Verify tracking accuracy, ETL lag, or event schema changes.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), content type, feature usage, and time of day to find engagement drivers.

Hypothesize: Product changes (UI, pricing, policy), external factors (competitor, seasonality), performance issues (latency, crashes), or supply-side changes (if marketplace).

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and compare to control segments. Look for crash rates, error codes, or performance degradation.

Action: If severe + clear cause â†’ rollback/hotfix immediately. If unclear â†’ add logging, run targeted experiments, or fix segment-specific issues. Communicate findings and mitigation plan."
718,Diagnose a 45% drop in ride orders on Lyft.,ðŸŸ¢,P1,Metric Drop Diagnosis,Clarify Metric â†’ Segment â†’ Hypothesize â†’ Data Check â†’ Action,Ride orders drop; metric diagnosis,"Clarify: Define the metric (numerator/denominator), baseline, and scope. Specify: orders = what exactly? Time window: when did it start? Magnitude: how significant?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Verify tracking accuracy, ETL lag, or event schema changes.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), funnel step, acquisition channel, and user segment to find the hot spot.

Hypothesize: Product changes (UI, pricing, policy), external factors (competitor, seasonality), performance issues (latency, crashes), or supply-side changes (if marketplace).

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and compare to control segments. Look for crash rates, error codes, or performance degradation.

Action: If severe + clear cause â†’ rollback/hotfix immediately. If unclear â†’ add logging, run targeted experiments, or fix segment-specific issues. Communicate findings and mitigation plan."
778,Events created are down 100% on Facebook - why?,ðŸŸ¢,P1,Metric Drop Diagnosis,Clarify Metric â†’ Segment â†’ Hypothesize â†’ Data Check â†’ Action,Metric drop; complete drop-off,"Clarify: Define the metric (numerator/denominator), baseline, and scope. Time window: when did it start? Magnitude: how significant?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Verify tracking accuracy, ETL lag, or event schema changes.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), funnel step, acquisition channel, and user segment to find the hot spot.

Hypothesize: Product changes (UI, pricing, policy), external factors (competitor, seasonality), performance issues (latency, crashes), or supply-side changes (if marketplace).

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and compare to control segments. Look for crash rates, error codes, or performance degradation.

Action: If severe + clear cause â†’ rollback/hotfix immediately. If unclear â†’ add logging, run targeted experiments, or fix segment-specific issues. Communicate findings and mitigation plan."
994,Google searches are down 35%. What happened?,ðŸŸ¢,P1,Metric Drop Diagnosis,Clarify Metric â†’ Segment â†’ Hypothesize â†’ Data Check â†’ Action,Metric drop; incident response,"Clarify: Define the metric (numerator/denominator), baseline, and scope. Time window: when did it start? Magnitude: how significant?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Verify tracking accuracy, ETL lag, or event schema changes.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), funnel step, acquisition channel, and user segment to find the hot spot.

Hypothesize: Product changes (UI, pricing, policy), external factors (competitor, seasonality), performance issues (latency, crashes), or supply-side changes (if marketplace).

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and compare to control segments. Look for crash rates, error codes, or performance degradation.

Action: If severe + clear cause â†’ rollback/hotfix immediately. If unclear â†’ add logging, run targeted experiments, or fix segment-specific issues. Communicate findings and mitigation plan."
1014,Help a premium airline with declining bookings in the business category.,ðŸŸ¢,P1,Metric Drop Diagnosis,Clarify Metric â†’ Segment â†’ Hypothesize â†’ Data Check â†’ Action,Booking decline; metric diagnosis,"Clarify: Define the key metric(s) and success criteria. What exactly needs to change? Baseline and target?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Ensure data quality and measurement consistency.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), listing type, and booking window to find highest-leverage opportunities.

Hypothesize: Top 3-5 potential causes ranked by likelihood Ã— impact. Consider product, user, market, and technical factors.

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and analyze user behavior patterns. Use session replays, surveys, or log analysis.

Action: Prioritize fixes by impact Ã— confidence. Start with data issues, then high-impact hypotheses. Run experiments, monitor results, and communicate plan."
1019,High Volume Low Success.,ðŸŸ¢,P1,Metric Drop Diagnosis,Clarify Metric â†’ Segment â†’ Hypothesize â†’ Data Check â†’ Action,Metric pattern; volume vs success,"Clarify: Define the key metric(s) and success criteria. What exactly needs to change? Baseline and target?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Ensure data quality and measurement consistency.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), funnel step, acquisition channel, and user segment to find the hot spot.

Hypothesize: Top 3-5 potential causes ranked by likelihood Ã— impact. Consider product, user, market, and technical factors.

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and analyze user behavior patterns. Use session replays, surveys, or log analysis.

Action: Prioritize fixes by impact Ã— confidence. Start with data issues, then high-impact hypotheses. Run experiments, monitor results, and communicate plan."
1027,How can you improve Facebook's DAU?,ðŸŸ¢,P1,Metric Drop Diagnosis,Clarify Metric â†’ Segment â†’ Hypothesize â†’ Data Check â†’ Action,DAU improvement; metric diagnosis,"Clarify: Define success metric and target. Scope: which segments, surfaces, or user types?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Confirm measurement is accurate and not inflated by bots or data quality issues.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), funnel step, acquisition channel, and user segment to find the hot spot.

Hypothesize: Search relevance, pricing optimization, trust signals, supply quality, feature adoption, or user experience improvements.

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and test hypotheses with A/B tests or targeted experiments. Compare conversion rates by segment.

Action: Focus on highest-impact segments. Implement fixes: improve search/ranking, optimize pricing, add trust signals, or enhance UX. Measure impact and iterate."
1242,How would you analyze why user engagement is declining?,ðŸŸ¢,P1,Metric Drop Diagnosis,Metric â†’ Segment â†’ Hypothesis â†’ Data Check â†’ Action,Engagement decline; metric analysis,"Clarify: Define the key metric(s) and success criteria. What exactly needs to change? Baseline and target?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Ensure data quality and measurement consistency.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), content type, feature usage, and time of day to find engagement drivers.

Hypothesize: Top 3-5 potential causes ranked by likelihood Ã— impact. Consider product, user, market, and technical factors.

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and analyze user behavior patterns. Use session replays, surveys, or log analysis.

Action: Prioritize fixes by impact Ã— confidence. Start with data issues, then high-impact hypotheses. Run experiments, monitor results, and communicate plan."
1288,How would you debug a decline in sales and decide whether to build a new feature or not?,ðŸŸ¢,P1,Metric Drop Diagnosis,Metric â†’ Segment â†’ Hypothesis â†’ Data Check â†’ Action,Sales decline; metric analysis,"Clarify: Define the metric (numerator/denominator), baseline, and scope. Time window: when did it start? Magnitude: how significant?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Verify tracking accuracy, ETL lag, or event schema changes.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), funnel step, acquisition channel, and user segment to find the hot spot.

Hypothesize: Product changes (UI, pricing, policy), external factors (competitor, seasonality), performance issues (latency, crashes), or supply-side changes (if marketplace).

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and compare to control segments. Look for crash rates, error codes, or performance degradation.

Action: If severe + clear cause â†’ rollback/hotfix immediately. If unclear â†’ add logging, run targeted experiments, or fix segment-specific issues. Communicate findings and mitigation plan."
1343,How would you evaluate the impact of fake news on Facebook users?,ðŸŸ¢,P1,Metric Drop Diagnosis,Metric â†’ Segment â†’ Hypothesis â†’ Data Check â†’ Action,Impact evaluation; metric analysis,"Clarify: Define the key metric(s) and success criteria. What exactly needs to change? Baseline and target?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Ensure data quality and measurement consistency.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), funnel step, acquisition channel, and user segment to find the hot spot.

Hypothesize: Top 3-5 potential causes ranked by likelihood Ã— impact. Consider product, user, market, and technical factors.

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and analyze user behavior patterns. Use session replays, surveys, or log analysis.

Action: Prioritize fixes by impact Ã— confidence. Start with data issues, then high-impact hypotheses. Run experiments, monitor results, and communicate plan."
1368,How would you handle a situation where qualitative insights contradict quantitative data?,ðŸŸ¢,P1,Metric Drop Diagnosis,Metric â†’ Segment â†’ Hypothesis â†’ Data Check â†’ Action,Data contradiction; metric analysis,"Clarify: Define the key metric(s) and success criteria. What exactly needs to change? Baseline and target?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Ensure data quality and measurement consistency.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), funnel step, acquisition channel, and user segment to find the hot spot.

Hypothesize: Top 3-5 potential causes ranked by likelihood Ã— impact. Consider product, user, market, and technical factors.

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and analyze user behavior patterns. Use session replays, surveys, or log analysis.

Action: Prioritize fixes by impact Ã— confidence. Start with data issues, then high-impact hypotheses. Run experiments, monitor results, and communicate plan."
1378,How would you identify inefficiencies in a team's workflow using data?,ðŸŸ¢,P1,Metric Drop Diagnosis,Metric â†’ Segment â†’ Hypothesis â†’ Data Check â†’ Action,Workflow inefficiency; metric analysis,"Clarify: Define the key metric(s) and success criteria. What exactly needs to change? Baseline and target?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Ensure data quality and measurement consistency.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), funnel step, acquisition channel, and user segment to find the hot spot.

Hypothesize: Top 3-5 potential causes ranked by likelihood Ã— impact. Consider product, user, market, and technical factors.

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and analyze user behavior patterns. Use session replays, surveys, or log analysis.

Action: Prioritize fixes by impact Ã— confidence. Start with data issues, then high-impact hypotheses. Run experiments, monitor results, and communicate plan."
1472,How would you investigate a week-over-week 10% drop in successful deliveries?,ðŸŸ¢,P1,Metric Drop Diagnosis,Metric â†’ Segment â†’ Hypothesis â†’ Data Check â†’ Action,Delivery drop; metric analysis,"Clarify: Define the metric (numerator/denominator), baseline, and scope. Specify: deliveries = what exactly? Time window: when did it start? Magnitude: how significant?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Verify tracking accuracy, ETL lag, or event schema changes.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), funnel step, acquisition channel, and user segment to find the hot spot.

Hypothesize: Product changes (UI, pricing, policy), external factors (competitor, seasonality), performance issues (latency, crashes), or supply-side changes (if marketplace).

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and compare to control segments. Look for crash rates, error codes, or performance degradation.

Action: If severe + clear cause â†’ rollback/hotfix immediately. If unclear â†’ add logging, run targeted experiments, or fix segment-specific issues. Communicate findings and mitigation plan."
1473,How would you investigate the 10% of inactive Netflix users?,ðŸŸ¢,P1,Metric Drop Diagnosis,Metric â†’ Segment â†’ Hypothesis â†’ Data Check â†’ Action,User inactivity; metric analysis,"Clarify: Define the key metric(s) and success criteria. What exactly needs to change? Baseline and target?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Ensure data quality and measurement consistency.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), funnel step, acquisition channel, and user segment to find the hot spot.

Hypothesize: Top 3-5 potential causes ranked by likelihood Ã— impact. Consider product, user, market, and technical factors.

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and analyze user behavior patterns. Use session replays, surveys, or log analysis.

Action: Prioritize fixes by impact Ã— confidence. Start with data issues, then high-impact hypotheses. Run experiments, monitor results, and communicate plan."
1549,How would you reduce attrition in a team/organization?,ðŸŸ¢,P1,Metric Drop Diagnosis,Metric â†’ Segment â†’ Hypothesis â†’ Data Check â†’ Action,Attrition reduction; metric analysis,"Clarify: Define the key metric(s) and success criteria. What exactly needs to change? Baseline and target?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Ensure data quality and measurement consistency.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), funnel step, acquisition channel, and user segment to find the hot spot.

Hypothesize: Top 3-5 potential causes ranked by likelihood Ã— impact. Consider product, user, market, and technical factors.

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and analyze user behavior patterns. Use session replays, surveys, or log analysis.

Action: Prioritize fixes by impact Ã— confidence. Start with data issues, then high-impact hypotheses. Run experiments, monitor results, and communicate plan."
1550,How would you reduce cancellations on Uber?,ðŸŸ¢,P1,Metric Drop Diagnosis,Metric â†’ Segment â†’ Hypothesis â†’ Data Check â†’ Action,Cancellation reduction; metric analysis,"Clarify: Define the key metric(s) and success criteria. What exactly needs to change? Baseline and target?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Ensure data quality and measurement consistency.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), funnel step, acquisition channel, and user segment to find the hot spot.

Hypothesize: Top 3-5 potential causes ranked by likelihood Ã— impact. Consider product, user, market, and technical factors.

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and analyze user behavior patterns. Use session replays, surveys, or log analysis.

Action: Prioritize fixes by impact Ã— confidence. Start with data issues, then high-impact hypotheses. Run experiments, monitor results, and communicate plan."
1551,How would you reduce the number of customer support tickets from users on our rideshare app?,ðŸŸ¢,P1,Metric Drop Diagnosis,Metric â†’ Segment â†’ Hypothesis â†’ Data Check â†’ Action,Support ticket reduction; metric analysis,"Clarify: Define success metric and target. Current tickets rate? Target growth? Scope: which segments, surfaces, or user types?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Confirm measurement is accurate and not inflated by bots or data quality issues.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), funnel step, acquisition channel, and user segment to find the hot spot.

Hypothesize: Search relevance, pricing optimization, trust signals, supply quality, feature adoption, or user experience improvements.

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and test hypotheses with A/B tests or targeted experiments. Compare conversion rates by segment.

Action: Focus on highest-impact segments. Implement fixes: improve search/ranking, optimize pricing, add trust signals, or enhance UX. Measure impact and iterate."
1582,How would you use data to help Snap engineering improve phone camera speed?,ðŸŸ¢,P1,Metric Drop Diagnosis,Metric â†’ Segment â†’ Hypothesis â†’ Data Check â†’ Action,Performance improvement; metric analysis,"Clarify: Define success metric and target. Scope: which segments, surfaces, or user types?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Confirm measurement is accurate and not inflated by bots or data quality issues.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), funnel step, acquisition channel, and user segment to find the hot spot.

Hypothesize: Search relevance, pricing optimization, trust signals, supply quality, feature adoption, or user experience improvements.

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and test hypotheses with A/B tests or targeted experiments. Compare conversion rates by segment.

Action: Focus on highest-impact segments. Implement fixes: improve search/ranking, optimize pricing, add trust signals, or enhance UX. Measure impact and iterate."
1595,"If customer support tickets are increasing, how would you investigate and solve this issue?",ðŸŸ¢,P1,Metric Drop Diagnosis,Metric â†’ Segment â†’ Hypothesis â†’ Data Check â†’ Action,Support ticket increase; metric analysis,"Clarify: Define success metric and target. Current tickets rate? Target growth? Scope: which segments, surfaces, or user types?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Confirm measurement is accurate and not inflated by bots or data quality issues.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), funnel step, acquisition channel, and user segment to find the hot spot.

Hypothesize: Search relevance, pricing optimization, trust signals, supply quality, feature adoption, or user experience improvements.

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and test hypotheses with A/B tests or targeted experiments. Compare conversion rates by segment.

Action: Focus on highest-impact segments. Implement fixes: improve search/ranking, optimize pricing, add trust signals, or enhance UX. Measure impact and iterate."
1627,"If you noticed a 10% decrease in an app's conversion rate, what steps would you take to investigate and resolve the issue?",ðŸŸ¢,P1,Metric Drop Diagnosis,Metric â†’ Segment â†’ Hypothesis â†’ Data Check â†’ Action,Conversion drop; metric analysis,"Clarify: Define the metric (numerator/denominator), baseline, and scope. Specify: conversion = what exactly? Time window: when did it start? Magnitude: how significant?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Verify tracking accuracy, ETL lag, or event schema changes.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), funnel step, acquisition channel, and user segment to find the hot spot.

Hypothesize: Product changes (UI, pricing, policy), external factors (competitor, seasonality), performance issues (latency, crashes), or supply-side changes (if marketplace).

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and compare to control segments. Look for crash rates, error codes, or performance degradation.

Action: If severe + clear cause â†’ rollback/hotfix immediately. If unclear â†’ add logging, run targeted experiments, or fix segment-specific issues. Communicate findings and mitigation plan."
1644,Imagine you're a data scientist at Meta. There's been a sudden 10% drop in Facebook's daily post views. How would you investigate?,ðŸŸ¢,P1,Metric Drop Diagnosis,Metric â†’ Segment â†’ Hypothesis â†’ Data Check â†’ Action,Post views drop; metric analysis,"Clarify: Define the metric (numerator/denominator), baseline, and scope. Time window: when did it start? Magnitude: how significant?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Verify tracking accuracy, ETL lag, or event schema changes.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), funnel step, acquisition channel, and user segment to find the hot spot.

Hypothesize: Product changes (UI, pricing, policy), external factors (competitor, seasonality), performance issues (latency, crashes), or supply-side changes (if marketplace).

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and compare to control segments. Look for crash rates, error codes, or performance degradation.

Action: If severe + clear cause â†’ rollback/hotfix immediately. If unclear â†’ add logging, run targeted experiments, or fix segment-specific issues. Communicate findings and mitigation plan."
1700,Instagram sees a 5% decrease in Daily Active Users (DAU) over a week. How do you determine the root cause?,ðŸŸ¢,P1,Metric Drop Diagnosis,Metric â†’ Segment â†’ Hypothesis â†’ Data Check â†’ Action,DAU drop; metric analysis,"Clarify: Define the metric (numerator/denominator), baseline, and scope. Time window: when did it start? Magnitude: how significant?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Verify tracking accuracy, ETL lag, or event schema changes.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), funnel step, acquisition channel, and user segment to find the hot spot.

Hypothesize: Product changes (UI, pricing, policy), external factors (competitor, seasonality), performance issues (latency, crashes), or supply-side changes (if marketplace).

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and compare to control segments. Look for crash rates, error codes, or performance degradation.

Action: If severe + clear cause â†’ rollback/hotfix immediately. If unclear â†’ add logging, run targeted experiments, or fix segment-specific issues. Communicate findings and mitigation plan."
1701,"Installs are down 35% on DoorDash's iOS app, what do you do?",ðŸŸ¢,P1,Metric Drop Diagnosis,Metric â†’ Segment â†’ Hypothesis â†’ Data Check â†’ Action,Install drop; metric analysis,"Clarify: Define the metric (numerator/denominator), baseline, and scope. Specify: installs = what exactly? Time window: when did it start? Magnitude: how significant?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Verify tracking accuracy, ETL lag, or event schema changes.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), funnel step, acquisition channel, and user segment to find the hot spot.

Hypothesize: Product changes (UI, pricing, policy), external factors (competitor, seasonality), performance issues (latency, crashes), or supply-side changes (if marketplace).

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and compare to control segments. Look for crash rates, error codes, or performance degradation.

Action: If severe + clear cause â†’ rollback/hotfix immediately. If unclear â†’ add logging, run targeted experiments, or fix segment-specific issues. Communicate findings and mitigation plan."
1702,"Installs on LinkedIn's iOS app are down, what do you do?",ðŸŸ¢,P1,Metric Drop Diagnosis,Metric â†’ Segment â†’ Hypothesis â†’ Data Check â†’ Action,Install drop; metric analysis,"Clarify: Define the metric (numerator/denominator), baseline, and scope. Specify: installs = what exactly? Time window: when did it start? Magnitude: how significant?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Verify tracking accuracy, ETL lag, or event schema changes.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), funnel step, acquisition channel, and user segment to find the hot spot.

Hypothesize: Product changes (UI, pricing, policy), external factors (competitor, seasonality), performance issues (latency, crashes), or supply-side changes (if marketplace).

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and compare to control segments. Look for crash rates, error codes, or performance degradation.

Action: If severe + clear cause â†’ rollback/hotfix immediately. If unclear â†’ add logging, run targeted experiments, or fix segment-specific issues. Communicate findings and mitigation plan."
1711,Let's say a marketing campaign underperformedâ€”what would you do?,ðŸŸ¢,P1,Metric Drop Diagnosis,Metric â†’ Segment â†’ Hypothesis â†’ Data Check â†’ Action,Campaign underperformance; metric analysis,"Clarify: Define the key metric(s) and success criteria. What exactly needs to change? Baseline and target?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Ensure data quality and measurement consistency.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), funnel step, acquisition channel, and user segment to find the hot spot.

Hypothesize: Top 3-5 potential causes ranked by likelihood Ã— impact. Consider product, user, market, and technical factors.

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and analyze user behavior patterns. Use session replays, surveys, or log analysis.

Action: Prioritize fixes by impact Ã— confidence. Start with data issues, then high-impact hypotheses. Run experiments, monitor results, and communicate plan."
1742,Meta's new app shows 25% drop-off at sign-up. How do you analyze this?,ðŸŸ¢,P1,Metric Drop Diagnosis,Metric â†’ Segment â†’ Hypothesis â†’ Data Check â†’ Action,Sign-up drop-off; metric analysis,"Clarify: Define the metric (numerator/denominator), baseline, and scope. Specify: drop-off = what exactly? Time window: when did it start? Magnitude: how significant?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Verify tracking accuracy, ETL lag, or event schema changes.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), funnel step, acquisition channel, and user segment to find the hot spot.

Hypothesize: Product changes (UI, pricing, policy), external factors (competitor, seasonality), performance issues (latency, crashes), or supply-side changes (if marketplace).

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and compare to control segments. Look for crash rates, error codes, or performance degradation.

Action: If severe + clear cause â†’ rollback/hotfix immediately. If unclear â†’ add logging, run targeted experiments, or fix segment-specific issues. Communicate findings and mitigation plan."
1743,"Metrics moved in different directions, how do you interpret the results and decide next steps?",ðŸŸ¢,P1,Metric Drop Diagnosis,Metric â†’ Segment â†’ Hypothesis â†’ Data Check â†’ Action,Mixed metrics; metric analysis,"Clarify: Define the key metric(s) and success criteria. What exactly needs to change? Baseline and target?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Ensure data quality and measurement consistency.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), funnel step, acquisition channel, and user segment to find the hot spot.

Hypothesize: Top 3-5 potential causes ranked by likelihood Ã— impact. Consider product, user, market, and technical factors.

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and analyze user behavior patterns. Use session replays, surveys, or log analysis.

Action: Prioritize fixes by impact Ã— confidence. Start with data issues, then high-impact hypotheses. Run experiments, monitor results, and communicate plan."
1752,"On DoorDash, there are missing item and wrong item issues for deliveries. How would you analyze each of them?",ðŸŸ¢,P1,Metric Drop Diagnosis,Metric â†’ Segment â†’ Hypothesis â†’ Data Check â†’ Action,Delivery issues; metric analysis,"Clarify: Define the key metric(s) and success criteria. What exactly needs to change? Baseline and target?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Ensure data quality and measurement consistency.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), funnel step, acquisition channel, and user segment to find the hot spot.

Hypothesize: Top 3-5 potential causes ranked by likelihood Ã— impact. Consider product, user, market, and technical factors.

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and analyze user behavior patterns. Use session replays, surveys, or log analysis.

Action: Prioritize fixes by impact Ã— confidence. Start with data issues, then high-impact hypotheses. Run experiments, monitor results, and communicate plan."
1754,One of your clients has experienced a 20% decline in profits. What would you do?,ðŸŸ¢,P1,Metric Drop Diagnosis,Metric â†’ Segment â†’ Hypothesis â†’ Data Check â†’ Action,Profit decline; metric analysis,"Clarify: Define the metric (numerator/denominator), baseline, and scope. Time window: when did it start? Magnitude: how significant?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Verify tracking accuracy, ETL lag, or event schema changes.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), funnel step, acquisition channel, and user segment to find the hot spot.

Hypothesize: Product changes (UI, pricing, policy), external factors (competitor, seasonality), performance issues (latency, crashes), or supply-side changes (if marketplace).

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and compare to control segments. Look for crash rates, error codes, or performance degradation.

Action: If severe + clear cause â†’ rollback/hotfix immediately. If unclear â†’ add logging, run targeted experiments, or fix segment-specific issues. Communicate findings and mitigation plan."
1759,Overstretched Employees,ðŸŸ¢,P1,Metric Drop Diagnosis,Metric â†’ Segment â†’ Hypothesis â†’ Data Check â†’ Action,Employee metrics; metric analysis,"Clarify: Define the key metric(s) and success criteria. What exactly needs to change? Baseline and target?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Ensure data quality and measurement consistency.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), funnel step, acquisition channel, and user segment to find the hot spot.

Hypothesize: Top 3-5 potential causes ranked by likelihood Ã— impact. Consider product, user, market, and technical factors.

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and analyze user behavior patterns. Use session replays, surveys, or log analysis.

Action: Prioritize fixes by impact Ã— confidence. Start with data issues, then high-impact hypotheses. Run experiments, monitor results, and communicate plan."
1841,Spotify installs increased 25%. What happened?,ðŸŸ¢,P1,Metric Drop Diagnosis,Metric â†’ Segment â†’ Hypothesis â†’ Data Check â†’ Action,Install increase; metric analysis,"Clarify: Define success metric and target. Current installs rate? Target growth? Scope: which segments, surfaces, or user types?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Confirm measurement is accurate and not inflated by bots or data quality issues.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), funnel step, acquisition channel, and user segment to find the hot spot.

Hypothesize: Search relevance, pricing optimization, trust signals, supply quality, feature adoption, or user experience improvements.

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and test hypotheses with A/B tests or targeted experiments. Compare conversion rates by segment.

Action: Focus on highest-impact segments. Implement fixes: improve search/ranking, optimize pricing, add trust signals, or enhance UX. Measure impact and iterate."
2154,The company observes that drivers spend significantly less active time on grocery store orders compared to convenience store orders. What next steps would you take?,ðŸŸ¢,P1,Metric Drop Diagnosis,Metric â†’ Segment â†’ Hypothesis â†’ Data Check â†’ Action,Time difference; metric analysis,"Clarify: Define the key metric(s) and success criteria. What exactly needs to change? Baseline and target?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Ensure data quality and measurement consistency.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), funnel step, acquisition channel, and user segment to find the hot spot.

Hypothesize: Top 3-5 potential causes ranked by likelihood Ã— impact. Consider product, user, market, and technical factors.

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and analyze user behavior patterns. Use session replays, surveys, or log analysis.

Action: Prioritize fixes by impact Ã— confidence. Start with data issues, then high-impact hypotheses. Run experiments, monitor results, and communicate plan."
2155,The conversion ratio on OpenTable dipped by 10% in one day. What could be the cause?,ðŸŸ¢,P1,Metric Drop Diagnosis,Metric â†’ Segment â†’ Hypothesis â†’ Data Check â†’ Action,Conversion drop; metric analysis,"Clarify: Define the metric (numerator/denominator), baseline, and scope. Specify: conversion = what exactly? Time window: when did it start? Magnitude: how significant?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Verify tracking accuracy, ETL lag, or event schema changes.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), funnel step, acquisition channel, and user segment to find the hot spot.

Hypothesize: Product changes (UI, pricing, policy), external factors (competitor, seasonality), performance issues (latency, crashes), or supply-side changes (if marketplace).

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and compare to control segments. Look for crash rates, error codes, or performance degradation.

Action: If severe + clear cause â†’ rollback/hotfix immediately. If unclear â†’ add logging, run targeted experiments, or fix segment-specific issues. Communicate findings and mitigation plan."
2158,"The same-store sales are declining for one of your local supermarket chains. As a PM, how will you build products and features to serve the need of users?",ðŸŸ¢,P1,Metric Drop Diagnosis,Metric â†’ Segment â†’ Hypothesis â†’ Data Check â†’ Action,Sales decline; product strategy,"Clarify: Define success metric and target. Scope: which segments, surfaces, or user types?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Confirm measurement is accurate and not inflated by bots or data quality issues.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), funnel step, acquisition channel, and user segment to find the hot spot.

Hypothesize: Search relevance, pricing optimization, trust signals, supply quality, feature adoption, or user experience improvements.

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and test hypotheses with A/B tests or targeted experiments. Compare conversion rates by segment.

Action: Focus on highest-impact segments. Implement fixes: improve search/ranking, optimize pricing, add trust signals, or enhance UX. Measure impact and iterate."
2159,The usage of Meta AI within Instagram DMs is up while the usage of Meta AI within the Search Bar of IG Discover page is down. How would you investigate?,ðŸŸ¢,P1,Metric Drop Diagnosis,Metric â†’ Segment â†’ Hypothesis â†’ Data Check â†’ Action,Usage divergence; metric analysis,"Clarify: Define the metric (numerator/denominator), baseline, and scope. Specify: usage = what exactly? Time window: when did it start? Magnitude: how significant?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Verify tracking accuracy, ETL lag, or event schema changes.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), content type, feature usage, and time of day to find engagement drivers.

Hypothesize: Product changes (UI, pricing, policy), external factors (competitor, seasonality), performance issues (latency, crashes), or supply-side changes (if marketplace).

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and compare to control segments. Look for crash rates, error codes, or performance degradation.

Action: If severe + clear cause â†’ rollback/hotfix immediately. If unclear â†’ add logging, run targeted experiments, or fix segment-specific issues. Communicate findings and mitigation plan."
2160,There's a YoY slowdown in transactions. How would you structure your analysis?,ðŸŸ¢,P1,Metric Drop Diagnosis,Metric â†’ Segment â†’ Hypothesis â†’ Data Check â†’ Action,Transaction slowdown; metric analysis,"Clarify: Define the metric (numerator/denominator), baseline, and scope. Specify: transactions = what exactly? Time window: when did it start? Magnitude: how significant?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Verify tracking accuracy, ETL lag, or event schema changes.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), product category, discovery surface, and payment method to identify friction points.

Hypothesize: Product changes (UI, pricing, policy), external factors (competitor, seasonality), performance issues (latency, crashes), or supply-side changes (if marketplace).

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and compare to control segments. Look for crash rates, error codes, or performance degradation.

Action: If severe + clear cause â†’ rollback/hotfix immediately. If unclear â†’ add logging, run targeted experiments, or fix segment-specific issues. Communicate findings and mitigation plan."
2171,Uber booking rates have dropped by 10%. How would you address this?,ðŸŸ¢,P1,Metric Drop Diagnosis,Metric â†’ Segment â†’ Hypothesis â†’ Data Check â†’ Action,Booking drop; metric analysis,"Clarify: Define the metric (numerator/denominator), baseline, and scope. Time window: when did it start? Magnitude: how significant?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Verify tracking accuracy, ETL lag, or event schema changes.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), listing type, and booking window to find highest-leverage opportunities.

Hypothesize: Product changes (UI, pricing, policy), external factors (competitor, seasonality), performance issues (latency, crashes), or supply-side changes (if marketplace).

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and compare to control segments. Look for crash rates, error codes, or performance degradation.

Action: If severe + clear cause â†’ rollback/hotfix immediately. If unclear â†’ add logging, run targeted experiments, or fix segment-specific issues. Communicate findings and mitigation plan."
2175,"Users are creating more Instagram Stories, but engagement is down. What metrics would you track to improve this?",ðŸŸ¢,P1,Metric Drop Diagnosis,Metric â†’ Segment â†’ Hypothesis â†’ Data Check â†’ Action,Engagement issue; metric analysis,"Clarify: Define the metric (numerator/denominator), baseline, and scope. Specify: engagement = what exactly? Time window: when did it start? Magnitude: how significant?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Verify tracking accuracy, ETL lag, or event schema changes.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), content type, feature usage, and time of day to find engagement drivers.

Hypothesize: Product changes (UI, pricing, policy), external factors (competitor, seasonality), performance issues (latency, crashes), or supply-side changes (if marketplace).

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and compare to control segments. Look for crash rates, error codes, or performance degradation.

Action: If severe + clear cause â†’ rollback/hotfix immediately. If unclear â†’ add logging, run targeted experiments, or fix segment-specific issues. Communicate findings and mitigation plan."
2181,Walk me through a time you diagnosed a drop in conversion.,ðŸŸ¢,P1,Metric Drop Diagnosis,Metric â†’ Segment â†’ Hypothesis â†’ Data Check â†’ Action,Conversion diagnosis; behavioral question,"Clarify: Define the metric (numerator/denominator), baseline, and scope. Specify: conversion = what exactly? Time window: when did it start? Magnitude: how significant?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Verify tracking accuracy, ETL lag, or event schema changes.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), funnel step, acquisition channel, and user segment to find the hot spot.

Hypothesize: Product changes (UI, pricing, policy), external factors (competitor, seasonality), performance issues (latency, crashes), or supply-side changes (if marketplace).

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and compare to control segments. Look for crash rates, error codes, or performance degradation.

Action: If severe + clear cause â†’ rollback/hotfix immediately. If unclear â†’ add logging, run targeted experiments, or fix segment-specific issues. Communicate findings and mitigation plan."
2291,What factors would you investigate to determine why the app is underperforming in a new geography?,ðŸŸ¢,P1,Metric Drop Diagnosis,Metric â†’ Segment â†’ Hypothesis â†’ Data Check â†’ Action,Geographic underperformance; metric analysis,"Clarify: Define the key metric(s) and success criteria. What exactly needs to change? Baseline and target?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Ensure data quality and measurement consistency.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), funnel step, acquisition channel, and user segment to find the hot spot.

Hypothesize: Top 3-5 potential causes ranked by likelihood Ã— impact. Consider product, user, market, and technical factors.

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and analyze user behavior patterns. Use session replays, surveys, or log analysis.

Action: Prioritize fixes by impact Ã— confidence. Start with data issues, then high-impact hypotheses. Run experiments, monitor results, and communicate plan."
2429,What questions would you ask before starting an analysis?,ðŸŸ¢,P1,Metric Drop Diagnosis,Metric â†’ Segment â†’ Hypothesis â†’ Data Check â†’ Action,Analysis preparation; metric analysis,"Clarify: Define the key metric(s) and success criteria. What exactly needs to change? Baseline and target?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Ensure data quality and measurement consistency.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), funnel step, acquisition channel, and user segment to find the hot spot.

Hypothesize: Top 3-5 potential causes ranked by likelihood Ã— impact. Consider product, user, market, and technical factors.

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and analyze user behavior patterns. Use session replays, surveys, or log analysis.

Action: Prioritize fixes by impact Ã— confidence. Start with data issues, then high-impact hypotheses. Run experiments, monitor results, and communicate plan."
2439,What signals would you use to improve Meta's News Feed relevance?,ðŸŸ¢,P1,Metric Drop Diagnosis,Metric â†’ Segment â†’ Hypothesis â†’ Data Check â†’ Action,Relevance improvement; metric analysis,"Clarify: Define success metric and target. Scope: which segments, surfaces, or user types?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Confirm measurement is accurate and not inflated by bots or data quality issues.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), funnel step, acquisition channel, and user segment to find the hot spot.

Hypothesize: Search relevance, pricing optimization, trust signals, supply quality, feature adoption, or user experience improvements.

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and test hypotheses with A/B tests or targeted experiments. Compare conversion rates by segment.

Action: Focus on highest-impact segments. Implement fixes: improve search/ranking, optimize pricing, add trust signals, or enhance UX. Measure impact and iterate."
2468,What would you do if Dropbox uploads were down 50%?,ðŸŸ¢,P1,Metric Drop Diagnosis,Metric â†’ Segment â†’ Hypothesis â†’ Data Check â†’ Action,Upload drop; metric analysis,"Clarify: Define the metric (numerator/denominator), baseline, and scope. Time window: when did it start? Magnitude: how significant?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Verify tracking accuracy, ETL lag, or event schema changes.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), funnel step, acquisition channel, and user segment to find the hot spot.

Hypothesize: Product changes (UI, pricing, policy), external factors (competitor, seasonality), performance issues (latency, crashes), or supply-side changes (if marketplace).

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and compare to control segments. Look for crash rates, error codes, or performance degradation.

Action: If severe + clear cause â†’ rollback/hotfix immediately. If unclear â†’ add logging, run targeted experiments, or fix segment-specific issues. Communicate findings and mitigation plan."
2542,Why are online orders on The New Yorker down 30%?,ðŸŸ¢,P1,Metric Drop Diagnosis,Metric â†’ Segment â†’ Hypothesis â†’ Data Check â†’ Action,Order drop; metric analysis,"Clarify: Define the metric (numerator/denominator), baseline, and scope. Specify: orders = what exactly? Time window: when did it start? Magnitude: how significant?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Verify tracking accuracy, ETL lag, or event schema changes.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), funnel step, acquisition channel, and user segment to find the hot spot.

Hypothesize: Product changes (UI, pricing, policy), external factors (competitor, seasonality), performance issues (latency, crashes), or supply-side changes (if marketplace).

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and compare to control segments. Look for crash rates, error codes, or performance degradation.

Action: If severe + clear cause â†’ rollback/hotfix immediately. If unclear â†’ add logging, run targeted experiments, or fix segment-specific issues. Communicate findings and mitigation plan."
2549,Why did Codecademy's signups increase by 15%?,ðŸŸ¢,P1,Metric Drop Diagnosis,Metric â†’ Segment â†’ Hypothesis â†’ Data Check â†’ Action,Signup increase; metric analysis,"Clarify: Define success metric and target. Current signups rate? Target growth? Scope: which segments, surfaces, or user types?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Confirm measurement is accurate and not inflated by bots or data quality issues.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), funnel step, acquisition channel, and user segment to find the hot spot.

Hypothesize: Search relevance, pricing optimization, trust signals, supply quality, feature adoption, or user experience improvements.

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and test hypotheses with A/B tests or targeted experiments. Compare conversion rates by segment.

Action: Focus on highest-impact segments. Implement fixes: improve search/ranking, optimize pricing, add trust signals, or enhance UX. Measure impact and iterate."
2619,Why is Gmail search slower than Google search?,ðŸŸ¢,P1,Metric Drop Diagnosis,Metric â†’ Segment â†’ Hypothesis â†’ Data Check â†’ Action,Performance metric; metric analysis,"Clarify: Define the key metric(s) and success criteria. What exactly needs to change? Baseline and target?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Ensure data quality and measurement consistency.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), funnel step, acquisition channel, and user segment to find the hot spot.

Hypothesize: Top 3-5 potential causes ranked by likelihood Ã— impact. Consider product, user, market, and technical factors.

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and analyze user behavior patterns. Use session replays, surveys, or log analysis.

Action: Prioritize fixes by impact Ã— confidence. Start with data issues, then high-impact hypotheses. Run experiments, monitor results, and communicate plan."
2622,Why might Venmo be seeing a decrease in users adding their bank accounts?,ðŸŸ¢,P1,Metric Drop Diagnosis,Metric â†’ Segment â†’ Hypothesis â†’ Data Check â†’ Action,User behavior drop; metric analysis,"Clarify: Define the metric (numerator/denominator), baseline, and scope. Time window: when did it start? Magnitude: how significant?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Verify tracking accuracy, ETL lag, or event schema changes.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), funnel step, acquisition channel, and user segment to find the hot spot.

Hypothesize: Product changes (UI, pricing, policy), external factors (competitor, seasonality), performance issues (latency, crashes), or supply-side changes (if marketplace).

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and compare to control segments. Look for crash rates, error codes, or performance degradation.

Action: If severe + clear cause â†’ rollback/hotfix immediately. If unclear â†’ add logging, run targeted experiments, or fix segment-specific issues. Communicate findings and mitigation plan."
2651,You are a Gmail PM and discover that traffic has dropped 10% on a Monday morning. What do you do?,ðŸŸ¢,P1,Metric Drop Diagnosis,Metric â†’ Segment â†’ Hypothesis â†’ Data Check â†’ Action,Traffic drop; metric analysis,"Clarify: Define the metric (numerator/denominator), baseline, and scope. Specify: traffic = what exactly? Time window: when did it start? Magnitude: how significant?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Verify tracking accuracy, ETL lag, or event schema changes.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), funnel step, acquisition channel, and user segment to find the hot spot.

Hypothesize: Product changes (UI, pricing, policy), external factors (competitor, seasonality), performance issues (latency, crashes), or supply-side changes (if marketplace).

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and compare to control segments. Look for crash rates, error codes, or performance degradation.

Action: If severe + clear cause â†’ rollback/hotfix immediately. If unclear â†’ add logging, run targeted experiments, or fix segment-specific issues. Communicate findings and mitigation plan."
2655,You are a PM at Amazon and want to increase the NPS. What would you do?,ðŸŸ¢,P1,Metric Drop Diagnosis,Metric â†’ Segment â†’ Hypothesis â†’ Data Check â†’ Action,NPS improvement; metric analysis,"Clarify: Define success metric and target. Scope: which segments, surfaces, or user types?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Confirm measurement is accurate and not inflated by bots or data quality issues.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), funnel step, acquisition channel, and user segment to find the hot spot.

Hypothesize: Search relevance, pricing optimization, trust signals, supply quality, feature adoption, or user experience improvements.

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and test hypotheses with A/B tests or targeted experiments. Compare conversion rates by segment.

Action: Focus on highest-impact segments. Implement fixes: improve search/ranking, optimize pricing, add trust signals, or enhance UX. Measure impact and iterate."
2681,You are the PM of Messenger and notice a significant drop in DAU. How would you investigate the cause?,ðŸŸ¢,P1,Metric Drop Diagnosis,Metric â†’ Segment â†’ Hypothesis â†’ Data Check â†’ Action,DAU drop; metric analysis,"Clarify: Define the metric (numerator/denominator), baseline, and scope. Time window: when did it start? Magnitude: how significant?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Verify tracking accuracy, ETL lag, or event schema changes.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), funnel step, acquisition channel, and user segment to find the hot spot.

Hypothesize: Product changes (UI, pricing, policy), external factors (competitor, seasonality), performance issues (latency, crashes), or supply-side changes (if marketplace).

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and compare to control segments. Look for crash rates, error codes, or performance degradation.

Action: If severe + clear cause â†’ rollback/hotfix immediately. If unclear â†’ add logging, run targeted experiments, or fix segment-specific issues. Communicate findings and mitigation plan."
2689,"You have a subscriber paying for YouTube TV but not using the platform, and they own a smart fridge, a Chromecast, and Google Nest. How would you increase their engagement?",ðŸŸ¢,P1,Metric Drop Diagnosis,Metric â†’ Segment â†’ Hypothesis â†’ Data Check â†’ Action,Engagement improvement; metric analysis,"Clarify: Define success metric and target. Current engagement rate? Target growth? Scope: which segments, surfaces, or user types?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Confirm measurement is accurate and not inflated by bots or data quality issues.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), content type, feature usage, and time of day to find engagement drivers.

Hypothesize: Search relevance, pricing optimization, trust signals, supply quality, feature adoption, or user experience improvements.

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and test hypotheses with A/B tests or targeted experiments. Compare conversion rates by segment.

Action: Focus on highest-impact segments. Implement fixes: improve search/ranking, optimize pricing, add trust signals, or enhance UX. Measure impact and iterate."
2698,You realized that Monthly Active Users (MAU) are down for this month. What would you do?,ðŸŸ¢,P1,Metric Drop Diagnosis,Metric â†’ Segment â†’ Hypothesis â†’ Data Check â†’ Action,MAU drop; metric analysis,"Clarify: Define the metric (numerator/denominator), baseline, and scope. Time window: when did it start? Magnitude: how significant?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Verify tracking accuracy, ETL lag, or event schema changes.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), funnel step, acquisition channel, and user segment to find the hot spot.

Hypothesize: Product changes (UI, pricing, policy), external factors (competitor, seasonality), performance issues (latency, crashes), or supply-side changes (if marketplace).

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and compare to control segments. Look for crash rates, error codes, or performance degradation.

Action: If severe + clear cause â†’ rollback/hotfix immediately. If unclear â†’ add logging, run targeted experiments, or fix segment-specific issues. Communicate findings and mitigation plan."
2719,"You're a PM at a top-up team. How would you launch cash deposits? If one of the main KPIs is down, how would you go about addressing it?",ðŸŸ¢,P1,Metric Drop Diagnosis,Metric â†’ Segment â†’ Hypothesis â†’ Data Check â†’ Action,Metric drop; metric analysis,"Clarify: Define the metric (numerator/denominator), baseline, and scope. Time window: when did it start? Magnitude: how significant?

Data Check: Rule out instrumentation changes, pipeline delays, or denominator shifts. Verify tracking accuracy, ETL lag, or event schema changes.

Segment: Slice by platform (iOS/Android/Web), geography, user cohort (new vs returning), funnel step, acquisition channel, and user segment to find the hot spot.

Hypothesize: Product changes (UI, pricing, policy), external factors (competitor, seasonality), performance issues (latency, crashes), or supply-side changes (if marketplace).

Validate: Check correlation with launches, counter-metrics, funnel drop-offs, and compare to control segments. Look for crash rates, error codes, or performance degradation.

Action: If severe + clear cause â†’ rollback/hotfix immediately. If unclear â†’ add logging, run targeted experiments, or fix segment-specific issues. Communicate findings and mitigation plan."
2157,The product team reports a decline in 30-day user retention. How would you approach this problem?,ðŸŸ¢,P1,Metric Drop Diagnosis,Clarify Metric â†’ Segment â†’ Hypothesize â†’ Data Check â†’ Action,Retention decline; funnel analysis,"Define Funnel Steps: Map the exact user journey. Step 1: First use / activation. Step 2: Core value experience (complete key action). Step 3: Return within 7 days. Step 4: Return within 30 days. Step 5: Habit formation (weekly active). Guardrail: Steps must be USER actions, not internal events.

Measure Drop-off: Compute conversion rate between each step. Calculate: Step 1 â†’ 2: X%, Step 2 â†’ 3: Y%, Step 3 â†’ 4: Z%. Identify the largest % drop - this is the bottleneck that needs attention.

Identify Friction: Ask WHY users fail at the bottleneck step. UX friction: unclear value, confusing interface, slow performance. Value friction: not seeing benefit, lack of personalization. Technical friction: bugs, crashes, latency. Use session replays, cohort analysis, and user surveys.

Hypothesize Fix: Generate 1-2 clear hypotheses. Format: If we reduce friction X, then conversion at step Y increases. Prioritize: High impact Ã— Low effort, isolated to one step. Examples: simplify form, show value earlier, fix technical issues, improve mobile UX.

Test: Run A/B test or staged rollout. Primary metric: conversion rate at the bottleneck step. Guardrails: monitor downstream impact (retention, quality, revenue). Decide: ship winner, iterate, or rollback based on results."
2506,"What's your favorite fitness product, and what would you do if you found that its users dropped off after 3 months?",ðŸŸ¢,P1,Metric Drop Diagnosis,Clarify Metric â†’ Segment â†’ Hypothesize â†’ Data Check â†’ Action,Retention issue; funnel analysis,"Define Funnel Steps: Map the exact user journey from entry to success. Identify 4-5 key steps: Entry â†’ Activation â†’ Core Action â†’ Conversion â†’ Success. Guardrail: Steps must be USER actions (not internal events or system metrics).

Measure Drop-off: Compute conversion rate between each step. Calculate: Step 1 â†’ 2: X%, Step 2 â†’ 3: Y%, Step 3 â†’ 4: Z%. Identify the largest % drop - this is the bottleneck that needs attention.

Identify Friction: Ask WHY users fail at the bottleneck step. UX friction: confusing flow, too many steps, slow load time. Trust friction: unclear value, privacy concerns. Value friction: benefit not clear. Technical friction: bugs, latency, errors. Use session replays, funnel by segment, and qual research.

Hypothesize Fix: Generate 1-2 clear hypotheses. Format: If we reduce friction X, then conversion at step Y increases. Prioritize: High impact Ã— Low effort, isolated to one step. Examples: simplify form, show value earlier, fix technical issues, improve mobile UX.

Test: Run A/B test or staged rollout. Primary metric: conversion rate at the bottleneck step. Guardrails: monitor downstream impact (retention, quality, revenue). Decide: ship winner, iterate, or rollback based on results."
2807,You're a PM for Instagram. You notice the Month-on-Month retention is down by 20%. What might be happening?,ðŸŸ¢,P1,Metric Drop Diagnosis,Clarify Metric â†’ Segment â†’ Hypothesize â†’ Data Check â†’ Action,Funnel analysis,"Define Funnel Steps: Map the exact user journey. Step 1: First use / activation. Step 2: Core value experience (complete key action). Step 3: Return within 7 days. Step 4: Return within 30 days. Step 5: Habit formation (weekly active). Guardrail: Steps must be USER actions, not internal events.

Measure Drop-off: Compute conversion rate between each step. Calculate: Step 1 â†’ 2: X%, Step 2 â†’ 3: Y%, Step 3 â†’ 4: Z%. Identify the largest % drop - this is the bottleneck that needs attention.

Identify Friction: Ask WHY users fail at the bottleneck step. UX friction: unclear value, confusing interface, slow performance. Value friction: not seeing benefit, lack of personalization. Technical friction: bugs, crashes, latency. Use session replays, cohort analysis, and user surveys.

Hypothesize Fix: Generate 1-2 clear hypotheses. Format: If we reduce friction X, then conversion at step Y increases. Prioritize: High impact Ã— Low effort, isolated to one step. Examples: simplify form, show value earlier, fix technical issues, improve mobile UX.

Test: Run A/B test or staged rollout. Primary metric: conversion rate at the bottleneck step. Guardrails: monitor downstream impact (retention, quality, revenue). Decide: ship winner, iterate, or rollback based on results."
2715,You're a PM at a food delivery app where conversion rates have declined over the past week. How would you investigate the causes? (Conversion: From users browsing to placing orders.),ðŸŸ¢,P1,Metric Drop Diagnosis,Clarify Metric â†’ Segment â†’ Hypothesize â†’ Data Check â†’ Action,Funnel analysis,"Define Funnel Steps: Map the exact user journey. Step 1: Product view / add to cart. Step 2: View cart / proceed to checkout. Step 3: Enter shipping / payment info. Step 4: Review order / confirm purchase. Step 5: Purchase complete / confirmation. Guardrail: Steps must be USER actions, not internal events.

Measure Drop-off: Compute conversion rate between each step. Calculate: Step 1 â†’ 2: X%, Step 2 â†’ 3: Y%, Step 3 â†’ 4: Z%. Identify the largest % drop - this is the bottleneck that needs attention.

Identify Friction: Ask WHY users fail at the bottleneck step. UX friction: unexpected costs, forced account creation, complex forms. Trust friction: payment security, price shock, shipping delays. Technical friction: payment errors, mobile issues, slow checkout. Use session replays, funnel by device/platform, and error logs.

Hypothesize Fix: Generate 1-2 clear hypotheses. Format: If we reduce friction X, then conversion at step Y increases. Prioritize: High impact Ã— Low effort, isolated to one step. Examples: simplify form, show value earlier, fix technical issues, improve mobile UX.

Test: Run A/B test or staged rollout. Primary metric: conversion rate at the bottleneck step. Guardrails: monitor downstream impact (retention, quality, revenue). Decide: ship winner, iterate, or rollback based on results."
