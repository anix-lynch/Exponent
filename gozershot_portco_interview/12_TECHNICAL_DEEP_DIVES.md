# Technical Deep-Dives - Cross-Project Questions

**15 questions about data engineering fundamentals across all your projects**

---

181. **How do you ensure data quality in your pipelines?** (Coffeeverse, Cocktailverse, Marketing Analytics)
182. **What's your approach to testing data transformations?** (across all your ETL projects)
183. **How do you handle schema evolution without breaking downstream consumers?** (Coffeeverse, Cocktailverse)
184. **What's your strategy for handling data lineage?** (across all projects)
185. **How do you approach data modeling for analytics vs operational use cases?** (Cocktailverse star schema, Coffeeverse Cosmos DB)
186. **What's your process for designing a new data pipeline from scratch?** (You've built 4+ pipelines)
187. **How do you decide between batch and streaming processing?** (Your projects use batch - why?)
188. **What's your approach to handling PII and data privacy?** (AI BI Agent, Mocktailverse)
189. **How do you design for scalability from day one?** (All your projects)
190. **What's your strategy for disaster recovery and backup?** (Coffeeverse, Cocktailverse)
191. **How do you approach cost optimization in cloud data platforms?** (You've optimized costs in multiple projects)
192. **What's your process for monitoring and alerting on data pipelines?** (All your projects)
193. **How do you handle data governance and access control?** (All your projects)
194. **What's your approach to documentation for data pipelines?** (Your GitHub repos)
195. **How do you balance technical debt vs new feature development?** (Across all projects)
