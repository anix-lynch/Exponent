#!/usr/bin/env python3
"""
Generate short answers for L14 questions using the System Design (Conceptual) framework.
Each answer follows: Components â†’ Data Flow â†’ Boundaries â†’ Scale Considerations
Tailored to each specific question while maintaining the framework structure.
"""

import csv
import re

def detect_system_type(question_text, notes):
    """Detect the type of system being designed from the question."""
    q_lower = question_text.lower()
    notes_lower = notes.lower() if notes else ""
    
    # System type detection
    if any(word in q_lower for word in ['url shortener', 'tinyurl', 'shorten url', 'bitly']):
        return 'url_shortener'
    elif any(word in q_lower for word in ['recommendation', 'recommend', 'personalized', 'ranking']):
        return 'recommendation'
    elif any(word in q_lower for word in ['data pipeline', 'etl', 'data warehouse', 'data lake']):
        return 'data_pipeline'
    elif any(word in q_lower for word in ['messaging', 'chat', 'message', 'whatsapp', 'slack', 'messenger']):
        return 'messaging'
    elif any(word in q_lower for word in ['storage', 'file storage', 'dropbox', 'drive', 's3']):
        return 'storage'
    elif any(word in q_lower for word in ['search', 'search engine', 'typeahead', 'autocomplete']):
        return 'search'
    elif any(word in q_lower for word in ['streaming', 'live', 'twitch', 'youtube live']):
        return 'streaming'
    elif any(word in q_lower for word in ['payment', 'transaction', 'stripe', 'paypal']):
        return 'payment'
    elif any(word in q_lower for word in ['api', 'endpoint', 'rest api']):
        return 'api'
    elif any(word in q_lower for word in ['ml', 'machine learning', 'model', 'ai', 'llm', 'rag']):
        return 'ml_system'
    elif any(word in q_lower for word in ['cache', 'caching', 'redis', 'memcached']):
        return 'cache'
    elif any(word in q_lower for word in ['rate limit', 'rate limiter']):
        return 'rate_limiter'
    elif any(word in q_lower for word in ['load balancer', 'load balance']):
        return 'load_balancer'
    elif any(word in q_lower for word in ['database', 'db', 'nosql', 'sql']):
        return 'database'
    else:
        return 'generic'

def generate_l14_short_answer(question_text, notes):
    """Generate a tailored short answer following L14 framework."""
    
    question_lower = question_text.lower()
    system_type = detect_system_type(question_text, notes)
    
    parts = []
    
    # 1. DEFINE THE GOAL - Tailored to system type
    goal_lines = []
    goal_lines.append("ðŸŽ¯ Define the GOAL: Clarify what problem we're solving")
    
    if system_type == 'url_shortener':
        goal_lines.append("  ðŸ‘¥ Primary user goal: shorten long URLs for sharing, trackability, and convenience")
        goal_lines.append("  ðŸ“Š Success metric: low latency redirects (<50ms), high availability, URL uniqueness")
        goal_lines.append("  ðŸš« Non-goals: URL expiration, custom aliases, analytics (initially)")
    elif system_type == 'recommendation':
        goal_lines.append("  ðŸ‘¥ Primary user goal: surface relevant content/products to users based on preferences")
        goal_lines.append("  ðŸ“Š Success metric: click-through rate, engagement, relevance score, latency")
        goal_lines.append("  ðŸš« Non-goals: real-time updates, explainability, A/B testing (initially)")
    elif system_type == 'data_pipeline':
        goal_lines.append("  ðŸ‘¥ Primary user goal: process, transform, and deliver data reliably and efficiently")
        goal_lines.append("  ðŸ“Š Success metric: data freshness, throughput, accuracy, cost per GB")
        goal_lines.append("  ðŸš« Non-goals: real-time processing, data quality checks (initially)")
    elif system_type == 'messaging':
        goal_lines.append("  ðŸ‘¥ Primary user goal: enable real-time communication between users reliably")
        goal_lines.append("  ðŸ“Š Success metric: message delivery latency, delivery guarantees, availability")
        goal_lines.append("  ðŸš« Non-goals: video calls, file sharing, group management (initially)")
    elif system_type == 'storage':
        goal_lines.append("  ðŸ‘¥ Primary user goal: store and retrieve files reliably with high availability")
        goal_lines.append("  ðŸ“Š Success metric: upload/download speed, durability, storage cost, availability")
        goal_lines.append("  ðŸš« Non-goals: file versioning, sharing, search (initially)")
    elif system_type == 'search':
        goal_lines.append("  ðŸ‘¥ Primary user goal: quickly find relevant results from large datasets")
        goal_lines.append("  ðŸ“Š Success metric: search latency, relevance, result ranking quality")
        goal_lines.append("  ðŸš« Non-goals: autocomplete, spell correction, personalization (initially)")
    elif system_type == 'streaming':
        goal_lines.append("  ðŸ‘¥ Primary user goal: deliver live content to viewers with low latency")
        goal_lines.append("  ðŸ“Š Success metric: stream latency, buffering rate, concurrent viewers, quality")
        goal_lines.append("  ðŸš« Non-goals: video on demand, chat, monetization (initially)")
    elif system_type == 'payment':
        goal_lines.append("  ðŸ‘¥ Primary user goal: process transactions securely and reliably")
        goal_lines.append("  ðŸ“Š Success metric: transaction success rate, latency, fraud detection, availability")
        goal_lines.append("  ðŸš« Non-goals: refunds, disputes, multi-currency (initially)")
    elif system_type == 'ml_system':
        goal_lines.append("  ðŸ‘¥ Primary user goal: serve ML models with low latency and high accuracy")
        goal_lines.append("  ðŸ“Š Success metric: inference latency, model accuracy, throughput, cost per prediction")
        goal_lines.append("  ðŸš« Non-goals: model training, feature engineering, A/B testing (initially)")
    else:
        goal_lines.append("  ðŸ‘¥ Primary user goal: what is the main user need or business objective?")
        goal_lines.append("  ðŸ“Š Success metric: latency, reliability, accuracy, cost, what defines success?")
        goal_lines.append("  ðŸš« Non-goals: explicitly say what's out of scope, what we're NOT building")
    
    goal_lines.append("  âš ï¸ Rule: If the goal isn't clear, architecture will be wrong")
    parts.append("\n".join(goal_lines))
    
    # 2. IDENTIFY CORE COMPONENTS - Tailored to system type
    component_lines = []
    component_lines.append("ðŸ§© Identify CORE COMPONENTS: Define what blocks exist")
    
    if system_type == 'url_shortener':
        component_lines.append("  ðŸ“± Clients: web browsers, mobile apps, API consumers")
        component_lines.append("  ðŸ”— API gateway: handle shorten and redirect requests")
        component_lines.append("  ðŸ†” ID generator: create unique short codes (base62, UUID, counter)")
        component_lines.append("  ðŸ’¾ URL store: database mapping short_code â†’ long_url")
        component_lines.append("  ðŸ’¨ Cache: Redis/CDN for hot redirects (read-heavy workload)")
    elif system_type == 'recommendation':
        component_lines.append("  ðŸ“± Clients: web, mobile apps requesting recommendations")
        component_lines.append("  ðŸŽ¯ Recommendation service: compute personalized rankings")
        component_lines.append("  ðŸ‘¤ User profile store: user preferences, history, behavior")
        component_lines.append("  ðŸ“¦ Item catalog: product/content metadata and features")
        component_lines.append("  ðŸ¤– ML models: ranking algorithms, collaborative filtering, embeddings")
    elif system_type == 'data_pipeline':
        component_lines.append("  ðŸ“¥ Ingestion: batch jobs, stream processors, API collectors")
        component_lines.append("  âš™ï¸ Processing: ETL/ELT engines (Spark, Flink, Dataflow)")
        component_lines.append("  ðŸ’¾ Storage: data lake (S3), warehouse (Snowflake), staging DB")
        component_lines.append("  ðŸ“Š Transformation: data cleaning, aggregation, enrichment")
        component_lines.append("  ðŸ“ˆ Orchestration: schedulers (Airflow), workflow managers")
    elif system_type == 'messaging':
        component_lines.append("  ðŸ“± Clients: mobile apps, web clients sending/receiving messages")
        component_lines.append("  ðŸ’¬ Message service: handle send, receive, delivery status")
        component_lines.append("  ðŸ“¨ Message queue: Kafka/RabbitMQ for reliable delivery")
        component_lines.append("  ðŸ’¾ Message store: database for message history and metadata")
        component_lines.append("  ðŸ”” Presence service: track online/offline status, push notifications")
    elif system_type == 'storage':
        component_lines.append("  ðŸ“± Clients: web, mobile apps uploading/downloading files")
        component_lines.append("  ðŸ“¤ Upload service: handle file uploads, chunking, validation")
        component_lines.append("  ðŸ’¾ Object storage: S3/GCS for file storage, metadata DB")
        component_lines.append("  ðŸ”„ Replication: ensure durability across regions")
        component_lines.append("  ðŸ“¥ CDN: cache popular files for fast downloads")
    elif system_type == 'search':
        component_lines.append("  ðŸ“± Clients: search UI, API consumers")
        component_lines.append("  ðŸ” Search service: query processing, ranking, result assembly")
        component_lines.append("  ðŸ“š Index: inverted index, document store, ranking data")
        component_lines.append("  ðŸ”„ Indexer: crawl, parse, and build search indexes")
        component_lines.append("  ðŸ’¨ Cache: popular queries, autocomplete suggestions")
    elif system_type == 'streaming':
        component_lines.append("  ðŸ“± Clients: viewers on web, mobile, TV apps")
        component_lines.append("  ðŸŽ¥ Encoder: transcode video to multiple quality levels")
        component_lines.append("  ðŸ“¡ CDN: deliver video chunks to viewers globally")
        component_lines.append("  ðŸ“Š Analytics: track views, engagement, quality metrics")
        component_lines.append("  ðŸ’¾ Origin server: store master video files")
    elif system_type == 'payment':
        component_lines.append("  ðŸ“± Clients: merchants, payment gateways, mobile apps")
        component_lines.append("  ðŸ’³ Payment processor: authorize, capture, settle transactions")
        component_lines.append("  ðŸ¦ Bank gateway: communicate with payment networks")
        component_lines.append("  ðŸ”’ Fraud detection: ML models to detect suspicious transactions")
        component_lines.append("  ðŸ’¾ Transaction store: database for transaction history, reconciliation")
    elif system_type == 'ml_system':
        component_lines.append("  ðŸ“± Clients: applications making inference requests")
        component_lines.append("  ðŸ¤– Model serving: load models, handle inference requests")
        component_lines.append("  ðŸ“Š Feature store: serve features for model input")
        component_lines.append("  âš™ï¸ Preprocessing: data transformation, feature engineering")
        component_lines.append("  ðŸ“ˆ Monitoring: track model performance, drift, latency")
    else:
        component_lines.append("  ðŸ“± Clients: web, mobile, internal tools, what are the entry points?")
        component_lines.append("  ðŸ“¥ Ingestion: APIs, SDKs, event collectors, how does data enter?")
        component_lines.append("  âš™ï¸ Processing: sync vs async, how is data processed?")
        component_lines.append("  ðŸ’¾ Storage: hot / warm / cold, where is data stored?")
        component_lines.append("  ðŸ–¥ï¸ Compute: stateless vs stateful, how is computation handled?")
    
    component_lines.append("  âš ï¸ Rule: Name boxes before wiring arrows")
    parts.append("\n".join(component_lines))
    
    # 3. DATA FLOW - Tailored to system type
    flow_lines = []
    flow_lines.append("ðŸ”„ Data FLOW: Describe how data moves end-to-end")
    
    if system_type == 'url_shortener':
        flow_lines.append("  âœï¸ Write path: client â†’ API â†’ generate short_code â†’ store (DB) â†’ cache")
        flow_lines.append("  ðŸ“– Read path: client â†’ API â†’ cache lookup â†’ DB fallback â†’ redirect")
        flow_lines.append("  â³ Async: analytics pipeline (track clicks, generate reports)")
        flow_lines.append("  âŒ Failure: cache miss â†’ DB timeout â†’ return error or default")
    elif system_type == 'recommendation':
        flow_lines.append("  ðŸ“– Request path: client â†’ API â†’ fetch user profile â†’ compute recommendations â†’ rank â†’ return")
        flow_lines.append("  âœï¸ Write path: user actions â†’ event stream â†’ update user profile â†’ retrain models (async)")
        flow_lines.append("  â³ Async: model training, feature computation, index updates")
        flow_lines.append("  âŒ Failure: model unavailable â†’ fallback to popularity-based, cache stale results")
    elif system_type == 'data_pipeline':
        flow_lines.append("  ðŸ“¥ Ingest: source systems â†’ message queue â†’ batch/stream processor")
        flow_lines.append("  âš™ï¸ Transform: raw data â†’ cleaned â†’ transformed â†’ aggregated â†’ loaded")
        flow_lines.append("  ðŸ’¾ Store: processed data â†’ data warehouse â†’ serve to dashboards/APIs")
        flow_lines.append("  âŒ Failure: retry failed jobs, dead letter queue, data quality checks")
    elif system_type == 'messaging':
        flow_lines.append("  âœï¸ Send: sender â†’ message service â†’ queue â†’ store â†’ push to recipient")
        flow_lines.append("  ðŸ“– Receive: recipient â†’ message service â†’ fetch from store â†’ deliver")
        flow_lines.append("  â³ Async: offline message delivery, read receipts, typing indicators")
        flow_lines.append("  âŒ Failure: message retry, dead letter queue, delivery status tracking")
    elif system_type == 'storage':
        flow_lines.append("  ðŸ“¤ Upload: client â†’ upload service â†’ chunk file â†’ store in object storage â†’ update metadata")
        flow_lines.append("  ðŸ“¥ Download: client â†’ CDN check â†’ object storage â†’ stream to client")
        flow_lines.append("  â³ Async: file replication, thumbnail generation, virus scanning")
        flow_lines.append("  âŒ Failure: upload retry, partial upload resume, storage replication")
    else:
        flow_lines.append("  ðŸ“– Request path (read): how do read requests flow through the system?")
        flow_lines.append("  âœï¸ Write path (create/update): how do write requests flow through?")
        flow_lines.append("  â³ Async paths: queues, streams, retries, how are async ops handled?")
        flow_lines.append("  âŒ Failure paths: timeouts, backpressure, how are failures handled?")
    
    flow_lines.append("  âš ï¸ Rule: Always describe the happy path first")
    parts.append("\n".join(flow_lines))
    
    # 4. BOUNDARIES & CONSTRAINTS - Tailored to system type
    boundary_lines = []
    boundary_lines.append("ðŸš§ Boundaries & CONSTRAINTS: Identify what limits us")
    
    if system_type == 'url_shortener':
        boundary_lines.append("  â±ï¸ Latency: redirects must be <50ms (read-heavy, cache-first)")
        boundary_lines.append("  ðŸ”’ Consistency: strong consistency on writes (URL uniqueness)")
        boundary_lines.append("  ðŸ“ˆ Throughput: 100M redirects/day, 1K writes/sec")
        boundary_lines.append("  ðŸ’° Cost: minimize storage (short codes are small), maximize cache hit rate")
    elif system_type == 'recommendation':
        boundary_lines.append("  â±ï¸ Latency: recommendations must be <100ms (user-facing)")
        boundary_lines.append("  ðŸ”’ Consistency: eventual consistency OK (user profiles update async)")
        boundary_lines.append("  ðŸ“ˆ Throughput: 1M requests/sec during peak, handle cold starts")
        boundary_lines.append("  ðŸ’° Cost: balance model complexity vs inference cost")
    elif system_type == 'data_pipeline':
        boundary_lines.append("  â±ï¸ Latency: batch processing acceptable (hourly/daily), not real-time")
        boundary_lines.append("  ðŸ”’ Consistency: eventual consistency OK, data freshness SLA")
        boundary_lines.append("  ðŸ“ˆ Throughput: handle TB/PB scale, process within time window")
        boundary_lines.append("  ðŸ’° Cost: optimize compute costs, use spot instances where possible")
    elif system_type == 'messaging':
        boundary_lines.append("  â±ï¸ Latency: message delivery <1s for online users")
        boundary_lines.append("  ðŸ”’ Consistency: at-least-once delivery guarantee, message ordering")
        boundary_lines.append("  ðŸ“ˆ Throughput: 1M messages/sec, handle message bursts")
        boundary_lines.append("  ðŸ’° Cost: optimize storage (message retention policies)")
    elif system_type == 'storage':
        boundary_lines.append("  â±ï¸ Latency: upload/download speed, minimize time to first byte")
        boundary_lines.append("  ðŸ”’ Consistency: strong consistency for metadata, eventual for replication")
        boundary_lines.append("  ðŸ“ˆ Throughput: handle large files, concurrent uploads/downloads")
        boundary_lines.append("  ðŸ’° Cost: optimize storage costs (tiering, compression, deduplication)")
    else:
        boundary_lines.append("  â±ï¸ Latency SLOs: what are the latency requirements?")
        boundary_lines.append("  ðŸ”’ Consistency: strong vs eventual consistency?")
        boundary_lines.append("  ðŸ“ˆ Throughput: how many requests per second must we handle?")
        boundary_lines.append("  ðŸ’° Cost ceilings: what are the budget constraints?")
    
    boundary_lines.append("  âš ï¸ Rule: Constraints shape architecture more than features")
    parts.append("\n".join(boundary_lines))
    
    # 5. SCALE & FAILURE MODES - Tailored to system type
    scale_lines = []
    scale_lines.append("ðŸ“ˆ Scale & FAILURE MODES: Consider what breaks at 10Ã—")
    
    if system_type == 'url_shortener':
        scale_lines.append("  ðŸŒ Bottlenecks: DB becomes bottleneck on writes, cache misses on reads")
        scale_lines.append("  âš ï¸ Single points: ID generator, database, cache")
        scale_lines.append("  ðŸš¦ Backpressure: rate limit writes, queue redirects if cache down")
        scale_lines.append("  ðŸ’¨ Caching: cache 80%+ of redirects, use CDN for global distribution")
        scale_lines.append("  ðŸ”€ Sharding: shard by short_code hash, replicate DB for reads")
    elif system_type == 'recommendation':
        scale_lines.append("  ðŸŒ Bottlenecks: model inference, feature store lookups, ranking computation")
        scale_lines.append("  âš ï¸ Single points: model serving, feature store, user profile DB")
        scale_lines.append("  ðŸš¦ Backpressure: queue requests, return cached/stale recommendations")
        scale_lines.append("  ðŸ’¨ Caching: cache popular recommendations, pre-compute for hot users")
        scale_lines.append("  ðŸ”€ Sharding: shard user profiles, distribute model serving")
    elif system_type == 'data_pipeline':
        scale_lines.append("  ðŸŒ Bottlenecks: processing time, storage I/O, network bandwidth")
        scale_lines.append("  âš ï¸ Single points: orchestrator, data warehouse, source systems")
        scale_lines.append("  ðŸš¦ Backpressure: queue jobs, parallelize processing, auto-scale workers")
        scale_lines.append("  ðŸ’¨ Caching: cache intermediate results, materialized views")
        scale_lines.append("  ðŸ”€ Partitioning: partition data by time/region, process in parallel")
    elif system_type == 'messaging':
        scale_lines.append("  ðŸŒ Bottlenecks: message queue, message store, push notification service")
        scale_lines.append("  âš ï¸ Single points: message queue, database, push service")
        scale_lines.append("  ðŸš¦ Backpressure: queue messages, rate limit sends, batch notifications")
        scale_lines.append("  ðŸ’¨ Caching: cache recent messages, user presence, connection state")
        scale_lines.append("  ðŸ”€ Sharding: shard by user_id, partition message queues")
    elif system_type == 'storage':
        scale_lines.append("  ðŸŒ Bottlenecks: object storage I/O, metadata DB, network bandwidth")
        scale_lines.append("  âš ï¸ Single points: object storage, metadata DB, upload service")
        scale_lines.append("  ðŸš¦ Backpressure: rate limit uploads, queue large files, throttle downloads")
        scale_lines.append("  ðŸ’¨ Caching: CDN for popular files, cache metadata")
        scale_lines.append("  ðŸ”€ Sharding: shard by file_id, replicate across regions")
    else:
        scale_lines.append("  ðŸŒ Bottlenecks: DB, network, fan-out, where will it slow down?")
        scale_lines.append("  âš ï¸ Single points of failure: what components have no redundancy?")
        scale_lines.append("  ðŸš¦ Backpressure: how do we handle overload?")
        scale_lines.append("  ðŸ’¨ Caching: where can we cache to reduce load?")
        scale_lines.append("  ðŸ”€ Sharding / partitioning: how do we distribute data?")
    
    scale_lines.append("  âš ï¸ Rule: Talk about failure BEFORE optimization")
    parts.append("\n".join(scale_lines))
    
    # Join with double newlines (blank line between sections)
    return "\n\n".join(parts)


def process_l14_csv(input_file, output_file):
    """Process L14 CSV and add/update short_answer column."""
    rows = []
    
    with open(input_file, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        # Get original fieldnames and remove duplicates
        original_fieldnames = list(reader.fieldnames)
        seen = set()
        fieldnames = []
        for field in original_fieldnames:
            if field not in seen:
                fieldnames.append(field)
                seen.add(field)
        
        # Add short_answer if it doesn't exist
        if 'short_answer' not in fieldnames:
            fieldnames.append('short_answer')
        
        for row in reader:
            short_answer = generate_l14_short_answer(row['question_text'], row.get('notes', ''))
            row['short_answer'] = short_answer
            rows.append(row)
    
    with open(output_file, 'w', encoding='utf-8', newline='') as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(rows)
    
    print(f"Generated {len(rows)} tailored short answers in {output_file}")


if __name__ == '__main__':
    input_file = 'pattern_bank_answered/25_L14_system_design_conceptual.csv'
    output_file = 'pattern_bank_answered/25_L14_system_design_conceptual.csv'
    process_l14_csv(input_file, output_file)
