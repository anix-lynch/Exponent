# L11 - Risk Mitigation

**Formula:** `Enumerate Risks â†’ Blast Radius â†’ Mitigations â†’ Monitor`

---

## ðŸ§  Mental Model (ASCII Tree)

```
START: "What could go wrong?"
â”‚
â”œâ”€ 1) Enumerate Risks (LIST before judging)
â”‚   â”‚
â”‚   â”œâ”€ Technical (bugs, downtime, data loss)
â”‚   â”œâ”€ Data (quality, drift, leakage, bias)
â”‚   â”œâ”€ Operational (on-call load, handoffs)
â”‚   â”œâ”€ Legal / Compliance (PII, regulations)
â”‚   â””â”€ Business (revenue, trust, reputation)
â”‚
â”‚   âš  Rule: If you can't name it, you can't manage it
â”‚
â”œâ”€ 2) Assess Blast Radius (HOW bad is it?)
â”‚   â”‚
â”‚   â”œâ”€ Users affected (1% vs 100%)
â”‚   â”œâ”€ Duration (minutes vs weeks)
â”‚   â”œâ”€ Reversibility (easy rollback vs permanent)
â”‚   â””â”€ Visibility (internal vs public)
â”‚
â”‚   Output: Risk = Probability Ã— Impact
â”‚
â”œâ”€ 3) Prioritize (NOT all risks deserve fixes)
â”‚   â”‚
â”‚   â”œâ”€ High impact + high probability â†’ ACT
â”‚   â”œâ”€ High impact + low probability â†’ PLAN
â”‚   â”œâ”€ Low impact + high probability â†’ AUTOMATE
â”‚   â””â”€ Low impact + low probability â†’ ACCEPT
â”‚
â”œâ”€ 4) Mitigate (REDUCE impact or probability)
â”‚   â”‚
â”‚   â”œâ”€ Prevent: guardrails, validation, limits
â”‚   â”œâ”€ Detect: monitoring, alerts
â”‚   â”œâ”€ Contain: rate limits, feature flags
â”‚   â””â”€ Recover: rollback, backups, runbooks
â”‚
â”œâ”€ 5) Monitor (ASSUME failure will happen)
â”‚   â”‚
â”‚   â”œâ”€ Early warning metrics
â”‚   â”œâ”€ Alert thresholds
â”‚   â””â”€ Clear owner + escalation path
â”‚
â””â”€ OUTPUT: "If X happens, we detect in Y mins and recover in Z."
```

---

## ðŸ“Š Risk Types â†’ Typical Mitigations

```
| Risk Type     | Example                    | Mitigation                     |
|---------------|----------------------------|--------------------------------|
| Data          | Bad input                  | Validation + sanity checks     |
| Model         | Drift                      | Drift monitoring               |
| Infra         | Traffic spike              | Rate limits + autoscaling      |
| Product       | Bad launch                 | Feature flags + phased rollout |
| Legal         | PII exposure               | Access control + audits        |
```

---

## ðŸš¨ Anti-Patterns (Red Flags)

```
âœ— "Low probability" with huge impact ignored
âœ— No owner for a risk
âœ— Alerts without action plans
âœ— One big mitigation instead of layers
âœ— Learning only after an outage
```

---

## ðŸ“Œ Interview Example: ML Model Launch

**Question:**
"What risks would you consider before launching a new ML model?"

```
Risks
â”œâ”€ Prediction drift
â”œâ”€ Biased outcomes
â”œâ”€ Latency regression

Blast Radius
â”œâ”€ Affects recommendations for all users

Mitigation
â”œâ”€ Shadow deploy
â”œâ”€ Canary rollout
â”œâ”€ Drift + latency alerts

Monitor
â””â”€ Auto-rollback on threshold breach
```

---

## ðŸ’¬ One-Liners You Can Drop

* "Risk = probability Ã— blast radius."
* "You don't eliminate risk â€” you bound it."
* "Detection speed matters more than perfection."
* "Assume failure, design recovery."

---

## ðŸ”‘ 5-Second Recall

```
List â†’ Size â†’ Fix â†’ Watch
```

Next: **L12 â€“ Metrics Interpretation**, or want a **rapid L1â€“L11 drill** to lock everything in.
