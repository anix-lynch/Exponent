# Executive Study Plan: P2B9 - General Metrics
**Approach:** GM-style, concept-level, flexible framework  
**Time:** 60-90 min  
**Source:** 76 questions ‚Üí Flexible NSM + KPI Ladder for any product/feature

**‚ù§Ô∏è = "Hedgehog Answer"** - Your fallback narrative if you know nothing. Master these first!

---

## üéØ EXECUTIVE SCOPE (10-15 min)

### Why General Metrics Matter

**Key Insight:** General metrics questions don't have a specific business model - you need to **adapt the NSM + KPI Ladder framework** to the product/feature context. The framework is universal, but the metrics are context-specific.

**Approach:**
1. Understand the product/feature: What does it do? Who uses it?
2. Define NSM: What single metric represents success?
3. Identify drivers: What moves the NSM?
4. Set leading indicators: Early signals of success
5. Add guardrails: What must not break?

---

## üìä CONCEPT BUCKET BREAKDOWN

### BUCKET 1: Define NSM for Any Product/Feature
**Questions:** ~30 | **Priority:** üü¢ GREEN (Master this)

**Board Slide Bullets:**
- **NSM Definition:** Single metric that represents user value + business value
- **Key Insight:** Must be actionable (we can influence it), measurable (we can track it), predictive (predicts long-term success)
- **Framework:** User value (what do users care about?) + Business value (what drives business?) = NSM
- **Examples:** Engagement (DAU, time spent), Transactions (GMV, volume), Retention (D7, D30, M3), Revenue (ARR, MRR)

**Concrete Examples:**
- "Productivity app: NSM = Weekly Active Users who complete tasks (engagement + value)"
- "Search feature: NSM = Successful Searches per User (utility + engagement)"
- "Notification feature: NSM = Weekly Users who engage with notifications (activation + retention)"

**Representative Question Types (Do 5 only):**
- Define success metrics for [Product/Feature]
- What metrics would you track for [Feature]?
- How would you measure success of [Product]?
- What is the north star metric for [Product]?
- How would you define KPIs for [Feature]?

**‚ù§Ô∏è Reusable Narrative (Base Story - Adapt for Each Question):**
> "When defining metrics for any product or feature, I start by understanding what it does and who uses it. Then I define the NSM - the single metric that represents both user value (what do users care about?) and business value (what drives business?). It must be actionable (we can influence it), measurable (we can track it), and predictive (predicts long-term success). I then build the KPI ladder: Input KPIs that drive the NSM (user behavior, product quality, business drivers), Leading Indicators that give early signals (activation, engagement signals), and Guardrails that protect what must not break (user trust, long-term health, cost/compliance). The framework is universal, but the metrics are context-specific."

**How to Adapt This Narrative for Each Question:**

- **Define success for [Product]:** Focus on product context ‚Üí "For [Product], I'd first understand what it does and who uses it. Then I'd define NSM based on user value (what users care about) and business value (what drives business). For example, if it's a productivity app, NSM might be Weekly Active Users who complete tasks. Input KPIs: task completion rate, feature usage, user retention. Leading indicators: first-task-completion rate, time-to-first-value. Guardrails: user satisfaction, data privacy, platform reliability."

- **What metrics for [Feature]:** Emphasize feature-specific ‚Üí "For [Feature], I'd define NSM based on what value it provides. If it's a search feature, NSM might be Successful Searches per User. Input KPIs: search volume, search success rate, search-to-action conversion. Leading indicators: first-search rate, search success rate. Guardrails: search quality, user satisfaction, platform performance."

---

### BUCKET 2: Feature-Specific Metrics
**Questions:** ~20 | **Priority:** üü¢ GREEN (High-yield)

**Board Slide Bullets:**
- **Feature Metrics:** Adoption (weekly active users), Engagement (usage per user), Value (outcomes achieved)
- **Key Insight:** Features need adoption (users try it), engagement (users use it), and value (users get value)
- **Measurement:** Feature adoption rate, feature usage rate, feature value rate
- **Framework:** Adoption ‚Üí Engagement ‚Üí Value ‚Üí Retention

**Concrete Examples:**
- "Feature adoption: % of users who try the feature - measures discovery"
- "Feature engagement: usage per user - measures value realization"
- "Feature value: outcomes achieved - measures success"

**Representative Question Types (Do 5 only):**
- How would you measure a new feature?
- What metrics indicate feature success?
- How would you improve feature adoption?
- What's the relationship between adoption and engagement?
- How do you measure feature value?

**‚ù§Ô∏è Reusable Narrative (Base Story - Adapt for Each Question):**
> "For feature-specific metrics, I measure adoption (% of users who try the feature), engagement (usage per user), and value (outcomes achieved). Input KPIs: feature discovery rate, feature usage rate, feature value rate. Leading indicators: first-feature-use rate, time-to-first-value, feature retention rate. Guardrails: core product metrics don't drop, user experience maintained, feature reliability. The framework is: Adoption ‚Üí Engagement ‚Üí Value ‚Üí Retention. Users must discover it, use it, get value from it, and come back to it."

---

### BUCKET 3: Product Improvement Metrics
**Questions:** ~15 | **Priority:** üü° YELLOW

**Board Slide Bullets:**
- **Improvement Metrics:** Before/after comparison, incremental lift, user satisfaction
- **Key Insight:** Measure improvement incrementally - compare new vs old, segment by user type
- **Measurement:** A/B test metrics, cohort comparison, satisfaction scores
- **Framework:** Baseline ‚Üí Improvement ‚Üí Validation ‚Üí Scale

**Concrete Examples:**
- "Incremental lift: new metric - old metric - measures improvement"
- "User satisfaction: NPS or satisfaction score - measures qualitative impact"
- "Cohort comparison: new users vs old users - measures improvement impact"

**Representative Question Types (Do 5 only):**
- How would you measure product improvement?
- What metrics indicate successful improvement?
- How would you validate a product change?
- What's the relationship between metrics and user satisfaction?
- How do you measure incremental impact?

**‚ù§Ô∏è Reusable Narrative (Base Story - Adapt for Each Question):**
> "For product improvement metrics, I measure incremental lift (new metric - old metric), user satisfaction (NPS or satisfaction score), and cohort comparison (new users vs old users). Input KPIs: baseline metrics, improvement metrics, user feedback. Leading indicators: early adoption rate, satisfaction signals, engagement signals. Guardrails: core metrics don't drop, user experience maintained, long-term health preserved. I measure improvement incrementally - compare new vs old, segment by user type, validate with experiments, then scale what works."

---

### BUCKET 4: Context-Specific Adaptations
**Questions:** ~11 | **Priority:** üü° YELLOW

**Board Slide Bullets:**
- **Context Types:** Consumer products, B2B products, Internal tools, Hardware products
- **Key Insight:** Same framework, different metrics based on context
- **Adaptation:** Understand context ‚Üí Apply framework ‚Üí Define context-specific metrics
- **Examples:** Consumer = engagement, B2B = adoption, Internal = efficiency, Hardware = usage

**Concrete Examples:**
- "Consumer product: NSM = engagement (DAU, time spent)"
- "B2B product: NSM = adoption (feature usage, seat utilization)"
- "Internal tool: NSM = efficiency (time saved, tasks completed)"

**Representative Question Types (Do 5 only):**
- How would you measure a consumer product?
- What metrics matter for B2B products?
- How would you define success for an internal tool?
- What's different about hardware product metrics?
- How do you adapt metrics to different contexts?

**‚ù§Ô∏è Reusable Narrative (Base Story - Adapt for Each Question):**
> "For context-specific adaptations, I use the same NSM + KPI Ladder framework but adapt the metrics to the context. For consumer products, NSM is typically engagement (DAU, time spent). For B2B products, NSM is typically adoption (feature usage, seat utilization). For internal tools, NSM is typically efficiency (time saved, tasks completed). The framework is universal - NSM ‚Üí Input KPIs ‚Üí Leading Indicators ‚Üí Guardrails - but the specific metrics depend on the context. I understand the context first, then apply the framework."

---

## üîç HOW TO IDENTIFY P2B9 (GENERAL METRICS) QUESTIONS

**Look for these keywords/phrases:**

### Explicit Keywords:
- "metrics", "KPIs", "success metrics", "how to measure", "define success"
- "what metrics", "track", "measure", "key metrics"

### Implicit Indicators:
- **Definition questions:** "how would you measure X?", "what metrics for Y?", "define success"
- **Feature questions:** "metrics for new feature", "how to measure feature success"
- **Product questions:** "success metrics for product", "KPIs for product", "what to track"
- **No specific business model:** Generic product/feature without clear business model context

### P2B9 vs Other Patterns:
- **P2B9 (General):** "What metrics for this product?" ‚Üí Focus: Universal NSM framework, adapt to context
- **P2B1-P2B8 (Specific):** "What metrics for Instagram?" ‚Üí Focus: Business model-specific metrics
- **P1 (Metric Drop):** "Metric down 25%" ‚Üí Focus: Diagnose why metric dropped

### When to Use P2B9:
- Product/feature without clear business model
- Generic "how to measure success" questions
- Questions that don't fit P2B1-P2B8 categories

---

## üö¶ TRAFFIC LIGHT PRIORITIZATION

### üü¢ GREEN (Master - Can explain to non-technical exec)
1. **Define NSM for Any Product/Feature** ‚Üí Study Bucket 1, practice 5 questions
2. **Feature-Specific Metrics** ‚Üí Study Bucket 2, practice 5 questions

### üü° YELLOW (High-yield but shaky - Practice questions)
3. **Product Improvement Metrics** ‚Üí Study Bucket 3, practice 5 questions
4. **Context-Specific Adaptations** ‚Üí Study Bucket 4, practice 5 questions

---

## ‚úÖ EXECUTIVE CHECKLIST

Before your interview, you should be able to:

- [ ] Define NSM for any product/feature (understand context, apply framework)
- [ ] Explain feature metrics (adoption, engagement, value)
- [ ] Describe improvement metrics (incremental lift, satisfaction, validation)
- [ ] Adapt framework to different contexts (consumer, B2B, internal, hardware)
- [ ] Identify guardrails for any product (trust, health, compliance)

---

## üéØ SUCCESS METRICS

**You're ready when:**
- You can explain the general metrics framework in 2 minutes
- You can adapt it to any product/feature context
- You can define NSM for any product
- You know how to build the KPI ladder (Input KPIs, Leading Indicators, Guardrails)

**Remember:** General metrics use the same NSM + KPI Ladder framework, but you adapt the specific metrics to the product/feature context. Understand context first, then apply framework.

---

## üìù NOTES

- **Total Questions:** 76
- **High-Priority Questions:** ~20 (5 per bucket across 4 buckets)
- **Study Time:** 60-90 min total
- **Approach:** Universal framework ‚Üí Context understanding ‚Üí Metric adaptation ‚Üí Narratives

**Key Insight:** General metrics questions use the same NSM + KPI Ladder framework, but you must adapt the specific metrics to the product/feature context. The framework is universal, the metrics are context-specific.
