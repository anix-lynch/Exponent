# Executive Study Plan: P2B9 - General Metrics
**Approach:** GM-style, concept-level, flexible framework  
**Time:** 60-90 min  
**Source:** 76 questions ‚Üí Flexible NSM + KPI Ladder for any product/feature

**‚ù§Ô∏è = "Hedgehog Answer"** - Your fallback narrative if you know nothing. Master these first!

---

## üéØ EXECUTIVE SCOPE (10-15 min)

### Why General Metrics Matter

**Key Insight:** General metrics questions don't have a specific business model - you need to **adapt the NSM + KPI Ladder framework** to the product/feature context. The framework is universal, but the metrics are context-specific.

**Approach:**
1. Understand the product/feature: What does it do? Who uses it?
2. Define NSM: What single metric represents success?
3. Identify drivers: What moves the NSM?
4. Set leading indicators: Early signals of success
5. Add guardrails: What must not break?

---

## üìä CONCEPT BUCKET BREAKDOWN

### BUCKET 1: Define NSM for Any Product/Feature
**Questions:** ~30 | **Priority:** üü¢ GREEN (Master this)

**Board Slide Bullets:**
- **NSM Definition:** Single metric that represents user value + business value
- **Key Insight:** Must be actionable (we can influence it), measurable (we can track it), predictive (predicts long-term success)
- **Framework:** User value (what do users care about?) + Business value (what drives business?) = NSM
- **Examples:** Engagement (DAU, time spent), Transactions (GMV, volume), Retention (D7, D30, M3), Revenue (ARR, MRR)

**Concrete Examples:**
- "Productivity app: NSM = Weekly Active Users who complete tasks (engagement + value)"
- "Search feature: NSM = Successful Searches per User (utility + engagement)"
- "Notification feature: NSM = Weekly Users who engage with notifications (activation + retention)"

**Representative Question Types (Do 5 only):**
- Define success metrics for [Product/Feature]
- What metrics would you track for [Feature]?
- How would you measure success of [Product]?
- What is the north star metric for [Product]?
- How would you define KPIs for [Feature]?

**‚ù§Ô∏è Reusable Narrative (Base Story - Adapt for Each Question):**

**Framework:** `Understand Context ‚Üí Define NSM ‚Üí Build KPI Ladder ‚Üí Input KPIs ‚Üí Leading Indicators ‚Üí Guardrails`

**Memorizable Answer:**

When defining metrics for any product or feature, I start by understanding what it does and who uses it.

**1Ô∏è‚É£ Understand Context** ‚Üí What does it do? Who uses it?

**2Ô∏è‚É£ Define NSM** ‚Üí Single metric that represents both user value (what do users care about?) and business value (what drives business?). Must be actionable (we can influence it), measurable (we can track it), and predictive (predicts long-term success).

**3Ô∏è‚É£ Build KPI Ladder** ‚Üí Input KPIs (user behavior, product quality, business drivers), Leading Indicators (activation, engagement signals), Guardrails (user trust, long-term health, cost/compliance).

**Key Principle:** Framework is universal, but metrics are context-specific - adapt to the product/feature.

---

**How to Adapt This Narrative for Each Question:**

- **Define success for [Product]:** Focus on product context
  - "First understand: what does it do? Who uses it?"
  - "Define NSM based on user value + business value"
  - "Example: productivity app ‚Üí NSM: Weekly Active Users who complete tasks"
  - "Input KPIs: task completion rate, feature usage, user retention"
  - "Leading indicators: first-task-completion rate, time-to-first-value"
  - "Guardrails: user satisfaction, data privacy, platform reliability"

- **What metrics for [Feature]:** Emphasize feature-specific
  - "Define NSM based on what value it provides"
  - "Example: search feature ‚Üí NSM: Successful Searches per User"
  - "Input KPIs: search volume, search success rate, search-to-action conversion"
  - "Leading indicators: first-search rate, search success rate"
  - "Guardrails: search quality, user satisfaction, platform performance"

---

### BUCKET 2: Feature-Specific Metrics
**Questions:** ~20 | **Priority:** üü¢ GREEN (High-yield)

**Board Slide Bullets:**
- **Feature Metrics:** Adoption (weekly active users), Engagement (usage per user), Value (outcomes achieved)
- **Key Insight:** Features need adoption (users try it), engagement (users use it), and value (users get value)
- **Measurement:** Feature adoption rate, feature usage rate, feature value rate
- **Framework:** Adoption ‚Üí Engagement ‚Üí Value ‚Üí Retention

**Concrete Examples:**
- "Feature adoption: % of users who try the feature - measures discovery"
- "Feature engagement: usage per user - measures value realization"
- "Feature value: outcomes achieved - measures success"

**Representative Question Types (Do 5 only):**
- How would you measure a new feature?
- What metrics indicate feature success?
- How would you improve feature adoption?
- What's the relationship between adoption and engagement?
- How do you measure feature value?

**‚ù§Ô∏è Reusable Narrative (Base Story - Adapt for Each Question):**

**Framework:** `Adoption ‚Üí Engagement ‚Üí Value ‚Üí Retention`

**Memorizable Answer:**

For feature-specific metrics, I measure three key metrics.

**1Ô∏è‚É£ Adoption** ‚Üí % of users who try the feature.

**2Ô∏è‚É£ Engagement** ‚Üí Usage per user.

**3Ô∏è‚É£ Value** ‚Üí Outcomes achieved.

**4Ô∏è‚É£ Input KPIs** ‚Üí Feature discovery rate, feature usage rate, feature value rate.

**5Ô∏è‚É£ Guardrails** ‚Üí Core product metrics don't drop, user experience maintained, feature reliability.

**Key Principle:** Users must discover it, use it, get value from it, and come back to it.

---

### BUCKET 3: Product Improvement Metrics
**Questions:** ~15 | **Priority:** üü° YELLOW

**Board Slide Bullets:**
- **Improvement Metrics:** Before/after comparison, incremental lift, user satisfaction
- **Key Insight:** Measure improvement incrementally - compare new vs old, segment by user type
- **Measurement:** A/B test metrics, cohort comparison, satisfaction scores
- **Framework:** Baseline ‚Üí Improvement ‚Üí Validation ‚Üí Scale

**Concrete Examples:**
- "Incremental lift: new metric - old metric - measures improvement"
- "User satisfaction: NPS or satisfaction score - measures qualitative impact"
- "Cohort comparison: new users vs old users - measures improvement impact"

**Representative Question Types (Do 5 only):**
- How would you measure product improvement?
- What metrics indicate successful improvement?
- How would you validate a product change?
- What's the relationship between metrics and user satisfaction?
- How do you measure incremental impact?

**‚ù§Ô∏è Reusable Narrative (Base Story - Adapt for Each Question):**

**Framework:** `Incremental Lift ‚Üí User Satisfaction ‚Üí Cohort Comparison ‚Üí Input KPIs ‚Üí Guardrails`

**Memorizable Answer:**

For product improvement metrics, I measure three key metrics.

**1Ô∏è‚É£ Incremental Lift** ‚Üí New metric - old metric.

**2Ô∏è‚É£ User Satisfaction** ‚Üí NPS or satisfaction score.

**3Ô∏è‚É£ Cohort Comparison** ‚Üí New users vs old users.

**4Ô∏è‚É£ Input KPIs** ‚Üí Baseline metrics, improvement metrics, user feedback.

**5Ô∏è‚É£ Guardrails** ‚Üí Core metrics don't drop, user experience maintained, long-term health preserved.

**Key Principle:** Measure improvement incrementally - compare new vs old, segment by user type, validate with experiments, scale what works.

---

### BUCKET 4: Context-Specific Adaptations
**Questions:** ~11 | **Priority:** üü° YELLOW

**Board Slide Bullets:**
- **Context Types:** Consumer products, B2B products, Internal tools, Hardware products
- **Key Insight:** Same framework, different metrics based on context
- **Adaptation:** Understand context ‚Üí Apply framework ‚Üí Define context-specific metrics
- **Examples:** Consumer = engagement, B2B = adoption, Internal = efficiency, Hardware = usage

**Concrete Examples:**
- "Consumer product: NSM = engagement (DAU, time spent)"
- "B2B product: NSM = adoption (feature usage, seat utilization)"
- "Internal tool: NSM = efficiency (time saved, tasks completed)"

**Representative Question Types (Do 5 only):**
- How would you measure a consumer product?
- What metrics matter for B2B products?
- How would you define success for an internal tool?
- What's different about hardware product metrics?
- How do you adapt metrics to different contexts?

**‚ù§Ô∏è Reusable Narrative (Base Story - Adapt for Each Question):**

**Framework:** `Understand Context ‚Üí Apply Universal Framework ‚Üí Adapt Metrics`

**Memorizable Answer:**

For context-specific adaptations, I use the same NSM + KPI Ladder framework but adapt the metrics to the context.

**1Ô∏è‚É£ Consumer Products** ‚Üí NSM: engagement (DAU, time spent).

**2Ô∏è‚É£ B2B Products** ‚Üí NSM: adoption (feature usage, seat utilization).

**3Ô∏è‚É£ Internal Tools** ‚Üí NSM: efficiency (time saved, tasks completed).

**4Ô∏è‚É£ Universal Framework** ‚Üí NSM ‚Üí Input KPIs ‚Üí Leading Indicators ‚Üí Guardrails.

**Key Principle:** Framework is universal, but specific metrics depend on context - understand context first, then apply framework.

---

## üîç HOW TO IDENTIFY P2B9 (GENERAL METRICS) QUESTIONS

**Look for these keywords/phrases:**

### Explicit Keywords:
- "metrics", "KPIs", "success metrics", "how to measure", "define success"
- "what metrics", "track", "measure", "key metrics"

### Implicit Indicators:
- **Definition questions:** "how would you measure X?", "what metrics for Y?", "define success"
- **Feature questions:** "metrics for new feature", "how to measure feature success"
- **Product questions:** "success metrics for product", "KPIs for product", "what to track"
- **No specific business model:** Generic product/feature without clear business model context

### P2B9 vs Other Patterns:
- **P2B9 (General):** "What metrics for this product?" ‚Üí Focus: Universal NSM framework, adapt to context
- **P2B1-P2B8 (Specific):** "What metrics for Instagram?" ‚Üí Focus: Business model-specific metrics
- **P1 (Metric Drop):** "Metric down 25%" ‚Üí Focus: Diagnose why metric dropped

### When to Use P2B9:
- Product/feature without clear business model
- Generic "how to measure success" questions
- Questions that don't fit P2B1-P2B8 categories

---

## üö¶ TRAFFIC LIGHT PRIORITIZATION

### üü¢ GREEN (Master - Can explain to non-technical exec)
1. **Define NSM for Any Product/Feature** ‚Üí Study Bucket 1, practice 5 questions
2. **Feature-Specific Metrics** ‚Üí Study Bucket 2, practice 5 questions

### üü° YELLOW (High-yield but shaky - Practice questions)
3. **Product Improvement Metrics** ‚Üí Study Bucket 3, practice 5 questions
4. **Context-Specific Adaptations** ‚Üí Study Bucket 4, practice 5 questions

---

## ‚úÖ EXECUTIVE CHECKLIST

Before your interview, you should be able to:

- [ ] Define NSM for any product/feature (understand context, apply framework)
- [ ] Explain feature metrics (adoption, engagement, value)
- [ ] Describe improvement metrics (incremental lift, satisfaction, validation)
- [ ] Adapt framework to different contexts (consumer, B2B, internal, hardware)
- [ ] Identify guardrails for any product (trust, health, compliance)

---

## üéØ SUCCESS METRICS

**You're ready when:**
- You can explain the general metrics framework in 2 minutes
- You can adapt it to any product/feature context
- You can define NSM for any product
- You know how to build the KPI ladder (Input KPIs, Leading Indicators, Guardrails)

**Remember:** General metrics use the same NSM + KPI Ladder framework, but you adapt the specific metrics to the product/feature context. Understand context first, then apply framework.

---
