# Executive Study Plan: P3 - Funnel Analysis
**Approach:** GM-style, concept-level, not per-question  
**Time:** 2-3 hours total across 3 passes  
**Source:** 40 questions ‚Üí 5 concept buckets ‚Üí 3-5 high-impact buckets

**‚ù§Ô∏è = "Hedgehog Answer"** - Your fallback narrative if you know nothing. Master these first!

---

## üéØ EXECUTIVE SCOPE (15-20 min)

### Your 3-5 High-Impact Buckets (Pick Based on Role)

**For Business Leader / GM:**
1. ‚úÖ **Classic Funnel Drop-off** (HIGHEST PRIORITY)
2. ‚úÖ **Conversion Optimization** (HIGH PRIORITY)
3. ‚úÖ **Funnel Prioritization** (MEDIUM-HIGH)
4. ‚ö†Ô∏è **Retention/Engagement Funnels** (MEDIUM)
5. ‚ùå **Multi-step Complex Funnels** (LOW - skip for now)

**For Product Manager:**
1. ‚úÖ **Classic Funnel Drop-off** (HIGHEST)
2. ‚úÖ **Conversion Optimization** (HIGH)
3. ‚úÖ **Funnel Prioritization** (MEDIUM-HIGH)
4. ‚ö†Ô∏è **Retention/Engagement Funnels** (MEDIUM)
5. ‚ùå **Multi-step Complex Funnels** (LOW)

---

## üìä CONCEPT BUCKET BREAKDOWN

### BUCKET 1: Classic Funnel Drop-off ("X% drop at step Y")
**Questions:** ~15 | **Priority:** üü¢ GREEN (Master this)

**Board Slide Bullets:**
- **What:** Specific drop-off at a funnel step (sign-up, checkout, application, onboarding)
- **Framework:** Define Funnel Steps ‚Üí Measure Drop-off ‚Üí Identify Friction ‚Üí Hypothesize Fix ‚Üí Test
- **Key Insight:** Find the biggest drop, then ask WHY users get stuck at that step
- **Common Friction Types:** UX (confusing, slow), Trust (price shock, permissions), Value (unclear benefit), Technical (bugs, latency)
- **Fix Approach:** Reduce friction, test incrementally, measure conversion improvement

**Concrete Examples:**
- "55% drop at application submission - likely form too long or unclear required fields"
- "25% drop-off during sign-up - likely email verification friction or too many steps"
- "42% drop at checkout - likely shipping cost surprise or forced account creation"

**Representative Questions (Do 5 only):**
- Q4: 55% of users do not complete the application from the application page to the submission page. Why do you think this is the case?
- Q13: A newly launched mobile app has a 25% drop-off during sign-up. How would you investigate the issue?
- Q2715: You're a PM at a food delivery app where conversion rates have declined over the past week. How would you investigate the causes? (Conversion: From users browsing to placing orders.)
- Q2731: You're a PM at Facebook. How would you decide whether to remove the profile photo step from the onboarding experience?
- Q2830: You're a PM in the Onboarding team. You have to increase the conversion of the onboarding funnel by 15% in 3 months.

**‚ù§Ô∏è Reusable Narrative (Base Story - Adapt for Each Question):**
> "When I see a funnel drop-off, I follow a systematic approach. First, I define the funnel steps - the exact user journey from entry to conversion. Then I measure drop-off between each step to find the biggest bottleneck. Once I identify where users drop, I ask WHY - is it UX friction (confusing, slow, too many fields), trust friction (price shock, permissions, privacy concerns), value friction (unclear benefit), or technical friction (bugs, latency)? I use session replays, segment analysis, and qualitative feedback to diagnose. Then I hypothesize 1-2 targeted fixes that address the root cause, prioritize by impact and effort, and test with A/B tests or staged rollouts. I measure the conversion improvement and use guardrails to ensure downstream metrics don't degrade."

**How to Adapt This Narrative for Each Question:**

- **Q4 (55% drop at application submission):** Focus on form friction ‚Üí "For a 55% drop at application submission, I'd first define the funnel: open application ‚Üí start application ‚Üí fill form ‚Üí submit. The biggest drop is likely fill form ‚Üí submit. I'd hypothesize: form too long, required fields unclear, or users unsure why info is needed. I'd check session replays to see where users abandon. Fixes: reduce required fields, add progress bar, save progress, explain why each field is needed. I'd A/B test and measure submission rate improvement."

- **Q13 (25% drop-off during sign-up):** Emphasize sign-up flow ‚Üí "For 25% sign-up drop-off, I'd define the funnel: app open ‚Üí click sign-up ‚Üí enter email/password ‚Üí verify email ‚Üí complete sign-up. I'd measure drop-off at each step. Likely friction: email verification (slow email, goes to spam, user distracted). I'd check: verification email delivery time, spam rate, completion rate by device. Fixes: allow limited access before verification, resend CTA, inline verification. I'd test and measure sign-up completion rate."

- **Q2715 (Conversion declined over week):** Focus on investigation ‚Üí "For conversion decline, I'd first check if it's a data bug, then define the funnel: browse ‚Üí product view ‚Üí add to cart ‚Üí checkout ‚Üí purchase. I'd measure drop-off at each step and compare to baseline. I'd segment by platform, geography, and user type to find the hot spot. Likely causes: product change, pricing change, or technical issue. I'd check error rates, latency, and support tickets. I'd validate with quick checks and propose fixes based on root cause."

- **Q2731 (Remove profile photo step?):** Emphasize decision framework ‚Üí "To decide whether to remove profile photo step, I'd first measure current funnel: sign-up ‚Üí enter info ‚Üí upload photo ‚Üí complete. I'd check drop-off at photo step - if it's high, removing it might help. But I'd also check: does photo improve downstream metrics (connections, engagement)? I'd run A/B test: one group with photo, one without. Measure: sign-up completion rate, downstream engagement, user satisfaction. If removing photo increases sign-up without hurting engagement, remove it."

- **Q2830 (Increase onboarding conversion 15%):** Focus on improvement ‚Üí "To increase onboarding conversion 15%, I'd first measure current funnel and identify biggest drop-off. Then I'd segment by user type to see if it's universal or specific. I'd hypothesize top 3-5 friction points, prioritize by impact and effort. Likely fixes: reduce steps, add progress indicator, allow skip optional steps, improve value communication. I'd test fixes incrementally, measure conversion improvement, and scale what works. Target: 15% lift in 3 months through systematic optimization."

---

### BUCKET 2: Conversion Optimization ("How to improve conversion?")
**Questions:** ~10 | **Priority:** üü¢ GREEN (High-yield)

**Board Slide Bullets:**
- **What:** "How would you improve conversion?" or "How to optimize booking/checkout/purchase?"
- **Framework:** Same funnel analysis, but focus on optimization opportunities
- **Key Insight:** Find biggest drop-off, identify friction, test fixes, measure improvement
- **Approach:** Map current funnel ‚Üí Identify bottlenecks ‚Üí Hypothesize fixes ‚Üí Test ‚Üí Scale

**Concrete Examples:**
- "Improve booking conversion: map funnel, find drop at payment step, test guest checkout"
- "Optimize checkout: reduce steps, show shipping cost earlier, allow guest checkout"
- "Increase sign-up: reduce friction, add social login, show value earlier"

**Representative Questions (Do 5 only):**
- Q1521: How would you optimize booking.com to improve conversion rates?
- Q1465: How would you increase the conversion rate for YouTube Premium?
- Q2720: You're a PM at a travel booking platform. Which step of the booking process would you address first to reduce drop-offs?
- Q2726: You're a PM at an e-commerce site. What percentage discount should different customers get during onboarding?
- Q1756: Only 1 in 5 riders tips their driver after a ride. How would you improve this?

**‚ù§Ô∏è Reusable Narrative (Base Story - Adapt for Each Question):**
> "When optimizing conversion, I map the current funnel to understand where users drop. I measure drop-off at each step and identify the biggest bottleneck. Then I segment by user type, device, and geography to see if friction is universal or specific. I hypothesize top 3-5 friction points - UX (too many steps, confusing), trust (price surprise, permissions), value (unclear benefit), or technical (slow, bugs). I prioritize fixes by impact and effort, then test incrementally. I measure conversion improvement and use guardrails to ensure downstream metrics don't degrade. The key is systematic optimization - fix one step at a time, measure impact, then move to next."

**How to Adapt This Narrative for Each Question:**

- **Q1521 (Optimize booking.com conversion):** Focus on booking flow ‚Üí "To optimize booking.com conversion, I'd map the funnel: search ‚Üí results ‚Üí select hotel ‚Üí enter details ‚Üí payment ‚Üí confirmation. I'd measure drop-off at each step. Likely bottlenecks: price comparison (users leave to compare), payment friction (too many fields), or trust (reviews, cancellation policy). I'd segment by device (mobile vs desktop) and geography. Fixes: show price comparison, simplify payment, highlight trust signals. I'd test and measure booking conversion improvement."

- **Q1465 (Increase YouTube Premium conversion):** Emphasize subscription ‚Üí "To increase YouTube Premium conversion, I'd map the funnel: watch video ‚Üí see Premium prompt ‚Üí click learn more ‚Üí see pricing ‚Üí start trial ‚Üí convert. I'd measure drop-off at each step. Likely friction: pricing (too expensive), value (unclear benefit), or trial (too short). I'd segment by user type (heavy vs light watchers). Fixes: show value earlier, offer longer trial, highlight ad-free benefit. I'd test and measure conversion rate improvement."

- **Q2720 (Which booking step to address first?):** Focus on prioritization ‚Üí "To prioritize booking steps, I'd map the funnel and measure drop-off at each step. I'd calculate: drop-off % √ó users at that step = total users lost. The step with highest total users lost is the priority. I'd also consider: ease of fix (quick wins first), impact on downstream (don't break later steps), and user segment (fix for biggest segment first). Typically, payment step has highest drop-off, so I'd start there."

- **Q2726 (What discount for onboarding?):** Emphasize personalization ‚Üí "For onboarding discounts, I'd first measure current funnel and conversion by user segment. I'd segment by: user value (high vs low intent), acquisition cost (high vs low CAC), and behavior (new vs returning). I'd test different discount levels by segment. High-intent users might need smaller discount, low-intent might need larger. I'd measure: conversion rate, LTV, and overall ROI. Goal: maximize conversion while maintaining unit economics."

- **Q1756 (Improve tipping rate):** Focus on behavioral change ‚Üí "To improve tipping rate from 20% to higher, I'd map the funnel: ride completes ‚Üí rating screen ‚Üí tip prompt ‚Üí tip entered ‚Üí tip submitted. I'd measure drop-off at each step. Likely friction: tip prompt timing (too late), default amount (unclear), or value (unclear why tip). I'd segment by ride type and user segment. Fixes: show tip prompt earlier, suggest default amounts, explain driver benefit. I'd test and measure tipping rate improvement."

---

### BUCKET 3: Retention/Engagement Funnels
**Questions:** ~8 | **Priority:** üü° YELLOW (High-yield but needs practice)

**Board Slide Bullets:**
- **What:** "How to improve retention/engagement?" - funnel over time, not just one session
- **Framework:** Define retention funnel ‚Üí Measure drop-off over time ‚Üí Identify friction ‚Üí Fix
- **Key Insight:** Retention funnels measure behavior over time (D1, D7, D30), not just conversion
- **Approach:** Map user journey over time ‚Üí Find where users drop ‚Üí Identify why ‚Üí Fix

**Concrete Examples:**
- "Retention funnel: Sign up ‚Üí First value ‚Üí Return D7 ‚Üí Return D30 - find where users drop"
- "Engagement funnel: Open app ‚Üí First action ‚Üí Core value action ‚Üí Return next week"
- "Adoption high but retention low: users try but don't see long-term value"

**Representative Questions (Do 5 only):**
- Q1846: Suppose adoption is high, but retention is low‚Äîhow would you diagnose and communicate the issue?
- Q2157: The product team reports a decline in 30-day user retention. How would you approach this problem?
- Q1256: How would you boost retention for DashPass?
- Q1410: How would you improve retention on LinkedIn?
- Q2738: You're a PM at Instacart. What would you do to improve retention?

**‚ù§Ô∏è Reusable Narrative (Base Story - Adapt for Each Question):**
> "For retention/engagement funnels, I map the user journey over time: sign up ‚Üí first value ‚Üí return D7 ‚Üí return D30. I measure drop-off at each time point to find where users churn. I segment by cohort to see if it's a recent issue or ongoing. I identify friction: users don't see long-term value, no habit formed, or value not delivered. I hypothesize fixes: guide users to core value action, add reminders/nudges, improve onboarding, or enhance product value. I test fixes and measure retention improvement (D7, D30). The key is understanding why users don't return, not just that they don't return."

**How to Adapt This Narrative for Each Question:**

- **Q1846 (Adoption high, retention low):** Focus on diagnosis ‚Üí "If adoption is high but retention low, I'd map the funnel: sign up ‚Üí first action ‚Üí core value action ‚Üí return D7. The drop is likely after first action - users try but don't return. I'd segment by user type and first action to see patterns. Likely causes: users don't see long-term value, no habit formed, or value not delivered. I'd check: what do retained users do differently? I'd communicate: adoption is good (users try), but retention is low (users don't return) - we need to improve value delivery or habit formation."

- **Q2157 (30-day retention decline):** Emphasize investigation ‚Üí "For 30-day retention decline, I'd first check if it's a data bug, then map the retention funnel: sign up ‚Üí first value ‚Üí return D7 ‚Üí return D30. I'd measure drop-off at each point and compare to baseline. I'd segment by cohort to see if it's recent or ongoing. I'd check: product changes, external factors, or user behavior changes. I'd identify where users drop and why, then propose fixes based on root cause."

- **Q1256 (Boost DashPass retention):** Focus on subscription ‚Üí "To boost DashPass retention, I'd map the funnel: sign up ‚Üí first order ‚Üí second order ‚Üí month renewal. I'd measure drop-off at each step. Likely friction: users don't see value (delivery fee savings), don't order enough, or forget to use. I'd segment by order frequency and user type. Fixes: show savings prominently, remind users of benefit, offer incentives for repeat orders. I'd test and measure retention improvement."

---

### BUCKET 4: Funnel Prioritization ("Which step to fix first?")
**Questions:** ~4 | **Priority:** üü° YELLOW

**Board Slide Bullets:**
- **What:** "Which step would you address first?" or "How do you prioritize funnel fixes?"
- **Framework:** Calculate impact = drop-off % √ó users at that step, then consider ease and downstream impact
- **Key Insight:** Fix the step with highest total users lost, not just highest drop-off %
- **Prioritization:** Impact (users saved) √ó Ease (effort to fix) √ó Risk (downstream impact)

**Concrete Examples:**
- "Step with 50% drop-off but 100 users = 50 users lost"
- "Step with 20% drop-off but 1000 users = 200 users lost (fix this first!)"
- "Prioritize by: total users lost, ease of fix, downstream impact"

**Representative Questions (Do 5 only):**
- Q1696: In a multi-step funnel with drop-offs at each stage, which stage would you prioritize addressing first?
- Q985: Given this user funnel, how would you prioritize addressing drop-off points? Come up with design solutions to increase conversion.
- Q2720: You're a PM at a travel booking platform. Which step of the booking process would you address first to reduce drop-offs?
- Q2706: You work at SFO airport, and the CEO asks you to improve the experience from car drop-off to boarding the plane. What's one recommendation you would make?
- Q2887: You're a PM at CarGurus. You launched in Canada 8 months ago and conversions are lower in Canada than the US. What would you do?

**‚ù§Ô∏è Reusable Narrative (Base Story - Adapt for Each Question):**
> "When prioritizing funnel fixes, I calculate impact for each step: drop-off % √ó users at that step = total users lost. The step with highest total users lost is usually the priority. But I also consider: ease of fix (quick wins first), downstream impact (don't break later steps), and user segment (fix for biggest segment first). I prioritize by: Impact (users saved) √ó Ease (effort to fix) √ó Risk (downstream impact). I start with high-impact, low-effort fixes, then move to high-impact, high-effort fixes. The key is fixing the step that saves the most users, not just the step with highest drop-off %."

**How to Adapt This Narrative for Each Question:**

- **Q1696 (Which stage to prioritize?):** Focus on calculation ‚Üí "To prioritize stages, I'd calculate impact for each: drop-off % √ó users at that step = total users lost. For example, if Step 2 has 50% drop-off but only 100 users reach it, that's 50 users lost. If Step 4 has 20% drop-off but 1000 users reach it, that's 200 users lost - fix Step 4 first! I'd also consider ease of fix and downstream impact. The step with highest total users lost is the priority."

- **Q985 (Prioritize drop-off points):** Emphasize design solutions ‚Üí "To prioritize drop-off points, I'd calculate impact (drop-off % √ó users at step) for each step. Then I'd identify friction at high-impact steps: UX (too many fields, confusing), trust (price surprise), value (unclear benefit), or technical (slow, bugs). I'd propose design solutions: reduce steps, add progress indicator, show value earlier, simplify forms. I'd prioritize by impact and ease, then test and measure conversion improvement."

- **Q2706 (SFO airport experience):** Focus on physical funnel ‚Üí "For airport experience, I'd map the funnel: car drop-off ‚Üí check-in ‚Üí security ‚Üí gate ‚Üí boarding. I'd measure time and friction at each step. Likely bottleneck: security (longest wait, most friction). I'd prioritize: reduce security wait time (biggest impact on experience). Solutions: more lanes, better queuing, pre-check promotion. I'd measure: total time from drop-off to boarding, user satisfaction."

---

### BUCKET 5: Multi-step Complex Funnels
**Questions:** ~3 | **Priority:** üî¥ RED (Low impact - skip for now)

**Examples:** Complex multi-step processes, enterprise workflows, long sales cycles

**Decision:** These are advanced - only study if you have extra time or they come up in your specific role.

---

## üö¶ TRAFFIC LIGHT PRIORITIZATION

### üü¢ GREEN (Master - Can explain to non-technical exec)
1. **Classic Funnel Drop-off** ‚Üí Study Bucket 1, practice 5 questions
2. **Conversion Optimization** ‚Üí Study Bucket 2, practice 5 questions

### üü° YELLOW (High-yield but shaky - Practice questions)
3. **Retention/Engagement Funnels** ‚Üí Study Bucket 3, practice 5 questions
4. **Funnel Prioritization** ‚Üí Study Bucket 4, practice 5 questions

---

## üìÖ DAILY ROUTINE TEMPLATE (2-3 hours)

### Day 1: Classic Funnel Drop-off (üü¢)
- **30 min:** Create "board slide" summary (use Bucket 1 bullets above)
- **60 min:** Practice 5 representative questions
- **30 min:** Verbal rehearsal - explain out loud like in interview

### Day 2: Conversion Optimization (üü¢)
- **30 min:** Board slide summary (Bucket 2)
- **60 min:** Practice 5 questions
- **30 min:** Verbal rehearsal

### Day 3: Retention/Engagement Funnels (üü°)
- **30 min:** Board slide summary (Bucket 3)
- **60 min:** Practice 5 questions
- **30 min:** Verbal rehearsal

### Day 4: Funnel Prioritization (üü°)
- **30 min:** Board slide summary (Bucket 4)
- **60 min:** Practice 5 questions
- **30 min:** Verbal rehearsal

---

## ‚úÖ EXECUTIVE CHECKLIST

Before your interview, you should be able to:

- [ ] Walk through funnel analysis framework in 2 minutes (Define ‚Üí Measure ‚Üí Identify ‚Üí Hypothesize ‚Üí Test)
- [ ] Explain how to find the biggest drop-off (calculate drop-off % at each step)
- [ ] List 4 types of friction (UX, Trust, Value, Technical)
- [ ] Describe how to prioritize funnel fixes (impact √ó ease √ó risk)
- [ ] Explain the difference between funnel (where users drop) and cohort (who drops over time)

---

## üéØ SUCCESS METRICS

**You're ready when:**
- You can explain the P3 framework to a non-technical person in 2 minutes
- You have 4 reusable narratives (one per bucket) that you can adapt
- You've practiced 15-20 representative questions total (5 per bucket, not all 40!)
- You focus on **systematic analysis, friction identification, and incremental testing**, not memorizing answers

**Remember:** P3 is about systematic funnel analysis. The framework works for any funnel, regardless of product or industry.

---

## üìù NOTES

- **Total Questions:** 40
- **High-Priority Questions:** ~20 (5 per bucket across 4 buckets)
- **Study Time:** 2-3 hours total (not per question!)
- **Approach:** Concept clusters ‚Üí Board slides ‚Üí Representative questions ‚Üí Narratives

**Key Insight:** Most questions follow the same funnel analysis framework. Master the 4 concept buckets and their narratives, then adapt to any P3 question.

**Key Distinction:** Funnel (P3) = where users drop in a single journey. Cohort (P4) = who drops over time across multiple sessions.
