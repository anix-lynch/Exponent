# L1 - Data Trust

**Formula:** `Source â†’ Freshness â†’ Completeness â†’ Bias â†’ Sanity Checks`

---

## ğŸ§  Mental Model (ASCII Tree)

```
START: A metric looks wrong / decision depends on this data
â”‚
â”œâ”€ 1) Source (WHERE did this come from?)
â”‚   â”‚
â”‚   â”œâ”€ Identify origin
â”‚   â”‚   â”œâ”€ Primary (product logs, first-party events)
â”‚   â”‚   â”œâ”€ Secondary (internal pipelines, transformations)
â”‚   â”‚   â””â”€ External (vendors, partners, scraped data)
â”‚   â”‚
â”‚   â””â”€ Validate ownership
â”‚       â”œâ”€ Who maintains it?
â”‚       â”œâ”€ Who is on-call when it breaks?
â”‚       â””â”€ Is there documentation / lineage?
â”‚
â”œâ”€ 2) Freshness (IS it up to date?)
â”‚   â”‚
â”‚   â”œâ”€ Expected latency
â”‚   â”‚   â”œâ”€ Real-time
â”‚   â”‚   â”œâ”€ Hourly
â”‚   â”‚   â””â”€ Daily / Batch
â”‚   â”‚
â”‚   â””â”€ Check gaps
â”‚       â”œâ”€ Last updated timestamp
â”‚       â”œâ”€ Delays vs SLA
â”‚       â””â”€ Silent failures (no alerts but stale data)
â”‚
â”œâ”€ 3) Completeness (IS anything missing?)
â”‚   â”‚
â”‚   â”œâ”€ Coverage checks
â”‚   â”‚   â”œâ”€ Missing rows / days
â”‚   â”‚   â”œâ”€ Null or default-heavy fields
â”‚   â”‚   â””â”€ Partial segments dropped
â”‚   â”‚
â”‚   â””â”€ Join loss
â”‚       â”œâ”€ Inner joins removing data
â”‚       â”œâ”€ Key mismatches
â”‚       â””â”€ Upstream schema changes
â”‚
â”œâ”€ 4) Bias (WHO is over- or under-represented?)
â”‚   â”‚
â”‚   â”œâ”€ Sampling bias
â”‚   â”‚   â”œâ”€ Logged-in only
â”‚   â”‚   â”œâ”€ Power users
â”‚   â”‚   â””â”€ íŠ¹ì • ì§€ì—­ / í”Œë«í¼
â”‚   â”‚
â”‚   â””â”€ Measurement bias
â”‚       â”œâ”€ Proxy â‰  true behavior
â”‚       â”œâ”€ Instrumentation gaps
â”‚       â””â”€ Incentives to game metrics
â”‚
â””â”€ 5) Sanity Checks (DO numbers pass smell test?)
    â”‚
    â”œâ”€ Trend checks (sharp jumps/drops)
    â”œâ”€ Ratio checks (conversion > 100%?)
    â”œâ”€ Cross-metric consistency
    â””â”€ Compare to historical baselines
```

---

## ğŸ”‘ Golden Rule

No decision is better than a confident decision on bad data.
If trust is low â†’ **slow down, qualify, or re-measure**.

---

## ğŸ“Œ Sample: Revenue Drop Investigation

**Question:**
"Revenue dropped 20% last week â€” can we trust this?"

```
START: Revenue drop observed
â”‚
â”œâ”€ 1) Source
â”‚   â””â”€ Revenue from billing DB, owned by Finance
â”‚
â”œâ”€ 2) Freshness
â”‚   â””â”€ Data is T+2 days late (pipeline delay)
â”‚
â”œâ”€ 3) Completeness
â”‚   â””â”€ Mobile payments missing after SDK update
â”‚
â”œâ”€ 4) Bias
â”‚   â””â”€ Only web users counted â†’ under-reporting
â”‚
â””â”€ 5) Sanity Checks
    â””â”€ Orders flat, ARPU stable â†’ drop is artificial
```

**Conclusion:** Data issue, not real business decline.

---

## ğŸ“Š Data Trust Checklist (Quick Fill)

```
Check        | Status | Notes
-----------------------------------------
Source       |  âœ… / âŒ | Owner, lineage
Freshness    |  âœ… / âŒ | Last update time
Completeness |  âœ… / âŒ | Missing segments
Bias         |  âœ… / âŒ | Who is excluded?
Sanity       |  âœ… / âŒ | Trends & ratios
```

---

## ğŸ’¬ Language That Works

* "Before acting, let's validate whether this data is trustworthy."
* "What assumptions does this metric rely on?"
* "Which users or events might be missing here?"

---

## ğŸ”‘ 5-Second Recall

```
Where did this come from?
â†’ Is it fresh?
â†’ Is anything missing?
â†’ Who is over/under counted?
â†’ Does it pass the smell test?
```

If you want, next we can do **L2 â€“ Scale & Capacity**, or I can compress **L1** into a **30-second interview answer** you can memorize.
