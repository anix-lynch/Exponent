# P9 - Decision Under Uncertainty

**Formula:** `Clarify Assumptions â†’ Identify Risks â†’ Validation Plan â†’ Decide`

---

## ðŸ§  Mental Model (ASCII Tree)

```
START: We must decide, but information is incomplete
â”‚
â”œâ”€ 1) Clarify Assumptions
â”‚   â”‚
â”‚   â”œâ”€ What do we believe is true?
â”‚   â”‚   â”œâ”€ User behavior assumptions
â”‚   â”‚   â”œâ”€ Market / demand assumptions
â”‚   â”‚   â”œâ”€ Technical feasibility assumptions
â”‚   â”‚   â””â”€ Timing / dependency assumptions
â”‚   â”‚
â”‚   â””â”€ Classify assumptions
â”‚       â”œâ”€ Critical (decision breaks if wrong)
â”‚       â””â”€ Non-critical (nice to know)
â”‚
â”œâ”€ 2) Identify Risks
â”‚   â”‚
â”‚   â”œâ”€ If assumption is wrong, what happens?
â”‚   â”‚   â”œâ”€ Revenue risk
â”‚   â”‚   â”œâ”€ User trust / UX risk
â”‚   â”‚   â”œâ”€ Technical / scalability risk
â”‚   â”‚   â”œâ”€ Legal / compliance risk
â”‚   â”‚   â””â”€ Opportunity cost
â”‚   â”‚
â”‚   â””â”€ Rank risks
â”‚       â”œâ”€ High impact Ã— high likelihood â†’ MUST address
â”‚       â””â”€ Low impact or low likelihood â†’ monitor
â”‚
â”œâ”€ 3) Validation Plan
â”‚   â”‚
â”‚   â”œâ”€ What is the cheapest signal to reduce uncertainty?
â”‚   â”‚   â”œâ”€ Qualitative: user interviews, expert review
â”‚   â”‚   â”œâ”€ Quantitative: logs, metrics, small experiments
â”‚   â”‚   â”œâ”€ Proxies: analogous products, historical data
â”‚   â”‚   â””â”€ Time-boxed spike / prototype
â”‚   â”‚
â”‚   â””â”€ Decide upfront
â”‚       â”œâ”€ What result would change the decision?
â”‚       â””â”€ What result is "good enough" to proceed?
â”‚
â””â”€ 4) Decide
    â”‚
    â”œâ”€ Option A: Proceed now
    â”‚   â””â”€ If upside >> downside and risks are bounded
    â”‚
    â”œâ”€ Option B: Delay and validate
    â”‚   â””â”€ If one critical unknown dominates
    â”‚
    â””â”€ Option C: Kill / pivot
        â””â”€ If downside is irreversible or catastrophic
```

---

## ðŸ“Œ Sample: AI Auto-Reply Feature Launch

**Question:**
"Should we launch a new AI-powered auto-reply feature for customer support?"

```
START: Launch AI auto-reply?
â”‚
â”œâ”€ 1) Clarify Assumptions
â”‚   â”œâ”€ Users trust AI-generated replies
â”‚   â”œâ”€ AI replies reduce support workload
â”‚   â””â”€ Errors will be rare and acceptable
â”‚
â”œâ”€ 2) Identify Risks
â”‚   â”œâ”€ Wrong reply â†’ user trust damage (HIGH)
â”‚   â”œâ”€ Legal/compliance issues (MEDIUM)
â”‚   â”œâ”€ Minimal efficiency gain (LOW)
â”‚
â”œâ”€ 3) Validation Plan
â”‚   â”œâ”€ Shadow mode: AI drafts, humans approve
â”‚   â”œâ”€ Measure: % usable replies, correction rate
â”‚   â”œâ”€ Interview top support agents
â”‚   â””â”€ 2-week time box
â”‚
â””â”€ 4) Decide
    â”œâ”€ If â‰¥70% replies usable â†’ limited beta
    â”œâ”€ If <70% but improving â†’ iterate + delay
    â””â”€ If trust issues severe â†’ kill feature
```

---

## ðŸ”‘ Mental Shortcut (5-second recall)

```
What must be true?
â†’ What breaks if it's false?
â†’ What's the cheapest proof?
â†’ Decide with guardrails
```

If you want, next we can continue with **P10 â€“ Executive Communication** in the same ASCII + sample format, or convert all P1â€“P9 into a single printable cheat sheet.
